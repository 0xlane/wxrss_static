<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="referrer" content="no-referrer"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>PaperWeekly</title><style>
            /* 导航栏样式 - 水平滑动 */
            .navigation {
                display: flex;
                justify-content: center;
                gap: 20px;
                padding: 20px 20px; /* 左右增加 padding，避免内容贴边 */
                border-bottom: 1px solid #eee;
                margin-bottom: 20px;

                overflow-x: auto; /* 关键：水平方向内容超出时显示滚动条 */
                -webkit-overflow-scrolling: touch; /* 为了在iOS设备上滚动更顺畅 */
                white-space: nowrap; /* 导航链接不换行，保持水平排列 */
                flex-wrap: nowrap; /* 确保 flex items 不换行 */
            }

            /* 隐藏滚动条 (可选，但通常为了美观会隐藏) */
            .navigation::-webkit-scrollbar {
                display: none; /* 隐藏 Chrome, Safari, Edge 滚动条 */
            }
            .navigation {
                -ms-overflow-style: none;  /* 隐藏 IE and Edge 滚动条 */
                scrollbar-width: none;  /* 隐藏 Firefox 滚动条 */
            }

            .navigation-link {
                text-decoration: none;
                color: #333;
                font-weight: bold;
                transition: color 0.3s;
                flex-shrink: 0; /* 确保导航链接不会被压缩 */
            }

            .navigation-link:hover {
                color: #007bff;
            }

            .article-list {
                list-style: none;
                padding: 0;
                max-width: 800px; /* 桌面端最大宽度保持不变 */
                margin: 20px auto;
            }
    
            .article-item {
                border-bottom: 1px solid #eee;
                padding: 20px;
                transition: background 0.3s;
                display: flex;
                align-items: stretch;
            }
    
            .article-item:hover {
                background: #f9f9f9;
            }
    
            .article-cover {
                width: 40%;
                max-width: 200px;
                margin-right: 20px;
                overflow: hidden;
                flex-shrink: 0;
                box-sizing: border-box;
                max-height: 150px;
            }
    
            .article-cover:hover img {
                transform: scale3d(1.1,1.1,1.1);
                -webkit-transition: all .5s ease-in-out;
                -moz-transition: all .5s ease-in-out;
                transition: all .5s ease-in-out;
                filter: alpha(Opacity=85);
                -moz-opacity: .85;
                opacity: .85
            }
    
            .article-cover img {
                width: 100%;
                height: 100%;
                object-fit: cover;
                display: block;
                transition: transform 0.3s ease-in-out;
                -webkit-transition: transform 0.3s ease-in-out;
                -moz-transition: transform 0.3s ease-in-out;
            }
    
            .article-content {
                flex: 1;
                width: 60%;
                box-sizing: border-box;
            }
    
            .article-title {
                font-size: 1.2em;
                margin: 0 0 10px;
            }
            
            .article-title a {
                color: #333;
                text-decoration: none;
                transition: color 0.3s;
                -webkit-transition: color 0.3s;
                -moz-transition: color 0.3s;
            }

            .article-title a:hover {
                color: #007bff;
                text-decoration: none;
            }
    
            .article-meta {
                color: #666;
                font-size: 0.9em;
                margin-bottom: 8px;
            }
    
            .article-author {
                margin-right: 15px;
            }
    
            .article-date {
                color: #999;
            }
    
            .article-description {
                color: #444;
                line-height: 1.6;
                margin: 10px 0;
                height: 48px;
                overflow: hidden;
                text-overflow: ellipsis;
                display: -webkit-box;
                -webkit-line-clamp: 2;
                -webkit-box-orient: vertical;
            }
    
            .article-link {
                color: #007bff;
                text-decoration: none;
                font-size: 0.9em;
            }
    
            /* 分页按钮样式 */
            .pagination {
                display: flex;
                justify-content: center;
                margin-top: 20px;
                margin-bottom: 20px;
            }
    
            .pagination-button {
                display: inline-block;
                padding: 10px 20px;
                margin: 0 10px;
                border: 1px solid #ccc;
                border-radius: 5px;
                background-color: #fff;
                color: #333;
                text-decoration: none;
                cursor: pointer;
                transition: background-color 0.3s, border-color 0.3s, color 0.3s;
            }
    
            .pagination-button:hover {
                background-color: #f0f0f0;
                border-color: #bbb;
            }
    
            .pagination-button:disabled {
                background-color: #eee;
                color: #999;
                border-color: #ddd;
                cursor: not-allowed;
            }
    
            /*  Media Queries - 针对小屏幕设备优化  */
            @media (max-width: 768px) {  /*  2. 使用 Media Query，针对屏幕宽度小于 768px 的设备应用以下样式  */
                /* 手机端导航栏样式 (水平滑动) */
                .navigation {
                    justify-content: left;
                    gap: 10px; /* 减小导航链接之间的间距 */
                    padding: 10px 10px; /* 减小导航栏的左右和上下内边距 */
                    margin-bottom: 15px; /* 减小导航栏下外边距 */
                }

                .navigation-link {
                    font-size: 0.9rem; /* 可以适当减小导航链接字体大小 */
                    padding: 5px 10px; /* 可以适当减小导航链接内边距 */
                }

                .article-list {
                    max-width: 100%;  /*  手机上文章列表宽度撑满屏幕  */
                    margin-left: 10px;   /*  左右留出少量边距，避免内容紧贴屏幕边缘  */
                    margin-right: 10px;
                }
    
                .article-item {
                    flex-direction: column; /*  手机上文章条目垂直排列  */
                    padding: 15px;       /*  略微减小 article-item 的内边距  */
                }
    
                .article-cover {
                    width: 100%;        /*  手机上封面宽度撑满容器  */
                    max-width: none;      /*  移除最大宽度限制  */
                    margin-right: 0;      /*  移除右侧外边距  */
                    margin-bottom: 10px;   /*  底部增加外边距，与文字内容分隔  */
                    max-height: none;      /*  移除最大高度限制，让图片根据自身比例显示，或者可以设置一个合适的 max-height */
                }
    
                .article-content {
                    width: 100%;        /*  手机上内容区域宽度撑满容器  */
                }
    
                .article-title {
                    font-size: 1.1em;   /*  略微减小标题字体大小  */
                }
    
                .article-description {
                    font-size: 0.95em;  /*  略微减小描述字体大小  */
                    height: auto;        /*  手机上取消固定高度，让描述文字完整显示，或者根据需要调整行数限制 */
                    -webkit-line-clamp: unset; /* 取消行数限制 */
                }
    
                .article-meta {
                    font-size: 0.85em;  /*  略微减小 meta 信息字体大小  */
                }
    
                .pagination-button {
                    padding: 8px 16px;   /*  略微减小分页按钮内边距，但保持可点击区域  */
                    margin: 0 5px;      /*  略微减小按钮间距  */
                }

                /* 取消手机端 article-cover 的悬浮放大效果 */
                .article-cover:hover img {
                    transform: scale3d(1.0,1,0,1.0); /* 或者 transform: none;  都可以 */
                }
            }
                    </style></head><body><nav class="navigation"><a class="navigation-link" href="/">全部</a><a class="navigation-link" href="/sec/">安全</a><a class="navigation-link" href="/dev/">开发</a><a class="navigation-link" href="/new/">新闻</a><a class="navigation-link" href="/digital/">数码</a><a class="navigation-link" href="/photography/">摄影</a><a class="navigation-link" href="/car/">汽车</a><a class="navigation-link" href="/beijing/">北京</a><a class="navigation-link" href="/ai/">AI</a><a class="navigation-link" href="/it/">IT</a><a class="navigation-link" href="/other/">其他</a></nav><ul class="article-list"><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709914&amp;idx=3&amp;sn=a6f13d60691986d5b528c554d56842ff&amp;chksm=97c89f7f3ef93b291e404324b4a28b348a2c86ccffad99c810b77f05c6de8545f68db5cc172c&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglucskhct50hCAg0BZibMhVpKicJLjublWPH7oQo6U0CuiaVkb2gIFzwKJmicehzibuMFkBql8DSZia7a4A/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709914&amp;idx=3&amp;sn=a6f13d60691986d5b528c554d56842ff&amp;chksm=97c89f7f3ef93b291e404324b4a28b348a2c86ccffad99c810b77f05c6de8545f68db5cc172c&amp;scene=0&amp;xtrack=1#rd" target="_blank">早鸟票倒计时2天！全国大模型智能生成大会：推理、多模态、智能体前沿集结</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-18 18:39:03">发布日期：2025-10-18 18:39:03</time></div><p class="article-description">会议简介全国大模型智能生成大会（LMG）是中国中文信息学会（CIPS）大模型与生成专业委员会的旗舰学术会议。LMG是国内外大模型技术精英最期待的年度盛会，是极具行业实践的专业大模型交流平台，共同推进大</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709914&amp;idx=3&amp;sn=a6f13d60691986d5b528c554d56842ff&amp;chksm=97c89f7f3ef93b291e404324b4a28b348a2c86ccffad99c810b77f05c6de8545f68db5cc172c&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709834&amp;idx=1&amp;sn=2986fb95731ad97b3c473dad0bec0ad1&amp;chksm=979e9a7e23d6523beb3ddb259ed5ce07b5f8d24e7fe69782346c8f202c9c1707564d6d0b0ba6&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmiaDAKH30ztic2HaDCSLWCeOSb7Y4l3XrAHSGZK4eXISpSxMbLeEvfVXWgNbcZpkLyHw7zqG3pibghg/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709834&amp;idx=1&amp;sn=2986fb95731ad97b3c473dad0bec0ad1&amp;chksm=979e9a7e23d6523beb3ddb259ed5ce07b5f8d24e7fe69782346c8f202c9c1707564d6d0b0ba6&amp;scene=0&amp;xtrack=1#rd" target="_blank">Meta花了420万美元、烧掉40万GPU·小时，只为验证一条Sigmoid曲线</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-17 17:13:39">发布日期：2025-10-17 17:13:39</time></div><p class="article-description">Meta 花了 420 万美元、40 万 GPU·小时，只为验证一个大胆猜想： 强化学习的结果，其实在训练一半时就能被算出来。在大模型时代，烧钱的研究已经见怪不怪；但当 Meta 的论文承认——这项实</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709834&amp;idx=1&amp;sn=2986fb95731ad97b3c473dad0bec0ad1&amp;chksm=979e9a7e23d6523beb3ddb259ed5ce07b5f8d24e7fe69782346c8f202c9c1707564d6d0b0ba6&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709834&amp;idx=2&amp;sn=edc4e24618bcb27adb5a47705b58122e&amp;chksm=97a0bd22f80f86b5edede326d7b46c2090417502185631ee85c26e5f5168c6501ae643ae3f46&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmiaDAKH30ztic2HaDCSLWCeO8KfLnA37SLkoxsFibOsGEzM6qF7PbtMRuXdiaVN1Yof0hZwuuFYIEvDg/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709834&amp;idx=2&amp;sn=edc4e24618bcb27adb5a47705b58122e&amp;chksm=97a0bd22f80f86b5edede326d7b46c2090417502185631ee85c26e5f5168c6501ae643ae3f46&amp;scene=0&amp;xtrack=1#rd" target="_blank">从会画画到会思考：快手可灵提出T2I-CoReBench，最强模型也难逃推理瓶颈</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-17 17:13:39">发布日期：2025-10-17 17:13:39</time></div><p class="article-description">文本生成图像已从“能画出来”进入“要想明白”的时代。快手可灵团队发布的 T2I-CoReBench，用 12 个维度、1080 个高难 Prompt 与 13,500+ 精细化问题，首次系统揭示 T2</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709834&amp;idx=2&amp;sn=edc4e24618bcb27adb5a47705b58122e&amp;chksm=97a0bd22f80f86b5edede326d7b46c2090417502185631ee85c26e5f5168c6501ae643ae3f46&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709834&amp;idx=3&amp;sn=3eb8d617efd73692807b3dcfcd2e9173&amp;chksm=97322c0e8508cf73cc6b82c768dabdfa763dd70018010bc2e4bb945e86e500db1819e802a8c0&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmiaDAKH30ztic2HaDCSLWCeOq2O8AySBooORbyT6yib2IIMGhZ7cHKMwsmfQmhdTgUa9w9VhgIzWhtQ/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709834&amp;idx=3&amp;sn=3eb8d617efd73692807b3dcfcd2e9173&amp;chksm=97322c0e8508cf73cc6b82c768dabdfa763dd70018010bc2e4bb945e86e500db1819e802a8c0&amp;scene=0&amp;xtrack=1#rd" target="_blank">NeurIPS 2025 | 上交大提出MM-UPT：多模态大模型的“无监督后训练”范式</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-17 17:13:39">发布日期：2025-10-17 17:13:39</time></div><p class="article-description">自多模态大语言模型（MLLM）问世以来，它们在图像描述、视觉问答等任务中展现了惊人的能力。为了进一步提升模型性能，尤其是在复杂的多模态推理任务上，学术界和工业界的主流范式是监督微调（SFT）或强化学习</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709834&amp;idx=3&amp;sn=3eb8d617efd73692807b3dcfcd2e9173&amp;chksm=97322c0e8508cf73cc6b82c768dabdfa763dd70018010bc2e4bb945e86e500db1819e802a8c0&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709740&amp;idx=1&amp;sn=ee844491802086e5370f59ade2660f4b&amp;chksm=972cfda39598f73270bf53a379c67c0cde279a2f0121db0a3c4c29f35d90d00e927250680b24&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmss4sI1bMib5niaDemCicIebfYY2mHND5Ys4RFqtZib4XBjczm2GIaFzEQBPjdViaTRFFiafiazyjuf4r5Q/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709740&amp;idx=1&amp;sn=ee844491802086e5370f59ade2660f4b&amp;chksm=972cfda39598f73270bf53a379c67c0cde279a2f0121db0a3c4c29f35d90d00e927250680b24&amp;scene=0&amp;xtrack=1#rd" target="_blank">GPT越来越保守？斯坦福Manning团队提出Verbalized Sampling，让模型重新“多想一点”</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-16 21:20:33">发布日期：2025-10-16 21:20:33</time></div><p class="article-description">当我们发现 GPT 的回答越来越相似、越来越像在背标准答案时，问题或许不在模型的能力，而在它被人类偏好训练“驯化”成了平均值——它学会了迎合最典型的答案，却忘了自己原本的多样性。过去两年，几乎所有经过</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709740&amp;idx=1&amp;sn=ee844491802086e5370f59ade2660f4b&amp;chksm=972cfda39598f73270bf53a379c67c0cde279a2f0121db0a3c4c29f35d90d00e927250680b24&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709740&amp;idx=2&amp;sn=01d3eb7ed866386741dc09c025cee31a&amp;chksm=97bf28a196aba62f8e8680827fea5ae7c7c78ead011a416d3e7069810430a2bee927b813a387&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmss4sI1bMib5niaDemCicIebfmEdqnGQWRxPicX5oSGulOcTIgPvZgb5TibI9pVMQpD7JhfzND58QdHYQ/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709740&amp;idx=2&amp;sn=01d3eb7ed866386741dc09c025cee31a&amp;chksm=97bf28a196aba62f8e8680827fea5ae7c7c78ead011a416d3e7069810430a2bee927b813a387&amp;scene=0&amp;xtrack=1#rd" target="_blank">ACL 2025 | 北大提出动态焦点解码：让开放生成既“靠谱”又“好看”</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-16 21:20:33">发布日期：2025-10-16 21:20:33</time></div><p class="article-description">近年来，大语言模型在开放式生成任务中大放异彩，但一个问题始终存在——生成的内容要么太死板，要么太离谱。固定的随机解码温度让模型陷入两难：温度高，输出多样但容易胡说八道；温度低，句句属实却千篇一律。如何</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709740&amp;idx=2&amp;sn=01d3eb7ed866386741dc09c025cee31a&amp;chksm=97bf28a196aba62f8e8680827fea5ae7c7c78ead011a416d3e7069810430a2bee927b813a387&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709740&amp;idx=3&amp;sn=12d9494b3a7a083f1fc7ecb93f582aa6&amp;chksm=972ae6520f3fceeafdbd31fd1e3207a4c572dbfcdbefeb1b1d7368c9001eec83e7ee082f9f44&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmss4sI1bMib5niaDemCicIebf7OTsskytkWSHHTAEKs80iaKrxshGicqEKuA6EriagW8yoIfQyLq90sNJg/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709740&amp;idx=3&amp;sn=12d9494b3a7a083f1fc7ecb93f582aa6&amp;chksm=972ae6520f3fceeafdbd31fd1e3207a4c572dbfcdbefeb1b1d7368c9001eec83e7ee082f9f44&amp;scene=0&amp;xtrack=1#rd" target="_blank">统一高效来了！清华发布RLinf-VLA：把VLA+RL的训练与部署“一网打尽”</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-16 21:20:33">发布日期：2025-10-16 21:20:33</time></div><p class="article-description">前段时间清华大学推出了首个面向具身智能的大规模强化学习框架 RLinf，之前主要是从系统设计的角度出发，介绍 RLinf 极度灵活的系统设计思想。最近，团队加班加点，终于出炉了 RLinf 系统中关于</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709740&amp;idx=3&amp;sn=12d9494b3a7a083f1fc7ecb93f582aa6&amp;chksm=972ae6520f3fceeafdbd31fd1e3207a4c572dbfcdbefeb1b1d7368c9001eec83e7ee082f9f44&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709576&amp;idx=1&amp;sn=6d3e74f75c7470bb03b88c8181547eec&amp;chksm=979b3e1f3686c78ce185574525223263f3a4d5cabeb9f06bcc5df9fd1fe9f447f6b854135a51&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgktzbRrzSfWazucnPjjiaibOM6fhWLzsoIfIaYsXjZdKWISRdXuZ1ShicavtdRIyGglKicuGXvXUkP7rg/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709576&amp;idx=1&amp;sn=6d3e74f75c7470bb03b88c8181547eec&amp;chksm=979b3e1f3686c78ce185574525223263f3a4d5cabeb9f06bcc5df9fd1fe9f447f6b854135a51&amp;scene=0&amp;xtrack=1#rd" target="_blank">罗福莉担任通讯作者，小米 × 北大联合发布R3：让MoE强化学习从崩盘回归可控</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-15 13:11:41">发布日期：2025-10-15 13:11:41</time></div><p class="article-description">“95 后天才少女”罗福莉以通讯作者身份参与小米联合发布的 R3（Rollout Routing Replay），首次从路由一致性层面对齐 MoE 强化学习的根因不稳，让训练曲线从“崩盘”回到可控区间</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709576&amp;idx=1&amp;sn=6d3e74f75c7470bb03b88c8181547eec&amp;chksm=979b3e1f3686c78ce185574525223263f3a4d5cabeb9f06bcc5df9fd1fe9f447f6b854135a51&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709576&amp;idx=2&amp;sn=92ded1a85a67dc0a3ff22e852be6cf78&amp;chksm=971696b69eb731a245068ef10d13322815db0fdd007bbcc996e5782d086b44ff8831fafe5001&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgktzbRrzSfWazucnPjjiaibOM2buTWiaEdn7alDRjno1XJYFPWPQM7usvHibkuXHvyUrOBzsFvBU8szIA/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709576&amp;idx=2&amp;sn=92ded1a85a67dc0a3ff22e852be6cf78&amp;chksm=971696b69eb731a245068ef10d13322815db0fdd007bbcc996e5782d086b44ff8831fafe5001&amp;scene=0&amp;xtrack=1#rd" target="_blank">下周见！Wiley Advanced主编论坛@IROS 2025：从审稿人视角重塑论文表达</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-15 13:11:41">发布日期：2025-10-15 13:11:41</time></div><p class="article-description">2025年全球机器人领域的顶级盛会——IEEE/RSJ智能机器人与系统国际会议（IROS 2025）将于 10 月19日-25日在杭州国际博览中心隆重召开。今年大会的主题是“人类-机器人前沿”，将重点</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709576&amp;idx=2&amp;sn=92ded1a85a67dc0a3ff22e852be6cf78&amp;chksm=971696b69eb731a245068ef10d13322815db0fdd007bbcc996e5782d086b44ff8831fafe5001&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709576&amp;idx=3&amp;sn=e8efa9061b9d95a57a84d68d313951e3&amp;chksm=972e20c4ddafeec2d49f79ee657e27bdb1b158131d94b100e5184f190351ad4f38f815f32445&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgktzbRrzSfWazucnPjjiaibOMavGEyjQ7icnSU8uav5u1FQfbaCnias7S5VJQjjEDdhshd7FNDzfP4N4g/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709576&amp;idx=3&amp;sn=e8efa9061b9d95a57a84d68d313951e3&amp;chksm=972e20c4ddafeec2d49f79ee657e27bdb1b158131d94b100e5184f190351ad4f38f815f32445&amp;scene=0&amp;xtrack=1#rd" target="_blank">AAAI 2026联合会议征稿开启：大语言模型中的深度逻辑推理</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-15 13:11:41">发布日期：2025-10-15 13:11:41</time></div><p class="article-description">AAAI 2026AAAI人工智能会议（AAAI Conference on Artificial Intelligence）由人工智能促进会（AAAI）主办，是人工智能领域中历史最悠久、涵盖内容最广</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709576&amp;idx=3&amp;sn=e8efa9061b9d95a57a84d68d313951e3&amp;chksm=972e20c4ddafeec2d49f79ee657e27bdb1b158131d94b100e5184f190351ad4f38f815f32445&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709503&amp;idx=1&amp;sn=96aa08cfe0b8a33329b77118b54c4e19&amp;chksm=97e2c82c55f73c67f7f4ac15cf27e761947205fa391eb46904cc3a696cd99c055b2800d4369f&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnptcgLq3PwJia1E41ARQKAotgpkl6zYa7Aw3pTj8tKEANZ8TYpFkbfRTBicjG5FoOXIUmsDDr0DtCQ/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709503&amp;idx=1&amp;sn=96aa08cfe0b8a33329b77118b54c4e19&amp;chksm=97e2c82c55f73c67f7f4ac15cf27e761947205fa391eb46904cc3a696cd99c055b2800d4369f&amp;scene=0&amp;xtrack=1#rd" target="_blank">直到毕业我才懂：原来延期的博士，不止我一个</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-14 13:48:06">发布日期：2025-10-14 13:48:06</time></div><p class="article-description">最近经常收到读者的留言 : 抱怨科研真是太难了，竞争压力大，导师不给指导、不开组会，一年见不到导师几次，对于论文初稿、毕业毫无建议! 其实他不是个例，大家也会有这样的烦恼：前沿顶会、期刊论文、综述文献</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709503&amp;idx=1&amp;sn=96aa08cfe0b8a33329b77118b54c4e19&amp;chksm=97e2c82c55f73c67f7f4ac15cf27e761947205fa391eb46904cc3a696cd99c055b2800d4369f&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709503&amp;idx=2&amp;sn=6cf48d217ce13cb68c86b21a4d31a6db&amp;chksm=9760fe3fc159c919b482e120a280eaf488d828d2e900ac3228be777d1044d2059117d2ea2441&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnptcgLq3PwJia1E41ARQKAoordmCdWIyjrl6dttTFTNGR1dByiaicWGrbZXicnTaJk9m5afrD8VzA3dA/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709503&amp;idx=2&amp;sn=6cf48d217ce13cb68c86b21a4d31a6db&amp;chksm=9760fe3fc159c919b482e120a280eaf488d828d2e900ac3228be777d1044d2059117d2ea2441&amp;scene=0&amp;xtrack=1#rd" target="_blank">让论文自己讲！Paper2Video一键生成论文讲解视频，赶顶会DDL不慌了</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-14 13:48:06">发布日期：2025-10-14 13:48:06</time></div><p class="article-description">你以为熬夜剪视频能保命，其实 Paper2Video 才是 DDL 真正的救命药。给它一篇论文、讲者图像和音频样本，几分钟就能生成一支“自己讲”的学术演示视频。想象一下：论文刚定稿，你的讲解视频也同步</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709503&amp;idx=2&amp;sn=6cf48d217ce13cb68c86b21a4d31a6db&amp;chksm=9760fe3fc159c919b482e120a280eaf488d828d2e900ac3228be777d1044d2059117d2ea2441&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709503&amp;idx=3&amp;sn=eede2987d8a2ac7125285ebfb7aa9d1f&amp;chksm=97ea2f858a4b7be142c2ee7a94903869e9ddf7f7ab42430caa3d8d5dbd9c81707dcebca3031e&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnptcgLq3PwJia1E41ARQKAoibZgWT5RiaichGEas1ibzJ6LXgvJeSmUOFR6jsooaRibLqVnicQ93KsOwHDQ/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709503&amp;idx=3&amp;sn=eede2987d8a2ac7125285ebfb7aa9d1f&amp;chksm=97ea2f858a4b7be142c2ee7a94903869e9ddf7f7ab42430caa3d8d5dbd9c81707dcebca3031e&amp;scene=0&amp;xtrack=1#rd" target="_blank">8美元“驯服”DeepSeek-V3.2？Training-Free GRPO把RL成本打到地板</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-14 13:48:06">发布日期：2025-10-14 13:48:06</time></div><p class="article-description">强化学习之父、图灵奖得主 Richard Sutton 认为：新一代的智能体将主要通过从经验中学习来获得超人类的能力，而不是仅靠人类数据的监督学习。传统 RL 训练在 32B 模型上动辄上万美元，现在</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709503&amp;idx=3&amp;sn=eede2987d8a2ac7125285ebfb7aa9d1f&amp;chksm=97ea2f858a4b7be142c2ee7a94903869e9ddf7f7ab42430caa3d8d5dbd9c81707dcebca3031e&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709412&amp;idx=1&amp;sn=0390b456ca4f05ba79aff8983093c33d&amp;chksm=97922d9125a31db63d3ad9be69b2f3a68c984ea39047be7e0d0eee414bea53579f0dc401d84d&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglia97KIicNkEPSFfE0NrdRaWsWCOahOwPYgfic29UPC41s7mRNcyicKqx9t62q6g6LxDPTAk2PqAYlDQ/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709412&amp;idx=1&amp;sn=0390b456ca4f05ba79aff8983093c33d&amp;chksm=97922d9125a31db63d3ad9be69b2f3a68c984ea39047be7e0d0eee414bea53579f0dc401d84d&amp;scene=0&amp;xtrack=1#rd" target="_blank">强化学习再迎范式切换：Sergey Levine团队把目标改写成“到达时间”</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-13 23:23:19">发布日期：2025-10-13 23:23:19</time></div><p class="article-description">还在把“目标”当一帧观测硬塞进网络？来自 UC Berkeley 强化学习大牛 Sergey Levine 团队的新作，直接把范式翻过来——用“从任意状态到目标的最优到达时间”来定义目标。理论上“既足</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709412&amp;idx=1&amp;sn=0390b456ca4f05ba79aff8983093c33d&amp;chksm=97922d9125a31db63d3ad9be69b2f3a68c984ea39047be7e0d0eee414bea53579f0dc401d84d&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709412&amp;idx=2&amp;sn=b9fd526b87e266001c746686cb9c2078&amp;chksm=97846e7d9b2d6249d7a3d38764a7178eab98cb18f4bad3a0123710e2ae9000f305d3fb498214&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglia97KIicNkEPSFfE0NrdRaWPwYHcWBnYDjTyCuTLCrE7wicichjaHbtJBpHQu9EJNcHXEJggsAuc1ibA/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709412&amp;idx=2&amp;sn=b9fd526b87e266001c746686cb9c2078&amp;chksm=97846e7d9b2d6249d7a3d38764a7178eab98cb18f4bad3a0123710e2ae9000f305d3fb498214&amp;scene=0&amp;xtrack=1#rd" target="_blank">如果RL可预测，我们还需要把训练跑满吗？中科大揭示参数更新的线性秘密</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-13 23:23:19">发布日期：2025-10-13 23:23:19</time></div><p class="article-description">RL 训练真的像我们以为的那样“混沌”吗？中科大团队发现，大模型的强化学习过程几乎沿着一条线性轨迹前进——早期的参数更新就能预测训练终局。 从复杂到可预测，这一发现让 RL 的漫长训练第一次显得“可计</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709412&amp;idx=2&amp;sn=b9fd526b87e266001c746686cb9c2078&amp;chksm=97846e7d9b2d6249d7a3d38764a7178eab98cb18f4bad3a0123710e2ae9000f305d3fb498214&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709332&amp;idx=1&amp;sn=ddf9d96ce773db8bfeb657bbc31e060a&amp;chksm=97e002084ba3d2c4f16d5b620a99b6d81ec5afffa460cb1e09b942e4e3fa18e8b29afdf3edbc&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgm4iaLGHibC5k1lnPbRHlKicEaJuicGeawgVIoFlIliaZGvR75TKJeicxGO8skI9DVVo7ZouqSaPVKyW9rg/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709332&amp;idx=1&amp;sn=ddf9d96ce773db8bfeb657bbc31e060a&amp;chksm=97e002084ba3d2c4f16d5b620a99b6d81ec5afffa460cb1e09b942e4e3fa18e8b29afdf3edbc&amp;scene=0&amp;xtrack=1#rd" target="_blank">Mamba-3惊现ICLR 2026投稿：三重升级打满“推理优先”范式</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-12 17:10:52">发布日期：2025-10-12 17:10:52</time></div><p class="article-description">ICLR 2026 投稿惊现 Mamba-3：一场从数值分析、复值状态到硬件算力的系统重构，线性模型的“效率—能力—质量”三线齐升。在 ICLR 2026 的 OpenReview 上，一篇匿名投稿以</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709332&amp;idx=1&amp;sn=ddf9d96ce773db8bfeb657bbc31e060a&amp;chksm=97e002084ba3d2c4f16d5b620a99b6d81ec5afffa460cb1e09b942e4e3fa18e8b29afdf3edbc&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709332&amp;idx=2&amp;sn=5198e465e340d40bd7d1d0f4ec94b3fc&amp;chksm=97d1720f1b10f3dbabae5b14b42e28d87aa13d166ee71580780de379de9d512e626ef74b3ebb&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgm4iaLGHibC5k1lnPbRHlKicEaF2rzk1nZxjQ2tIJb9X3vHKavc3w8s4ToZV0DmpwcVWxuBHhEacLjcQ/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709332&amp;idx=2&amp;sn=5198e465e340d40bd7d1d0f4ec94b3fc&amp;chksm=97d1720f1b10f3dbabae5b14b42e28d87aa13d166ee71580780de379de9d512e626ef74b3ebb&amp;scene=0&amp;xtrack=1#rd" target="_blank">93%成功率！从“改提示”到“写剧情”：STaR-Attack用叙事推理攻破大模型防线</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-12 17:10:52">发布日期：2025-10-12 17:10:52</time></div><p class="article-description">引言近两年，统一多模态大模型（UMMs）的发展让人惊叹。它们不只会理解图文，还能在对话中生成图像、视频，甚至跨模态推理。一个模型“多面手”，似乎无所不能。但能力越强，风险也随之而来。我们的研究首次发现</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709332&amp;idx=2&amp;sn=5198e465e340d40bd7d1d0f4ec94b3fc&amp;chksm=97d1720f1b10f3dbabae5b14b42e28d87aa13d166ee71580780de379de9d512e626ef74b3ebb&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709240&amp;idx=1&amp;sn=b68daa95bdd0406571b13544ef598111&amp;chksm=9754037fd37afc47f4952d47c2000536cb8f8eabc4ad18289e2943ab4bfb4169682241010880&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkLoia9bWRdPqiaIqI9fgLNiaNkJ6cEYPFSko7pmy2C5sm556e5qaxrL1pQ2ks5sClCGFfTP4icUnH1Nw/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709240&amp;idx=1&amp;sn=b68daa95bdd0406571b13544ef598111&amp;chksm=9754037fd37afc47f4952d47c2000536cb8f8eabc4ad18289e2943ab4bfb4169682241010880&amp;scene=0&amp;xtrack=1#rd" target="_blank">Attention is NOT All You Need：让“深度”重新流入时间，而非堆叠在参数之上</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-11 18:09:18">发布日期：2025-10-11 18:09:18</time></div><p class="article-description">自 Attention 统治深度学习以来，我们获得了惊人的速度与可扩展性，却似乎失去了另一种更本质的能力——在时间中递归地思考、积累与演化。当速度压倒深度，我们真的理解了“智能”的含义吗？自 2018</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709240&amp;idx=1&amp;sn=b68daa95bdd0406571b13544ef598111&amp;chksm=9754037fd37afc47f4952d47c2000536cb8f8eabc4ad18289e2943ab4bfb4169682241010880&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709240&amp;idx=2&amp;sn=9ed18c4649a43f9e81e349cb3115eedc&amp;chksm=97e8cdd079757ccf26a004b199a0f8a23fcad3d4da97b97206fc7843a107b79b310c3f019882&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkLoia9bWRdPqiaIqI9fgLNiaN9yEIjNZ5WdYMice2FIKd4ibjDk7JuUTiaPVa2QicT9r7pebTXticwL9ytyw/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709240&amp;idx=2&amp;sn=9ed18c4649a43f9e81e349cb3115eedc&amp;chksm=97e8cdd079757ccf26a004b199a0f8a23fcad3d4da97b97206fc7843a107b79b310c3f019882&amp;scene=0&amp;xtrack=1#rd" target="_blank">NeurIPS 2025 Oral | 1个Token零成本，REG让Diffusion训练收敛快20倍！</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-11 18:09:18">发布日期：2025-10-11 18:09:18</time></div><p class="article-description">只需引入一个 class token，REG 就让 Diffusion Transformer 的训练速度飙升至 63 倍，几乎“零成本”实现了更快收敛与更优生成——这项来自 NeurIPS 2025</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709240&amp;idx=2&amp;sn=9ed18c4649a43f9e81e349cb3115eedc&amp;chksm=97e8cdd079757ccf26a004b199a0f8a23fcad3d4da97b97206fc7843a107b79b310c3f019882&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709188&amp;idx=1&amp;sn=1bb896b549716972279d3ac471bcf359&amp;chksm=9705ab8146b3f09f0514b98329549a043ccd25f21835e5a47817f9b2fbf5cee1f1dd2df3da47&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglEVQhCaFLzicCMcOoibdvBicRzgdD9hvZ0Cialtpd650ELI8R4JYfeV3OW8E195ia9qiahXHvX0sdGwkng/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709188&amp;idx=1&amp;sn=1bb896b549716972279d3ac471bcf359&amp;chksm=9705ab8146b3f09f0514b98329549a043ccd25f21835e5a47817f9b2fbf5cee1f1dd2df3da47&amp;scene=0&amp;xtrack=1#rd" target="_blank">DeepSeek苦练1T，清华只用5B？InfLLM-V2把稀疏注意力玩明白了</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-10 13:16:59">发布日期：2025-10-10 13:16:59</time></div><p class="article-description">引言长序列高效处理已成为大模型应用的关键。传统稠密注意力在序列变长时计算开销极速增长，直接限制了产品可用性与成本可控性。为解决这一痛点，清华与 OpenBMB 提出 InfLLM-V2：一种零额外参数</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709188&amp;idx=1&amp;sn=1bb896b549716972279d3ac471bcf359&amp;chksm=9705ab8146b3f09f0514b98329549a043ccd25f21835e5a47817f9b2fbf5cee1f1dd2df3da47&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709188&amp;idx=2&amp;sn=07bb7ebad5d78b866103c55077c17954&amp;chksm=9720ea25d7253a482355fc252ad94a00b6020fd6210b3d8af4b119069f5b60c6f6b817a636da&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnmWiaJ0shIAxCHLmh5rQ1iaiavicSWZbicurg3BJmYppzggycCOGpDFHaCJUgKhUtpF70SUgewlkWvGAQ/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709188&amp;idx=2&amp;sn=07bb7ebad5d78b866103c55077c17954&amp;chksm=9720ea25d7253a482355fc252ad94a00b6020fd6210b3d8af4b119069f5b60c6f6b817a636da&amp;scene=0&amp;xtrack=1#rd" target="_blank">EMNLP 2025 | 拨云见日：知识电路分析揭示大语言模型“知识遮蔽”幻觉之源</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-10 13:16:59">发布日期：2025-10-10 13:16:59</time></div><p class="article-description">当我们以为大模型的“幻觉”只是记错事实时，PhantomCircuit 揭示了一个更隐蔽的真相——模型其实记得，但被主流知识遮蔽了。高频知识在神经电路中形成偏压，压制了那些低频却正确的事实，让模型“看</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709188&amp;idx=2&amp;sn=07bb7ebad5d78b866103c55077c17954&amp;chksm=9720ea25d7253a482355fc252ad94a00b6020fd6210b3d8af4b119069f5b60c6f6b817a636da&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709188&amp;idx=3&amp;sn=6327b36bd507a1afa9b860c7d054c060&amp;chksm=97058344e96cb111c6e700eb21435c92ce95648ea0781a00040c35c94413e4d88334d788557c&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnmWiaJ0shIAxCHLmh5rQ1iaiaEkRyYxxPCeQJIFFW1RMSA8P05Tlon0icYWSym9HCoOy71vbvzlw029A/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709188&amp;idx=3&amp;sn=6327b36bd507a1afa9b860c7d054c060&amp;chksm=97058344e96cb111c6e700eb21435c92ce95648ea0781a00040c35c94413e4d88334d788557c&amp;scene=0&amp;xtrack=1#rd" target="_blank">北京/上海内推 | 阶跃星辰招聘RL for AIGC方向算法研究员/实习生</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-10 13:16:59">发布日期：2025-10-10 13:16:59</time></div><p class="article-description">合适的工作难找？最新的招聘信息也不知道？AI 求职为大家精选人工智能领域最新鲜的招聘信息，助你先人一步投递，快人一步入职！阶跃星辰阶跃星辰是行业领先的通用大模型创业公司，坚定探索实现通用人工智能的道路</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709188&amp;idx=3&amp;sn=6327b36bd507a1afa9b860c7d054c060&amp;chksm=97058344e96cb111c6e700eb21435c92ce95648ea0781a00040c35c94413e4d88334d788557c&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709124&amp;idx=1&amp;sn=1767c8713d3b394708d56874d46b458c&amp;chksm=973306da948db77086dfce1f2d9548ebcaa79682e47938877727ba68ad2b26b7b9062a57cf96&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkCOVxC5Zh5LftZiccf7BdiaxF6WRn3Bo0mElITp40bhODrrK3BPqhkYjj4zJghfbQLfXgsfA7ic3Kqg/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709124&amp;idx=1&amp;sn=1767c8713d3b394708d56874d46b458c&amp;chksm=973306da948db77086dfce1f2d9548ebcaa79682e47938877727ba68ad2b26b7b9062a57cf96&amp;scene=0&amp;xtrack=1#rd" target="_blank">马毅团队重磅发布新书：从MCR²到白盒Transformer，重构深度学习的第一性原理</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-09 23:48:39">发布日期：2025-10-09 23:48:39</time></div><p class="article-description">在神经网络无处不在的今天，我们似乎已经习惯了“深度学习就是堆结构、调参数”的经验主义时代。但在这一切的背后，一个根本问题始终没有被系统回答——深度网络究竟在学什么？为什么它们能从数据中生长出强大的表征</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709124&amp;idx=1&amp;sn=1767c8713d3b394708d56874d46b458c&amp;chksm=973306da948db77086dfce1f2d9548ebcaa79682e47938877727ba68ad2b26b7b9062a57cf96&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709124&amp;idx=2&amp;sn=f27724cd8e3624c59e6f9f5e45049312&amp;chksm=97240904bff7bbd3375606251070cd361b21e7017c676f54587a29a5c0b5ed3102b9fefd6a17&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkCOVxC5Zh5LftZiccf7BdiaxKsWVTOhDTTE0A9j8bm0GawIU1WKNf7BxufnTBCIxM3iaoqkpwn81ic3g/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709124&amp;idx=2&amp;sn=f27724cd8e3624c59e6f9f5e45049312&amp;chksm=97240904bff7bbd3375606251070cd361b21e7017c676f54587a29a5c0b5ed3102b9fefd6a17&amp;scene=0&amp;xtrack=1#rd" target="_blank">腾讯推出TRM：让大模型像人类一样批判性思考，从文本依赖到事实正确</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-09 23:48:39">发布日期：2025-10-09 23:48:39</time></div><p class="article-description">最近，腾讯 WXG 推出了思维监督奖励模型Thinking-supervised Reward Model (TRM)，旨在提升大语言模型（LLM）在开放域问答任务中的事实正确性。TRM 通过引入忠实</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709124&amp;idx=2&amp;sn=f27724cd8e3624c59e6f9f5e45049312&amp;chksm=97240904bff7bbd3375606251070cd361b21e7017c676f54587a29a5c0b5ed3102b9fefd6a17&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709124&amp;idx=3&amp;sn=8a751a960bcca86dad234fc1f0b601df&amp;chksm=9722e8ceae630e50ac217ff60bf7cbc1e9829dc2d1625dc748138a7f0536bb882eea334d2c0e&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkCOVxC5Zh5LftZiccf7Bdiaxia8KFYPBN3ib7d22ibHM0z7a7Jf8TfrvjCIWX6SaicHI34icOgBk6Fiaefnw/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709124&amp;idx=3&amp;sn=8a751a960bcca86dad234fc1f0b601df&amp;chksm=9722e8ceae630e50ac217ff60bf7cbc1e9829dc2d1625dc748138a7f0536bb882eea334d2c0e&amp;scene=0&amp;xtrack=1#rd" target="_blank">稳住训练、跑出泛化：STAGE重写「自回归图像生成」的强化学习范式</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-09 23:48:39">发布日期：2025-10-09 23:48:39</time></div><p class="article-description">在扩散模型一家独大的时代，自回归文生图的潜力正被重新挖掘——它拥有更强的离散表征能力，却也更容易在强化学习阶段“失稳”。STAGE 在自回归（Autoregressive, AR）文生图模型上首次实现</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709124&amp;idx=3&amp;sn=8a751a960bcca86dad234fc1f0b601df&amp;chksm=9722e8ceae630e50ac217ff60bf7cbc1e9829dc2d1625dc748138a7f0536bb882eea334d2c0e&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709015&amp;idx=1&amp;sn=f76680bcd85054ecb02d6d5c5c9c0819&amp;chksm=97b334111ca626844d8a8e6a6b82257f489ed1f0937e6ce539410c95e46a395f496f54f7fd3f&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglNCcMajRxBktBd46thELiciaj3HCiaAyGyB7pIibhogESanibguAquQiapwPurq60MMtiaic6NRKdam7liaeA/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709015&amp;idx=1&amp;sn=f76680bcd85054ecb02d6d5c5c9c0819&amp;chksm=97b334111ca626844d8a8e6a6b82257f489ed1f0937e6ce539410c95e46a395f496f54f7fd3f&amp;scene=0&amp;xtrack=1#rd" target="_blank">无RLHF，7M小模型反超DeepSeek-R1：三星团队用递归思考取代规模堆叠</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-08 23:34:27">发布日期：2025-10-08 23:34:27</time></div><p class="article-description">在所有人都以为智能等同于规模的时代，三星研究团队用一个仅 7M 参数的微型神经网络，递归式地“先提答案、再反思改进”，在复杂推理基准 ARC-AGI 上击败了包括 DeepSeek-R1、Gemini</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709015&amp;idx=1&amp;sn=f76680bcd85054ecb02d6d5c5c9c0819&amp;chksm=97b334111ca626844d8a8e6a6b82257f489ed1f0937e6ce539410c95e46a395f496f54f7fd3f&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708997&amp;idx=1&amp;sn=678f7ce1043eb3fa2b5cd16d1d13ef4c&amp;chksm=97bffd4d98b27ef9c4bf708eb4ede7e6cbcfb0ad8b4eb5db8c7d4c98f7ee2e94bc5da8042386&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmcxy1mz2u0VFP9icMNWEXUUib52iaJKAJMgJ3nMeicfxEQyCM7IA2ia3VVt8HdL1CyBkMnRGsLm2QZ38Q/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708997&amp;idx=1&amp;sn=678f7ce1043eb3fa2b5cd16d1d13ef4c&amp;chksm=97bffd4d98b27ef9c4bf708eb4ede7e6cbcfb0ad8b4eb5db8c7d4c98f7ee2e94bc5da8042386&amp;scene=0&amp;xtrack=1#rd" target="_blank">告别梯度！Evolution Strategies全参微调挑战PPO/GRPO：更稳、更省、更好复现</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-07 19:03:35">发布日期：2025-10-07 19:03:35</time></div><p class="article-description">过去两年里，“后训练=RL”的观念几乎成了行业默认。很多团队把 PPO、GRPO 写进了自己的 Pipeline，并习惯性地在动作空间里做探索与优化。这篇论文则把镜头拉回到参数空间：作者将 Evolu</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708997&amp;idx=1&amp;sn=678f7ce1043eb3fa2b5cd16d1d13ef4c&amp;chksm=97bffd4d98b27ef9c4bf708eb4ede7e6cbcfb0ad8b4eb5db8c7d4c98f7ee2e94bc5da8042386&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708997&amp;idx=2&amp;sn=e2ffabb360e6926bcdf5fad776066335&amp;chksm=973131742549963c06489b989ad2f50c3efe0a7edd18348c8456ef7c728857696d4197afcc6f&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmcxy1mz2u0VFP9icMNWEXUUfYdWGmiboAHdItvmPnic1ZJWXxUUicNWibuHbSMTBOqFvAKXofRyX8YaxQ/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708997&amp;idx=2&amp;sn=e2ffabb360e6926bcdf5fad776066335&amp;chksm=973131742549963c06489b989ad2f50c3efe0a7edd18348c8456ef7c728857696d4197afcc6f&amp;scene=0&amp;xtrack=1#rd" target="_blank">NeurIPS 2025 | 北邮用“图+文”把人物检索拉满：自动合成数据 × 细粒度特征对齐</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-07 19:03:35">发布日期：2025-10-07 19:03:35</time></div><p class="article-description">在智能安防、失踪人口查找、公共场所人员溯源等实际场景中，我们往往需要结合「目标人物参考照片」和「文字描述」定位具体个体——比如用失踪者过往生活照，搭配“近期穿灰色连帽卫衣、戴黑色边框眼镜”的实时描述展</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708997&amp;idx=2&amp;sn=e2ffabb360e6926bcdf5fad776066335&amp;chksm=973131742549963c06489b989ad2f50c3efe0a7edd18348c8456ef7c728857696d4197afcc6f&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708957&amp;idx=1&amp;sn=4735d66301277b6b2dd1c0e4ac4a2d27&amp;chksm=972380b57c4d7e5aa092fc0fd3de67c014e87c4f3a9a517675baae6ff43f91f3916d1ebe2ea2&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmWoQgricShzibiaMj2GZnAve5KM1wwuHTcVd2YaUZjBKIFAjaZshaicEzxjGozRlAOuEOR2KlmADibGbw/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708957&amp;idx=1&amp;sn=4735d66301277b6b2dd1c0e4ac4a2d27&amp;chksm=972380b57c4d7e5aa092fc0fd3de67c014e87c4f3a9a517675baae6ff43f91f3916d1ebe2ea2&amp;scene=0&amp;xtrack=1#rd" target="_blank">自进化Agent的第三种可能：隐式记忆，不动模型参数，胜过GRPO</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-06 20:04:18">发布日期：2025-10-06 20:04:18</time></div><p class="article-description">当前，由大型语言模型（LLM）驱动的智能体（Agent）正引领着人工智能领域的变革。然而，智能体的记忆机制——无论是强制调整模型参数的“参数化记忆（Parametric Memory）”，还是将经验外</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708957&amp;idx=1&amp;sn=4735d66301277b6b2dd1c0e4ac4a2d27&amp;chksm=972380b57c4d7e5aa092fc0fd3de67c014e87c4f3a9a517675baae6ff43f91f3916d1ebe2ea2&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708957&amp;idx=2&amp;sn=ddf2cb465568896a1916926307cfd8bd&amp;chksm=97ea518e804ff25209298445972841b5b4ca00fa2bc1d34fb8664d4373e6dc24e87ac77ccdf0&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmWoQgricShzibiaMj2GZnAve5Fyr7iaKcibiaqU8Ya1vSYUuR4x9W8DaDBO95kb2icCU4RJClvQ1KkGUEyA/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708957&amp;idx=2&amp;sn=ddf2cb465568896a1916926307cfd8bd&amp;chksm=97ea518e804ff25209298445972841b5b4ca00fa2bc1d34fb8664d4373e6dc24e87ac77ccdf0&amp;scene=0&amp;xtrack=1#rd" target="_blank">真实数据、全链路、可复核：GenoMAS打造更可信的基因分析智能体</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-10-06 20:04:18">发布日期：2025-10-06 20:04:18</time></div><p class="article-description">在科学研究越来越依靠标准化精密计算手段的今天，用智能体技术来自动化加速科研的潜力让人心潮澎湃。但在现实使用中，无论是 Cursor 还是 Codex，这类智能体多作为辅助工具存在：每推进几步，仍需人工</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708957&amp;idx=2&amp;sn=ddf2cb465568896a1916926307cfd8bd&amp;chksm=97ea518e804ff25209298445972841b5b4ca00fa2bc1d34fb8664d4373e6dc24e87ac77ccdf0&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li></ul><div class="pagination"><a href="index_7.html" class="pagination-button pagination-prev">上一页</a><a href="index_9.html" class="pagination-button pagination-prev">下一页</a></div></body></html>