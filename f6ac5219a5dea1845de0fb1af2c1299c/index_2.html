<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="referrer" content="no-referrer"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>PaperWeekly</title><style>
            /* 导航栏样式 - 水平滑动 */
            .navigation {
                display: flex;
                justify-content: center;
                gap: 20px;
                padding: 20px 20px; /* 左右增加 padding，避免内容贴边 */
                border-bottom: 1px solid #eee;
                margin-bottom: 20px;

                overflow-x: auto; /* 关键：水平方向内容超出时显示滚动条 */
                -webkit-overflow-scrolling: touch; /* 为了在iOS设备上滚动更顺畅 */
                white-space: nowrap; /* 导航链接不换行，保持水平排列 */
                flex-wrap: nowrap; /* 确保 flex items 不换行 */
            }

            /* 隐藏滚动条 (可选，但通常为了美观会隐藏) */
            .navigation::-webkit-scrollbar {
                display: none; /* 隐藏 Chrome, Safari, Edge 滚动条 */
            }
            .navigation {
                -ms-overflow-style: none;  /* 隐藏 IE and Edge 滚动条 */
                scrollbar-width: none;  /* 隐藏 Firefox 滚动条 */
            }

            .navigation-link {
                text-decoration: none;
                color: #333;
                font-weight: bold;
                transition: color 0.3s;
                flex-shrink: 0; /* 确保导航链接不会被压缩 */
            }

            .navigation-link:hover {
                color: #007bff;
            }

            .article-list {
                list-style: none;
                padding: 0;
                max-width: 800px; /* 桌面端最大宽度保持不变 */
                margin: 20px auto;
            }
    
            .article-item {
                border-bottom: 1px solid #eee;
                padding: 20px;
                transition: background 0.3s;
                display: flex;
                align-items: stretch;
            }
    
            .article-item:hover {
                background: #f9f9f9;
            }
    
            .article-cover {
                width: 40%;
                max-width: 200px;
                margin-right: 20px;
                overflow: hidden;
                flex-shrink: 0;
                box-sizing: border-box;
                max-height: 150px;
            }
    
            .article-cover:hover img {
                transform: scale3d(1.1,1.1,1.1);
                -webkit-transition: all .5s ease-in-out;
                -moz-transition: all .5s ease-in-out;
                transition: all .5s ease-in-out;
                filter: alpha(Opacity=85);
                -moz-opacity: .85;
                opacity: .85
            }
    
            .article-cover img {
                width: 100%;
                height: 100%;
                object-fit: cover;
                display: block;
                transition: transform 0.3s ease-in-out;
                -webkit-transition: transform 0.3s ease-in-out;
                -moz-transition: transform 0.3s ease-in-out;
            }
    
            .article-content {
                flex: 1;
                width: 60%;
                box-sizing: border-box;
            }
    
            .article-title {
                font-size: 1.2em;
                margin: 0 0 10px;
            }
            
            .article-title a {
                color: #333;
                text-decoration: none;
                transition: color 0.3s;
                -webkit-transition: color 0.3s;
                -moz-transition: color 0.3s;
            }

            .article-title a:hover {
                color: #007bff;
                text-decoration: none;
            }
    
            .article-meta {
                color: #666;
                font-size: 0.9em;
                margin-bottom: 8px;
            }
    
            .article-author {
                margin-right: 15px;
            }
    
            .article-date {
                color: #999;
            }
    
            .article-description {
                color: #444;
                line-height: 1.6;
                margin: 10px 0;
                height: 48px;
                overflow: hidden;
                text-overflow: ellipsis;
                display: -webkit-box;
                -webkit-line-clamp: 2;
                -webkit-box-orient: vertical;
            }
    
            .article-link {
                color: #007bff;
                text-decoration: none;
                font-size: 0.9em;
            }
    
            /* 分页按钮样式 */
            .pagination {
                display: flex;
                justify-content: center;
                margin-top: 20px;
                margin-bottom: 20px;
            }
    
            .pagination-button {
                display: inline-block;
                padding: 10px 20px;
                margin: 0 10px;
                border: 1px solid #ccc;
                border-radius: 5px;
                background-color: #fff;
                color: #333;
                text-decoration: none;
                cursor: pointer;
                transition: background-color 0.3s, border-color 0.3s, color 0.3s;
            }
    
            .pagination-button:hover {
                background-color: #f0f0f0;
                border-color: #bbb;
            }
    
            .pagination-button:disabled {
                background-color: #eee;
                color: #999;
                border-color: #ddd;
                cursor: not-allowed;
            }
    
            /*  Media Queries - 针对小屏幕设备优化  */
            @media (max-width: 768px) {  /*  2. 使用 Media Query，针对屏幕宽度小于 768px 的设备应用以下样式  */
                /* 手机端导航栏样式 (水平滑动) */
                .navigation {
                    justify-content: left;
                    gap: 10px; /* 减小导航链接之间的间距 */
                    padding: 10px 10px; /* 减小导航栏的左右和上下内边距 */
                    margin-bottom: 15px; /* 减小导航栏下外边距 */
                }

                .navigation-link {
                    font-size: 0.9rem; /* 可以适当减小导航链接字体大小 */
                    padding: 5px 10px; /* 可以适当减小导航链接内边距 */
                }

                .article-list {
                    max-width: 100%;  /*  手机上文章列表宽度撑满屏幕  */
                    margin-left: 10px;   /*  左右留出少量边距，避免内容紧贴屏幕边缘  */
                    margin-right: 10px;
                }
    
                .article-item {
                    flex-direction: column; /*  手机上文章条目垂直排列  */
                    padding: 15px;       /*  略微减小 article-item 的内边距  */
                }
    
                .article-cover {
                    width: 100%;        /*  手机上封面宽度撑满容器  */
                    max-width: none;      /*  移除最大宽度限制  */
                    margin-right: 0;      /*  移除右侧外边距  */
                    margin-bottom: 10px;   /*  底部增加外边距，与文字内容分隔  */
                    max-height: none;      /*  移除最大高度限制，让图片根据自身比例显示，或者可以设置一个合适的 max-height */
                }
    
                .article-content {
                    width: 100%;        /*  手机上内容区域宽度撑满容器  */
                }
    
                .article-title {
                    font-size: 1.1em;   /*  略微减小标题字体大小  */
                }
    
                .article-description {
                    font-size: 0.95em;  /*  略微减小描述字体大小  */
                    height: auto;        /*  手机上取消固定高度，让描述文字完整显示，或者根据需要调整行数限制 */
                    -webkit-line-clamp: unset; /* 取消行数限制 */
                }
    
                .article-meta {
                    font-size: 0.85em;  /*  略微减小 meta 信息字体大小  */
                }
    
                .pagination-button {
                    padding: 8px 16px;   /*  略微减小分页按钮内边距，但保持可点击区域  */
                    margin: 0 5px;      /*  略微减小按钮间距  */
                }

                /* 取消手机端 article-cover 的悬浮放大效果 */
                .article-cover:hover img {
                    transform: scale3d(1.0,1,0,1.0); /* 或者 transform: none;  都可以 */
                }
            }
                    </style></head><body><nav class="navigation"><a class="navigation-link" href="/">全部</a><a class="navigation-link" href="/sec/">安全</a><a class="navigation-link" href="/dev/">开发</a><a class="navigation-link" href="/new/">新闻</a><a class="navigation-link" href="/digital/">数码</a><a class="navigation-link" href="/photography/">摄影</a><a class="navigation-link" href="/car/">汽车</a><a class="navigation-link" href="/beijing/">北京</a><a class="navigation-link" href="/ai/">AI</a><a class="navigation-link" href="/it/">IT</a><a class="navigation-link" href="/other/">其他</a></nav><ul class="article-list"><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716867&amp;idx=2&amp;sn=26853cf346d806361c20216404676d71&amp;chksm=9741568c245f428d968dbe025b52d8fc6aad46f0ac50b80ddfef6d01bc50bfdbd0e7bccc917a&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmF1XlYThtkutkWJwcyL0H093OZReMmU7iaqZwqYKDzKhVkz2VdibEl4Gqlia9E0fs3wH8wjxotRZEbw/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716867&amp;idx=2&amp;sn=26853cf346d806361c20216404676d71&amp;chksm=9741568c245f428d968dbe025b52d8fc6aad46f0ac50b80ddfef6d01bc50bfdbd0e7bccc917a&amp;scene=0&amp;xtrack=1#rd" target="_blank">超越RAG！首篇Deep Research综述来了：大模型正向“全栈科学家”进化</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-15 21:01:54">发布日期：2026-01-15 21:01:54</time></div><p class="article-description">近年来，大模型的应用正从对话与创意写作，走向更加开放、复杂的研究型问题。尽管以检索增强生成（RAG）为代表的方法缓解了知识获取瓶颈，但其静态的 “一次检索 + 一次生成” 范式，难以支撑多步推理与长期</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716867&amp;idx=2&amp;sn=26853cf346d806361c20216404676d71&amp;chksm=9741568c245f428d968dbe025b52d8fc6aad46f0ac50b80ddfef6d01bc50bfdbd0e7bccc917a&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716812&amp;idx=1&amp;sn=3852505d995e2852a9b0f1473f1eefd9&amp;chksm=972176ce5044dd93e87fcbb86a57d47afa067e691fbd335ce674ea5fb63f9e5fa6beb186bc10&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkBxFSia6STl2jhnRKmzicaiaCP1sHWGDE3JLWyX87ctl3HPAbMUGrmr4tFJA7OiaFyxk8oRaaDW2HeeA/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716812&amp;idx=1&amp;sn=3852505d995e2852a9b0f1473f1eefd9&amp;chksm=972176ce5044dd93e87fcbb86a57d47afa067e691fbd335ce674ea5fb63f9e5fa6beb186bc10&amp;scene=0&amp;xtrack=1#rd" target="_blank">GPT-5、Gemini 3 Pro谁更懂风控？首个信贷多模态评测基准FCMBench出炉</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-14 18:05:34">发布日期：2026-01-14 18:05:34</time></div><p class="article-description">4043 张物理重拍样本，打破信贷 AI 的数据死锁。在多模态大模型不断刷新各种通用榜单的今天，金融信贷却始终是一个让 SOTA 模型感到力不从心的隐秘角落。这并非因为模型不够聪明，而是整个行业长期陷</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716812&amp;idx=1&amp;sn=3852505d995e2852a9b0f1473f1eefd9&amp;chksm=972176ce5044dd93e87fcbb86a57d47afa067e691fbd335ce674ea5fb63f9e5fa6beb186bc10&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716812&amp;idx=2&amp;sn=b760f7ffdda80a8151a6f30c72f85fa9&amp;chksm=97c4800d4c0ef97aa3bcaef0fd8673cec0686802d6603f4f6ba2d0380c9a99953915eb70cb6f&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkBxFSia6STl2jhnRKmzicaiaCATgxpqTp2iaX116BMN3cj0TsH9X1eGIfw6TbWFMMPcyKHxLQJpu4LnQ/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716812&amp;idx=2&amp;sn=b760f7ffdda80a8151a6f30c72f85fa9&amp;chksm=97c4800d4c0ef97aa3bcaef0fd8673cec0686802d6603f4f6ba2d0380c9a99953915eb70cb6f&amp;scene=0&amp;xtrack=1#rd" target="_blank">AAAI 2026 | AutoLink首创自主扩展模式链接，突破大规模Text-to-SQL瓶颈</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-14 18:05:34">发布日期：2026-01-14 18:05:34</time></div><p class="article-description">Text-to-SQL（又称 NL2SQL）是一项将用户的自然语言问题自动转换为 SQL 查询的任务，其目标是让不懂 SQL 的用户，也能直接通过自然语言访问数据库。例如，用户只需问一句：“近三年每个</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716812&amp;idx=2&amp;sn=b760f7ffdda80a8151a6f30c72f85fa9&amp;chksm=97c4800d4c0ef97aa3bcaef0fd8673cec0686802d6603f4f6ba2d0380c9a99953915eb70cb6f&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716764&amp;idx=1&amp;sn=e3b35a3d1d06f2c00613b807ddfee343&amp;chksm=97f27eec7c6af4a1849d365369445cd00d30d205d66db092fa7cc1f54aac88f6292f0a151264&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgk4kdK0jXILJ0pGib4g3LGlsjmOibY8LC5PicbDuwTUUw8aaHuoqibBsVMGxQO0kHkYMRESGdzjkQia52A/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716764&amp;idx=1&amp;sn=e3b35a3d1d06f2c00613b807ddfee343&amp;chksm=97f27eec7c6af4a1849d365369445cd00d30d205d66db092fa7cc1f54aac88f6292f0a151264&amp;scene=0&amp;xtrack=1#rd" target="_blank">殊途同归的第三条道路：DeepSeek用数学推导，撞上了Google的工程直觉</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-13 18:11:51">发布日期：2026-01-13 18:11:51</time></div><p class="article-description">Gemma 3n 的技术黑盒，被 DeepSeek 的两篇新论文解开了。Google 在 2025 年 6 月发布 Gemma 3n 的时候，业界的反应分化极其严重。工程界惊叹于它在端侧设备上的极致压</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716764&amp;idx=1&amp;sn=e3b35a3d1d06f2c00613b807ddfee343&amp;chksm=97f27eec7c6af4a1849d365369445cd00d30d205d66db092fa7cc1f54aac88f6292f0a151264&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716764&amp;idx=2&amp;sn=a4dda29a9b9dcc5d7d5468893af82a44&amp;chksm=9718c8206854cf703c1db752aeeb89c12d091bba11ab530a075588d5d415d809ba0dd75c0905&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgk4kdK0jXILJ0pGib4g3LGlsu0sasV3WKO8eovgbdKT9kf4ukU9WqTHpibI4vkJHGvNR5SGloCKg8Ew/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716764&amp;idx=2&amp;sn=a4dda29a9b9dcc5d7d5468893af82a44&amp;chksm=9718c8206854cf703c1db752aeeb89c12d091bba11ab530a075588d5d415d809ba0dd75c0905&amp;scene=0&amp;xtrack=1#rd" target="_blank">AAAI 2026 | 不再盲从弱标签！让强模型自主选择，阿里通义探索超级对齐新范式</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-13 18:11:51">发布日期：2026-01-13 18:11:51</time></div><p class="article-description">TL;DR：本研究提出了一种基于选择的弱监督对齐强模型方法，探索了强模型自主选择利用弱标签的解决超级对齐问题新范式。论文标题：Selective Weak-to-Strong Generalizati</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716764&amp;idx=2&amp;sn=a4dda29a9b9dcc5d7d5468893af82a44&amp;chksm=9718c8206854cf703c1db752aeeb89c12d091bba11ab530a075588d5d415d809ba0dd75c0905&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716706&amp;idx=1&amp;sn=861ccba253718964b98e2d76503eb879&amp;chksm=97f63bbf2cc1d45cb08147bb38584afec5ecc40c9ec28c5fbfcd0d10138bd8aacebc99b0084d&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnQzgIH4GANibQTcfclWXc9UibJjzGCXbicRE1QrgbWsS5eRvSp1jZwAmNZ1znmghq6JXgibyrpyaRnyw/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716706&amp;idx=1&amp;sn=861ccba253718964b98e2d76503eb879&amp;chksm=97f63bbf2cc1d45cb08147bb38584afec5ecc40c9ec28c5fbfcd0d10138bd8aacebc99b0084d&amp;scene=0&amp;xtrack=1#rd" target="_blank">预训练数据太差怎么办？Bengio团队引入显式贝叶斯，无梯度实现In-Context RL</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-12 20:36:01">发布日期：2026-01-12 20:36:01</time></div><p class="article-description">单纯拉长上下文并不能自动涌现强化学习能力，引入显式贝叶斯推断才是破局关键。在 In-Context RL 的研究热潮中，往往存在一种惯性思维，认为只要把 Transformer 做大，把上下文窗口拉长</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716706&amp;idx=1&amp;sn=861ccba253718964b98e2d76503eb879&amp;chksm=97f63bbf2cc1d45cb08147bb38584afec5ecc40c9ec28c5fbfcd0d10138bd8aacebc99b0084d&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716706&amp;idx=2&amp;sn=809d1497d21be1545ec346143d05c924&amp;chksm=9735924552c0099536e0e4b2d7d1fdecf7ebf7bc0e0435e2a967bf739055be69a37d19d26a27&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnQzgIH4GANibQTcfclWXc9URFSWEEQatOUleMhLqCOEiclJsPviaYE1157AvLQLmxqPsNmhCicdt3p8g/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716706&amp;idx=2&amp;sn=809d1497d21be1545ec346143d05c924&amp;chksm=9735924552c0099536e0e4b2d7d1fdecf7ebf7bc0e0435e2a967bf739055be69a37d19d26a27&amp;scene=0&amp;xtrack=1#rd" target="_blank">LLM竟藏多重策略？自动化所 × 腾讯揭示大模型RL多策略博弈新机制</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-12 20:36:01">发布日期：2026-01-12 20:36:01</time></div><p class="article-description">当前，大模型+强化学习成为 AI 领域极为热门的研究。现有的强化学习（RL）方法通常将大语言模型（LLM）视为一个单一的整体策略进行优化，主要的算法优化集中在表层的奖励设计等方面，却忽略了模型内部复杂</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716706&amp;idx=2&amp;sn=809d1497d21be1545ec346143d05c924&amp;chksm=9735924552c0099536e0e4b2d7d1fdecf7ebf7bc0e0435e2a967bf739055be69a37d19d26a27&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716639&amp;idx=1&amp;sn=8f16cb94de76b1d7265674beb7558668&amp;chksm=9713590211aaacf39ecd81f6f9d90bbdf05e932a26e53e05494e0c40236353af7ed7cfbf9f6b&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglN94QowbsdJlgiayHUibbxLQHbursqEqnDxgftTvtwwXb6U6uaa8nhdaF02pwZZU3a4dpsrb8osqoA/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716639&amp;idx=1&amp;sn=8f16cb94de76b1d7265674beb7558668&amp;chksm=9713590211aaacf39ecd81f6f9d90bbdf05e932a26e53e05494e0c40236353af7ed7cfbf9f6b&amp;scene=0&amp;xtrack=1#rd" target="_blank">OpenAI理论失效、μP失灵？邱锡鹏团队重新定义预训练两大核心超参</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-11 10:02:43">发布日期：2026-01-11 10:02:43</time></div><p class="article-description">WSD 时代旧经验失效？复旦团队重塑 Scaling Law，让超参设置有章可循。在大模型预训练这项高昂的系统工程中，Batch Size (BS) 和 Learning Rate (LR) 是两个至</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716639&amp;idx=1&amp;sn=8f16cb94de76b1d7265674beb7558668&amp;chksm=9713590211aaacf39ecd81f6f9d90bbdf05e932a26e53e05494e0c40236353af7ed7cfbf9f6b&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716639&amp;idx=2&amp;sn=10a5dc6768b0aa3a13e83d3b52ac5228&amp;chksm=97552634c7aec01d023196b6b846419ff3d1ddac22307e09709d084e029303adbdad77f290ed&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglN94QowbsdJlgiayHUibbxLQBEFcO6oTVzN9icQQ7FBJjqicCmIVQaNGyTBzH52NsJ5gbRUxo7F13OIQ/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716639&amp;idx=2&amp;sn=10a5dc6768b0aa3a13e83d3b52ac5228&amp;chksm=97552634c7aec01d023196b6b846419ff3d1ddac22307e09709d084e029303adbdad77f290ed&amp;scene=0&amp;xtrack=1#rd" target="_blank">仅需8张4090！影石Insta360开源DA360，低成本刷新全景深度估计SOTA</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-11 10:02:43">发布日期：2026-01-11 10:02:43</time></div><p class="article-description">Insta360 Research 团队提出 DA360 模型，成功解决了全景深度估计在真实开放世界中的两大核心难题：零样本泛化能力不足与尺度不一致性。该模型通过创新的平移参数学习与环形填充技术，并延</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716639&amp;idx=2&amp;sn=10a5dc6768b0aa3a13e83d3b52ac5228&amp;chksm=97552634c7aec01d023196b6b846419ff3d1ddac22307e09709d084e029303adbdad77f290ed&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716561&amp;idx=1&amp;sn=c8af2bb536d84d4428b985956a5c207e&amp;chksm=97d0c2b0295fac92f23e774db33e6b24499ff69e6ee37c3fe9c888375256f6b0d14f09c743e6&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgliaRd3B92u4vHT1HnHFKYJH6SJAf3kxuyMehe7X1ekYNDQ6qwEroP2rO5TjVCx85FRjKzKHlEWqHg/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716561&amp;idx=1&amp;sn=c8af2bb536d84d4428b985956a5c207e&amp;chksm=97d0c2b0295fac92f23e774db33e6b24499ff69e6ee37c3fe9c888375256f6b0d14f09c743e6&amp;scene=0&amp;xtrack=1#rd" target="_blank">ICML 2026投稿开启：先别急着提交，详解史上最严的“连坐拒稿”机制</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-09 12:16:43">发布日期：2026-01-09 12:16:43</time></div><p class="article-description">刚肝完 ACL 别急着投 ICML，先读完这份避坑指南。就在昨天，ICML 2026 的投稿系统已正式对外开放。对于刚结束前两天 ACL 投稿的同学来说，现在或许正准备一鼓作气，将手头剩下的工作，或者</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716561&amp;idx=1&amp;sn=c8af2bb536d84d4428b985956a5c207e&amp;chksm=97d0c2b0295fac92f23e774db33e6b24499ff69e6ee37c3fe9c888375256f6b0d14f09c743e6&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716561&amp;idx=2&amp;sn=b52fc1a9c60324932a45ab5d274a9560&amp;chksm=978dc0ba0a10dce5fc7e36a7cd3c483893330fd499f14a2ab27da8d3c90a28ddbad7cd6218ea&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgliaRd3B92u4vHT1HnHFKYJH2GWcoibO9TpCo1Dm9bAiaeJlkCEgxoFCXtk6J08LHZ5QS8HiaXuQibu9LA/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716561&amp;idx=2&amp;sn=b52fc1a9c60324932a45ab5d274a9560&amp;chksm=978dc0ba0a10dce5fc7e36a7cd3c483893330fd499f14a2ab27da8d3c90a28ddbad7cd6218ea&amp;scene=0&amp;xtrack=1#rd" target="_blank">美团AAAI 2026中稿精选：破解过度思考与退火Scaling Law | 直播预告</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-09 12:16:43">发布日期：2026-01-09 12:16:43</time></div><p class="article-description">AAAI 是人工智能领域顶级的国际学术会议，本文精选了【美团技术团队】被收录的8篇学术论文（附下载链接），覆盖大模型推理、 退火策略、过程奖励模型、强化学习、视觉文本渲染等多个技术领域，欢迎一起交流学</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716561&amp;idx=2&amp;sn=b52fc1a9c60324932a45ab5d274a9560&amp;chksm=978dc0ba0a10dce5fc7e36a7cd3c483893330fd499f14a2ab27da8d3c90a28ddbad7cd6218ea&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716513&amp;idx=1&amp;sn=d9c9b248da7a28d6ff9399404ea0ab04&amp;chksm=97f632fd1945fda250dab20271d328dc2e45bf93f564762724082ff5b2113169274b8171649b&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgk2JdYDmyicVDrt8xzrlxPNTNbZQ5sEcJm4kzkkP6Opge7FQtnsAzJplxaN3BdNsK5XBicOL9tTgicIg/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716513&amp;idx=1&amp;sn=d9c9b248da7a28d6ff9399404ea0ab04&amp;chksm=97f632fd1945fda250dab20271d328dc2e45bf93f564762724082ff5b2113169274b8171649b&amp;scene=0&amp;xtrack=1#rd" target="_blank">谁说思维链越长越好？Yuan3.0 Flash开源：砍掉70%无效token，重构推理范式</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-08 13:10:22">发布日期：2026-01-08 13:10:22</time></div><p class="article-description">首创「反思抑制」机制，让大模型学会在答对的那一刻果断停下。过去一年，大模型推理能力的进化几乎沿着一条单向路径前进：更复杂的推理过程、更长的思维链、更“像人类”的自我反思。在数学和科学推理等 bench</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716513&amp;idx=1&amp;sn=d9c9b248da7a28d6ff9399404ea0ab04&amp;chksm=97f632fd1945fda250dab20271d328dc2e45bf93f564762724082ff5b2113169274b8171649b&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716513&amp;idx=2&amp;sn=d21f65deaebc48aa53d1488d15f1bd7c&amp;chksm=970c4db06a2c23aaa2783da4a1fbdc300f76d45ccc033259800a59ed32319440b3c6438156d5&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkO7yJELJPKBckFu8oMaNgGZgpV75yiah8IXibsejXZlWDn7SeAyAHlnZE6BfSYB8nia1GA1mCjvSaJg/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716513&amp;idx=2&amp;sn=d21f65deaebc48aa53d1488d15f1bd7c&amp;chksm=970c4db06a2c23aaa2783da4a1fbdc300f76d45ccc033259800a59ed32319440b3c6438156d5&amp;scene=0&amp;xtrack=1#rd" target="_blank">AAAI 2026 | 别再盲目采样了！OptScale实现概率最优停止，token消耗减半</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-08 13:10:22">发布日期：2026-01-08 13:10:22</time></div><p class="article-description">多采样 = 更强推理？  在 Inference-time Scaling 成为大模型“最后一公里”标配之后，这几乎成了一条默认公理。从 Self-Consistency、Best-of-N，到 De</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716513&amp;idx=2&amp;sn=d21f65deaebc48aa53d1488d15f1bd7c&amp;chksm=970c4db06a2c23aaa2783da4a1fbdc300f76d45ccc033259800a59ed32319440b3c6438156d5&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716450&amp;idx=1&amp;sn=2da55051e0e159009091ee61c2bea01e&amp;chksm=971628a60d143703ff235a21b07505ebc2067768f436f67433648ede8c693013e66b76e4f609&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgk2JdYDmyicVDrt8xzrlxPNTuD3lhUkmBTyTFCLcgueEl1ITM3YUXwUtZkhzTib90GFt01vKfUOYVWw/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716450&amp;idx=1&amp;sn=2da55051e0e159009091ee61c2bea01e&amp;chksm=971628a60d143703ff235a21b07505ebc2067768f436f67433648ede8c693013e66b76e4f609&amp;scene=0&amp;xtrack=1#rd" target="_blank">告别Scaling暴力美学：正如Ilya预言，算力不再是唯一的答案</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-07 14:04:25">发布日期：2026-01-07 14:04:25</time></div><p class="article-description">Scaling 的黄金十年已过，我们正重新踏入一片充满“惊奇与未知”（Wonder and Discovery）的探索之地。这是 OpenAI 前首席科学家 Ilya Sutskever 在 2025</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716450&amp;idx=1&amp;sn=2da55051e0e159009091ee61c2bea01e&amp;chksm=971628a60d143703ff235a21b07505ebc2067768f436f67433648ede8c693013e66b76e4f609&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716450&amp;idx=2&amp;sn=82a790e3c81879656749a97b0c3a3fde&amp;chksm=97fb6b77efba4401cc04adfb3a55f5beffc84cabf71382ddbd666ee968fc666e9534f464243a&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgk2JdYDmyicVDrt8xzrlxPNTkyfHhJKIIWGgJDuXwhVc66GEibicrjnAaK7H1BL4fyOyWstVAA259GaQ/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716450&amp;idx=2&amp;sn=82a790e3c81879656749a97b0c3a3fde&amp;chksm=97fb6b77efba4401cc04adfb3a55f5beffc84cabf71382ddbd666ee968fc666e9534f464243a&amp;scene=0&amp;xtrack=1#rd" target="_blank">CVPR 2025 | Mamba与局部注意力首次碰撞，SegMAN刷新语义分割SOTA</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-07 14:04:25">发布日期：2026-01-07 14:04:25</time></div><p class="article-description">摘要香港大学计算和数据科学学院俞益洲教授（https://i.cs.hku.hk/~yzyu/index.html）及其研究团队提出新型语义分割框架 SegMAN，包含全球首个融合动态状态空间模型（M</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716450&amp;idx=2&amp;sn=82a790e3c81879656749a97b0c3a3fde&amp;chksm=97fb6b77efba4401cc04adfb3a55f5beffc84cabf71382ddbd666ee968fc666e9534f464243a&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716385&amp;idx=1&amp;sn=4889b56153225bed55c20f88595c2be0&amp;chksm=972b078c2ad719b1621167bd5e9ac4fdf212fdf14a008852736735e6886959722fd8cc3a0d36&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgm77InacOVfoHae9OBNuMTZq7acMLh8pwjtBvzCsgvZwMSJguLD0iaMJoFFcGxs1uMol3v1zmIBq5A/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716385&amp;idx=1&amp;sn=4889b56153225bed55c20f88595c2be0&amp;chksm=972b078c2ad719b1621167bd5e9ac4fdf212fdf14a008852736735e6886959722fd8cc3a0d36&amp;scene=0&amp;xtrack=1#rd" target="_blank">别让 loss.backward() 成为黑盒：手推Transformer全链路梯度（含LoRA）</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-06 14:01:26">发布日期：2026-01-06 14:01:26</time></div><p class="article-description">硬核拆解 Transformer 梯度黑盒，从 Softmax 守恒律到 LoRA 微分实战。在深度学习框架高度封装的今天， loss.backward() 是一行魔法代码，它掩盖了计算图中数以亿计参</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716385&amp;idx=1&amp;sn=4889b56153225bed55c20f88595c2be0&amp;chksm=972b078c2ad719b1621167bd5e9ac4fdf212fdf14a008852736735e6886959722fd8cc3a0d36&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716385&amp;idx=2&amp;sn=1e59687f6012c01ce6f3e48621bd5e40&amp;chksm=97845c51f4b0e500145dc6c0a74901984621df660cda69b3fef5eb1d622a7be62232fd031a56&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgm77InacOVfoHae9OBNuMTZnkquUWaiao07lyLNzjb1lIGq8nqwObUZtR28roLA8nLHY4vpB5C2oBg/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716385&amp;idx=2&amp;sn=1e59687f6012c01ce6f3e48621bd5e40&amp;chksm=97845c51f4b0e500145dc6c0a74901984621df660cda69b3fef5eb1d622a7be62232fd031a56&amp;scene=0&amp;xtrack=1#rd" target="_blank">150k数据反超Qwen-2509！支持10图输入，MICo-150k刷新多图融合SOTA</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-06 14:01:26">发布日期：2026-01-06 14:01:26</time></div><p class="article-description">项目主页：https://mico-150k.github.io/GitHub：https://github.com/A113N-W3I/MICo-150KOnline Demo：https://hu</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716385&amp;idx=2&amp;sn=1e59687f6012c01ce6f3e48621bd5e40&amp;chksm=97845c51f4b0e500145dc6c0a74901984621df660cda69b3fef5eb1d622a7be62232fd031a56&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716309&amp;idx=1&amp;sn=bce0223da5c95147c5c021b7d0120f95&amp;chksm=97f8289f087367d650937a290b442c72fc0d9b8ebfc8bf1f3457a0808a1de41076bf0441b163&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnnMG4SmDAIVibKDWISlt7Edm4d28of5C5nzRRIMoyaubbbhUAprGtQWnXvgv3psqdumXmuS0W5e1A/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716309&amp;idx=1&amp;sn=bce0223da5c95147c5c021b7d0120f95&amp;chksm=97f8289f087367d650937a290b442c72fc0d9b8ebfc8bf1f3457a0808a1de41076bf0441b163&amp;scene=0&amp;xtrack=1#rd" target="_blank">Vibe Researching来了！斯坦福教授实测：1小时自动复现PNAS论文</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-05 14:34:38">发布日期：2026-01-05 14:34:38</time></div><p class="article-description">别只盯着 Vibe Coding 了，Vibe Researching 才是对传统科研的降维打击。当 Vibe Coding 正在改变代码生成的范式时，斯坦福政治经济学教授 Andrew B. Hal</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716309&amp;idx=1&amp;sn=bce0223da5c95147c5c021b7d0120f95&amp;chksm=97f8289f087367d650937a290b442c72fc0d9b8ebfc8bf1f3457a0808a1de41076bf0441b163&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716309&amp;idx=2&amp;sn=5bed765fb3b34730fb0d9f37b02e31a8&amp;chksm=974321e753ba3c1046af18af621620554b3c21c320377096ac61147f319e4ae20e529c67025a&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnnMG4SmDAIVibKDWISlt7EdIcQqJVtMAnuBWLD5iaianVy35gF4PsK6iaA79FpUKt7XmYZYObJ5wfkww/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716309&amp;idx=2&amp;sn=5bed765fb3b34730fb0d9f37b02e31a8&amp;chksm=974321e753ba3c1046af18af621620554b3c21c320377096ac61147f319e4ae20e529c67025a&amp;scene=0&amp;xtrack=1#rd" target="_blank">大模型也能「千人千面」？UIUC团队提出个性化LLM路由新框架</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-05 14:34:38">发布日期：2026-01-05 14:34:38</time></div><p class="article-description">随着大语言模型（LLM）的快速发展，我们正进入一个“模型选择”本身变得越来越复杂的时代。一方面，大模型数量不断增加，不同模型在性能、推理成本以及回答风格上差异显著。另一方面，在真实应用场景中，用户之间</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716309&amp;idx=2&amp;sn=5bed765fb3b34730fb0d9f37b02e31a8&amp;chksm=974321e753ba3c1046af18af621620554b3c21c320377096ac61147f319e4ae20e529c67025a&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716247&amp;idx=1&amp;sn=584edb6041579a68d396bb9a3f0c278f&amp;chksm=97ffa84c96766ed87c4739062912cdbb3f2b1e35fb90d912b2c592dd288e2c8bef1124a23bbb&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglCfnY2AWCQiaSXiabFbfl6bQ3TeNvWuXL3ia5p0npcqDETvLI479phoSHRicvcUlBQh3Pwzcq0cmJaFQ/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716247&amp;idx=1&amp;sn=584edb6041579a68d396bb9a3f0c278f&amp;chksm=97ffa84c96766ed87c4739062912cdbb3f2b1e35fb90d912b2c592dd288e2c8bef1124a23bbb&amp;scene=0&amp;xtrack=1#rd" target="_blank">别再把KL散度加进loss了！Bengio团队实证：回归Reward才是无偏正解</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-04 14:10:04">发布日期：2026-01-04 14:10:04</time></div><p class="article-description">全网都在卷 RLVR，但 Bengio 团队刚泼了盆冷水。DeepSeek-R1 的爆火让 RLVR 成为当下大模型后训练的绝对主流。无论是 PPO 还是近期大热的 GRPO，核心逻辑都是一致的：在最</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716247&amp;idx=1&amp;sn=584edb6041579a68d396bb9a3f0c278f&amp;chksm=97ffa84c96766ed87c4739062912cdbb3f2b1e35fb90d912b2c592dd288e2c8bef1124a23bbb&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716247&amp;idx=2&amp;sn=401d2a841eb11c34c48fd643eccee479&amp;chksm=9748905958ac7024f1249c8c3640db2362bb9d46d5b9aed70d95a26c850f72e31c9e32f13539&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglCfnY2AWCQiaSXiabFbfl6bQ770iaG2iaZZSbxIV7jhIbDmsdjfeuEPKicBCAZHZ7PcjNsib9V8Bk60nWw/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716247&amp;idx=2&amp;sn=401d2a841eb11c34c48fd643eccee479&amp;chksm=9748905958ac7024f1249c8c3640db2362bb9d46d5b9aed70d95a26c850f72e31c9e32f13539&amp;scene=0&amp;xtrack=1#rd" target="_blank">爆肝96页！NUS联合哈佛发布医疗智能体重磅综述，28万字+300篇文献梳理</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-04 14:10:04">发布日期：2026-01-04 14:10:04</time></div><p class="article-description">©PaperWeekly 原创· 作者 | 钱云航单位 | 新加坡国立大学医学智能体面临着数据隐私和安全、系统的互操作性、临床决策的透明性，准确性和可靠性等关键问题，对患者的健康安全构成严重威胁。针对</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716247&amp;idx=2&amp;sn=401d2a841eb11c34c48fd643eccee479&amp;chksm=9748905958ac7024f1249c8c3640db2362bb9d46d5b9aed70d95a26c850f72e31c9e32f13539&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716168&amp;idx=1&amp;sn=71d78876c52422c64f6d5f36bd240090&amp;chksm=971edbd252109deb6a9498d5909f44a202379885cddc0f45e349db2e89320b21b4cd1e3eaaee&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmokAvT7IRlmhoUvdv66Gu2rckQg3V40PRBRU4t5KKkl0AVRHsG3lCWJiamicpOqFqZVAvicp4Ng5Xfg/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716168&amp;idx=1&amp;sn=71d78876c52422c64f6d5f36bd240090&amp;chksm=971edbd252109deb6a9498d5909f44a202379885cddc0f45e349db2e89320b21b4cd1e3eaaee&amp;scene=0&amp;xtrack=1#rd" target="_blank">2026年的大模型范式变了：告别KV Cache爆炸，递归语言模型才是未来？</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-03 20:09:01">发布日期：2026-01-03 20:09:01</time></div><p class="article-description">2026 年的 AI 范式，或许已悄然剧变。在过去的一年里，我们目睹了上下文窗口（Context Window）的疯狂内卷，从 128k 到 1M 再到 10M。然而，这种基于 Transformer</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716168&amp;idx=1&amp;sn=71d78876c52422c64f6d5f36bd240090&amp;chksm=971edbd252109deb6a9498d5909f44a202379885cddc0f45e349db2e89320b21b4cd1e3eaaee&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716168&amp;idx=2&amp;sn=f6657bafb773ea298f22b11fc7fced22&amp;chksm=974abebbda022d443e0ce43e2e9e783480af89a60735a98aac285fe2add28f950ad7ad5daa15&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmokAvT7IRlmhoUvdv66Gu2m8vNeTh8hwibOzpn4LYxAWibzekbwTX0lgTyu6XxbhRUa1R38rfkBlUA/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716168&amp;idx=2&amp;sn=f6657bafb773ea298f22b11fc7fced22&amp;chksm=974abebbda022d443e0ce43e2e9e783480af89a60735a98aac285fe2add28f950ad7ad5daa15&amp;scene=0&amp;xtrack=1#rd" target="_blank">AAAI 2026 | 格式即先验：量化和分析大语言模型在异构数据中的偏见</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-03 20:09:01">发布日期：2026-01-03 20:09:01</time></div><p class="article-description">随着大语言模型（Large Language Models，LLMs）在问答、推理和决策支持等任务中的广泛应用，越来越多的系统开始引入外部知识以缓解幻觉问题并提升推理能力。这些外部知识通常以多种异构格</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716168&amp;idx=2&amp;sn=f6657bafb773ea298f22b11fc7fced22&amp;chksm=974abebbda022d443e0ce43e2e9e783480af89a60735a98aac285fe2add28f950ad7ad5daa15&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716108&amp;idx=1&amp;sn=9557b1b31d99b433d0d7f501aed89794&amp;chksm=9768f4b53ab99c9554a230dc7fb44e55a7c85bc2060acea6f3fbee32c3b02636a65010783f64&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgn4s8NrDm8UWA30XQCqjZAp38aGCcvlugcO5W2t72hjI5l95zFGdYojelSH7oH3hcOicC0lPKiabnKg/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716108&amp;idx=1&amp;sn=9557b1b31d99b433d0d7f501aed89794&amp;chksm=9768f4b53ab99c9554a230dc7fb44e55a7c85bc2060acea6f3fbee32c3b02636a65010783f64&amp;scene=0&amp;xtrack=1#rd" target="_blank">字节提出的“Hyper-Connections”，被DeepSeek救活了？</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-02 13:51:40">发布日期：2026-01-02 13:51:40</time></div><p class="article-description">当字节的 idea 遇上 DeepSeek 的数学洁癖。DeepSeek 似乎养成了一个习惯，专挑节假日给大家上强度。当大家正忙着庆祝新年时，他们悄然在 arXiv 上发布了一篇硬核论文。论文标题：m</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716108&amp;idx=1&amp;sn=9557b1b31d99b433d0d7f501aed89794&amp;chksm=9768f4b53ab99c9554a230dc7fb44e55a7c85bc2060acea6f3fbee32c3b02636a65010783f64&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716057&amp;idx=1&amp;sn=d2fb93dd5d9e2cc0fcf9cb11e5bc99ec&amp;chksm=97ef625db727998acfcab90e06fb95df18d4fc23d2eea66b5bb1174fc2ddebae48d00485664e&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmvQDasddbj0Phadjb1JPicOeteibA1RaQoCCVRJrcn8mvHorbibw4ztak5eA6tI3QCeWM4df9xs9Bkg/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716057&amp;idx=1&amp;sn=d2fb93dd5d9e2cc0fcf9cb11e5bc99ec&amp;chksm=97ef625db727998acfcab90e06fb95df18d4fc23d2eea66b5bb1174fc2ddebae48d00485664e&amp;scene=0&amp;xtrack=1#rd" target="_blank">优化即几何，几何即推理：用数学终结Transformer的黑盒时代</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-01 20:18:10">发布日期：2026-01-01 20:18:10</time></div><p class="article-description">不是设计，而是进化。当交叉熵遇见 SGD，贝叶斯推理成了唯一的数学必然。长期以来，LLM 的推理能力被视为一种难以解释的“涌现”。我们目睹了 Loss 的下降，却难以透视参数空间内部发生了什么。近日，</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716057&amp;idx=1&amp;sn=d2fb93dd5d9e2cc0fcf9cb11e5bc99ec&amp;chksm=97ef625db727998acfcab90e06fb95df18d4fc23d2eea66b5bb1174fc2ddebae48d00485664e&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716057&amp;idx=2&amp;sn=a742874b44a9e11291067bbc5717d6e3&amp;chksm=974df97ad9df82e2673ddd98849f0efcc4d0f78118685d028fe11c392f186c5cd32de9778b01&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmvQDasddbj0Phadjb1JPicOP5VTNoAM9uNqgcsqEUhCSRtE92XNNEbZPcnxlVs1mEYkrzpbKsAjMw/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716057&amp;idx=2&amp;sn=a742874b44a9e11291067bbc5717d6e3&amp;chksm=974df97ad9df82e2673ddd98849f0efcc4d0f78118685d028fe11c392f186c5cd32de9778b01&amp;scene=0&amp;xtrack=1#rd" target="_blank">重构通用异常检测新范式：Dinomaly2实现跨模态、跨任务的无缝统一</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2026-01-01 20:18:10">发布日期：2026-01-01 20:18:10</time></div><p class="article-description">重磅更新还记得在 CVPR 2025 上首次让多类别异常检测（MUAD）达到单类 UAD 模型水平的 Dinomaly 吗？现在，Dinomaly 进一步进化为了 Dinomaly2 —— 一个真正实</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716057&amp;idx=2&amp;sn=a742874b44a9e11291067bbc5717d6e3&amp;chksm=974df97ad9df82e2673ddd98849f0efcc4d0f78118685d028fe11c392f186c5cd32de9778b01&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715917&amp;idx=1&amp;sn=9a2ec7bcfe522080a81d34d4d890705a&amp;chksm=973585d4789229cdea27400885d1c8b6ae947a6d18c375127bcbb8a80ea343e040613307c573&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglViaIjmdmDviccYyX1F6m7lQgY32wp0yJaCbQQDIFnSHyMKBUFxrbKiaBqibxDCcWUNsXoQ2XU51BEEg/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715917&amp;idx=1&amp;sn=9a2ec7bcfe522080a81d34d4d890705a&amp;chksm=973585d4789229cdea27400885d1c8b6ae947a6d18c375127bcbb8a80ea343e040613307c573&amp;scene=0&amp;xtrack=1#rd" target="_blank">Mamba还是Transformer？Bengio给出第三选择：Phalanx完美替代局部注意力</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-12-30 14:08:31">发布日期：2025-12-30 14:08:31</time></div><p class="article-description">比 Transformer 快 24%，无损 SOTA。在长序列建模领域，Transformer 架构凭借其捕捉全局依赖的能力占据主导地位，但其  的计算复杂度始终是扩展上下文长度的主要瓶颈。为了突破</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715917&amp;idx=1&amp;sn=9a2ec7bcfe522080a81d34d4d890705a&amp;chksm=973585d4789229cdea27400885d1c8b6ae947a6d18c375127bcbb8a80ea343e040613307c573&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715917&amp;idx=2&amp;sn=dacadccd1c8fb9be569a32448128a615&amp;chksm=97591b92499cd6f86381b9226187e01aa9531a21ce397caf63a8cb3c9f053080eb62ca761bf1&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglViaIjmdmDviccYyX1F6m7lQxLbheOZurdZYxo7Fexq2X4qibyHTpIAKlFibicLHUiaJictllj4PrjHwJlw/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715917&amp;idx=2&amp;sn=dacadccd1c8fb9be569a32448128a615&amp;chksm=97591b92499cd6f86381b9226187e01aa9531a21ce397caf63a8cb3c9f053080eb62ca761bf1&amp;scene=0&amp;xtrack=1#rd" target="_blank">华为重构Transformer FFN：首创宽深自适应复用，零增参超越MoE</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-12-30 14:08:31">发布日期：2025-12-30 14:08:31</time></div><p class="article-description">在大模型 Scaling Law 依然奏效的今天，为了追求高性能，模型参数量动辄千亿甚至万亿。然而，随之而来的显存墙成为了阻碍模型落地的最大拦路虎。现有的剪枝、量化技术虽然能压缩模型，但往往以牺牲模型</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715917&amp;idx=2&amp;sn=dacadccd1c8fb9be569a32448128a615&amp;chksm=97591b92499cd6f86381b9226187e01aa9531a21ce397caf63a8cb3c9f053080eb62ca761bf1&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715848&amp;idx=1&amp;sn=3308225390d93222a80f7cafdb9f0145&amp;chksm=97ba909549dfb1ffe3f97f35b4d659afb65b5475eacad9f03dd90fecdf2dfe76690964827ce5&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl22pvdXucYpYeanHhfgbXicHlPnyF0YzDlRYQKCqhaiaicItVo5h1bakpc80eZYt2gAop7TIDTUINibg/640?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715848&amp;idx=1&amp;sn=3308225390d93222a80f7cafdb9f0145&amp;chksm=97ba909549dfb1ffe3f97f35b4d659afb65b5475eacad9f03dd90fecdf2dfe76690964827ce5&amp;scene=0&amp;xtrack=1#rd" target="_blank">比Mathpix更强大的公式识别神器，全免费！</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-12-29 19:51:45">发布日期：2025-12-29 19:51:45</time></div><p class="article-description">今天这篇文章大家一定要仔细看看，说不定不仅能帮你省下不少钱，还能让科研论文写作事半功倍！本周末，在忙于项目的间隙，朋友突然给我分享了一个新发现。他说，PaddleOCR 最近推出了一个新模型——Pad</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715848&amp;idx=1&amp;sn=3308225390d93222a80f7cafdb9f0145&amp;chksm=97ba909549dfb1ffe3f97f35b4d659afb65b5475eacad9f03dd90fecdf2dfe76690964827ce5&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li><li class="article-item"><div class="article-cover"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715848&amp;idx=2&amp;sn=73d75ff4d832ddb341a38d77d23d8133&amp;chksm=97b901fc80a37c64a1063be1312c7d1c46e7565a28e951deffba81f28eccf4aa68d3b64675eb&amp;scene=0&amp;xtrack=1#rd" target="_blank"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl22pvdXucYpYeanHhfgbXic3Q5nxWaB6GOibBB8yxUpl0qp4AK8AWSF3pXZ1u1BCxtQk39VX5ibM4kg/300?wxtype=jpeg&amp;wxfrom=0" alt="文章封面"></a></div><div class="article-content"><h3 class="article-title"><a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715848&amp;idx=2&amp;sn=73d75ff4d832ddb341a38d77d23d8133&amp;chksm=97b901fc80a37c64a1063be1312c7d1c46e7565a28e951deffba81f28eccf4aa68d3b64675eb&amp;scene=0&amp;xtrack=1#rd" target="_blank">中科院 × 北体大提出SportsGPT，打造懂专业、会指导的AI教练</a></h3><div class="article-meta"><span class="article-author">作者：<a class="article-link" href="/f6ac5219a5dea1845de0fb1af2c1299c/index.html">PaperWeekly</a></span><time class="article-date" datetime="2025-12-29 19:51:45">发布日期：2025-12-29 19:51:45</time></div><p class="article-description">在 AI 席卷各行各业的今天，体育圈的“智能化”走到哪一步了？现有的智能体育系统，大多还停留在“打分+可视化”的阶段。屏幕上画出的骨骼线很酷，但对于运动员和教练来说，往往面临一个尴尬的灵魂拷问：“我知</p><a class="article-link" href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715848&amp;idx=2&amp;sn=73d75ff4d832ddb341a38d77d23d8133&amp;chksm=97b901fc80a37c64a1063be1312c7d1c46e7565a28e951deffba81f28eccf4aa68d3b64675eb&amp;scene=0&amp;xtrack=1#rd" target="_blank">阅读全文</a></div></li></ul><div class="pagination"><a href="index_1.html" class="pagination-button pagination-prev">上一页</a><a href="index_3.html" class="pagination-button pagination-prev">下一页</a></div></body></html>