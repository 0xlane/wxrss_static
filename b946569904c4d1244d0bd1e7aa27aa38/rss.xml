<?xml version="1.0" encoding="utf-8"?><rss version="2.0"><channel><title>AI修猫Prompt</title><link>https://wxrss.reinject.top/b946569904c4d1244d0bd1e7aa27aa38/</link><description>An RSS feed.</description><language>zh-cn</language><lastBuildDate>Sun, 26 Oct 2025 03:32:54 +0800</lastBuildDate><generator>wxrss -- https://github.com/0xlane/wxrss</generator><item><title>验证者定律，智能的锯齿边缘和商品化，CoT之父Jason Wei2025AI进展的三个思路</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502941&amp;idx=1&amp;sn=43c47e91187ad80f63ff92ad60e834e8&amp;chksm=ce58104ec7e94ba3a742993f642b37de5775358bf887fafd1b1940a1c6e4722eceedbdaee5a0&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[从“AI没什么用”到“AI三年内将终结人类工作”，这片巨大的认知鸿沟，就是我们身处的2025年。在这片喧嚣和迷雾之中，我们迫切需要一个清晰的导航图。而Jason Wei正是提供这份地图的最佳人选之一。]]></description><author>AI修猫Prompt</author><pubDate>Fri, 24 Oct 2025 21:52:12 +0800</pubDate></item><item><title>最新Agentic Search综述，RL让Agent自主检索，RAG逐渐成为过去式</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502905&amp;idx=1&amp;sn=1f89dc2ccf31e389e5ad59c99c4f7002&amp;chksm=ce6ad8bf5f20a56eea46fdf262d35929ec6c0f67550a35ce01be01857f9d1cc505abe474d402&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[大型语言模型（LLM）本身很强大，但知识是静态的，有时会“胡说八道”。为了解决这个问题，我们可以让它去外部知识库（比如维基百科、搜索引擎）里“检索”信息，这就是所谓的“检索增强生成”（RAG）。但这还]]></description><author>AI修猫Prompt</author><pubDate>Thu, 23 Oct 2025 20:22:42 +0800</pubDate></item><item><title>和人类一样？LLM也会认知能力会退化，当它看久了短平快内容 |最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502874&amp;idx=1&amp;sn=059355db1fe0da145461eed51a8c4771&amp;chksm=cecd004d553f4a21d3417160b38f39fd0a5462d59bb38cacc6ca4c5c0d80300c99c168868190&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[您可能已经听过“Brain Rot（脑腐烂）”这个词，它在2024年被牛津大学（Oxford）评为年度热词，本意描述的是人类长期沉浸浅层信息流带来的注意力、记忆与社交认知的耗损。Texas A&M U]]></description><author>AI修猫Prompt</author><pubDate>Wed, 22 Oct 2025 00:05:33 +0800</pubDate></item><item><title>AI的光学时刻来了，DeepSeek-OCR运行3B参数，仅6.2G，完美！</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502853&amp;idx=1&amp;sn=cfc6d7295e337fb3b2f539a14adb80f8&amp;chksm=ce8832fffa449827d98ff3387ad2abd013ad5094eb01c974f2e628a26bcc5e3cdcbfe86c8449&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[DeepSeek昨天开源了它们的多模态模型DeepSeek-OCR，主打用视觉压缩技术重新定义文本处理，长上下文难题迎来新解法！这个家伙厉害在能覆盖100多种语言，除了整页文字，还能对图表、化学式、几]]></description><author>AI修猫Prompt</author><pubDate>Tue, 21 Oct 2025 08:57:40 +0800</pubDate></item><item><title>是RAG已死，还是RAG Anything，All in RAG？</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502791&amp;idx=1&amp;sn=5c87ec8439957b637012471e75559c3f&amp;chksm=cec15bec0eeb813b639795b708c0e46aed8bfd64bb5b191811103e8958159b24cc25b36d24f8&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[每隔一阵子，总有人宣告“RAG已死”：上下文越来越长、端到端多模态模型越来越强，好像不再需要检索与证据拼装。但真正落地到复杂文档与可溯源场景，你会发现死掉的只是“只切文本的旧RAG”。当图、表、公式与]]></description><author>AI修猫Prompt</author><pubDate>Mon, 20 Oct 2025 00:17:29 +0800</pubDate></item><item><title>你是对的，AGI一年内不会出现了！学术界对AGI的定义来了，27家机构最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502752&amp;idx=1&amp;sn=8d396837eb390c9bd9c9addf6ffe28b0&amp;chksm=ced793501fb2c916b389762260c9f7c2f56561e76b890291135d031b24945625d3d55a3e57e5&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[通用人工智能AGI可能是人类历史上最重要的技术，但这个词本身长期模糊不清、标准不断挪动。随着窄域 AI 把越来越多“看似需要人的智慧才能干”的活干得有模有样，人们对“什么才算 AGI”的门槛就跟着改，]]></description><author>AI修猫Prompt</author><pubDate>Fri, 17 Oct 2025 05:05:55 +0800</pubDate></item><item><title>Agent长程搜索的两大痛点被打通了！中科院 DeepMiner用32k跑近百轮，开源领先逼近闭源</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502654&amp;idx=1&amp;sn=2278ba7fc63b329febd635bfa53bfae4&amp;chksm=cee63827d8f3878c00fcb022812be80b090d452ad7a23f7d29c2271a4bc0453ea68e8eaccc70&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[中科院的这篇工作解决了“深度搜索智能体”（deep search agents），两个实打实的工程痛点，一个是问题本身不够难导致模型不必真正思考，另一个是上下文被工具长文本迅速挤爆导致过程提前夭折，研]]></description><author>AI修猫Prompt</author><pubDate>Thu, 16 Oct 2025 06:35:00 +0800</pubDate></item><item><title>试下GEPA-UI，或许你能在前端更深入理解这个提示词优化算法</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502594&amp;idx=1&amp;sn=208705a36739c8b34e527f78d859486b&amp;chksm=ce2a02cb925ed6f0414cd118b0f846acab9b9f422f98f46fc361a7ad15c58034a791e233d026&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[上周写了两篇关于GEPA的文章《Agent多步误差咋破？看下GEPA，反思自进化+帕累托前沿，超过DSPy的MIPROv2》《别被提示词优化困住！用DSPy.GEPA把Prompt做成可演进的工程（万]]></description><author>AI修猫Prompt</author><pubDate>Wed, 15 Oct 2025 07:20:00 +0800</pubDate></item><item><title>真实度达90%！PyMC Labs 和高露洁预测购买意图，仅需个两个LLM</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502572&amp;idx=1&amp;sn=182a02ca1a6cd99a4c407660b77da558&amp;chksm=cea581560409007e52a2c1cbc9cf98917e1016e7ffac70ed34341ea8214b54e6e6b48c712287&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[PyMC Labs 和个人护理领域的龙头企业高露洁-棕榄一起发了篇论文，核心想法很简单：传统消费者调研又贵又慢，还容易被面板偏差、迎合式作答这些老问题拖后腿。两家就想找一条更省钱省时、还能和现有流程配]]></description><author>AI修猫Prompt</author><pubDate>Tue, 14 Oct 2025 05:30:00 +0800</pubDate></item><item><title>无奖励也能把Agent练硬，Meta发布早期经验学习，隐式建模+反思（附提示词）</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502537&amp;idx=1&amp;sn=9f7a731465644cbfe82ae1330f578026&amp;chksm=ce4d2a86ff81462784b090711ecacc0b419bea245a0a8c639d71691a0653476f7b515c2b0b8c&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Meta提出早期经验（Early Experience）让代理在无奖励下从自身经验中学习：在专家状态上采样替代动作、执行并收集未来状态，将这些真实后果当作监督信号。核心是把“自己造成的未来状态”转为可]]></description><author>AI修猫Prompt</author><pubDate>Sun, 12 Oct 2025 19:43:42 +0800</pubDate></item><item><title>斯坦福最新：上下文只能写死在prompt里？用ACE把经验写进可演化上下文『附系统提示』</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502497&amp;idx=1&amp;sn=07de858a1624a7a39ef712f2120a65eb&amp;chksm=cedf6bcef34f4301e0e36c71b07cb1a6f2b0a35d09ba628653a969dc4cc9b6441910a2244a53&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[编者按：调模型不如“管上下文”。这篇文章基于 ACE（Agentic Context Engineering），把系统提示、运行记忆和证据做成可演化的 playbook，用“生成—反思—策展”三角色加]]></description><author>AI修猫Prompt</author><pubDate>Sat, 11 Oct 2025 00:06:58 +0800</pubDate></item><item><title>别被提示词优化困住！用DSPy.GEPA把Prompt做成可演进的工程（万字长文)</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502474&amp;idx=1&amp;sn=4e78f16e73d2a8d47f1b977bda591536&amp;chksm=cefc5c39cf9856684cce4a55f4eb77733c78846ed1f18b4c086a8e9a2cbb450d155127c31b88&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[写给正在落地 AI 产品的工程师。一些代码直接可改造复用；另一些，是我踩坑后的经验之谈。为什么是 DSPy.GEPA，而不是“再手搓一次提示”DSPy是一个2024年5月修猫曾反复推荐给大家的一个AI]]></description><author>AI修猫Prompt</author><pubDate>Fri, 10 Oct 2025 00:03:04 +0800</pubDate></item><item><title>Meta的代码生成世界模型CWM，先预测结果再写代码，IDE很快会多一个“预言”按钮</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502468&amp;idx=1&amp;sn=1076a333d89ff7ac1fbdddf621884b5f&amp;chksm=ce2e31b86e490db9ea6bcacb831e888100e57eeaee86284d424e8c327dda0449c2f6bc76dc53&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[您修过Bug吗？在Vibe coding的时代之前，当程序员遇到自己写的 Bug 时，通常能顺着自己的思路反推问题所在。但当面对 AI 生成的 Bug 时，情况变得复杂得多，我们不清楚 AI 的“思考]]></description><author>AI修猫Prompt</author><pubDate>Thu, 09 Oct 2025 07:10:00 +0800</pubDate></item><item><title>Agent多步误差咋破？看下GEPA，反思自进化+帕累托前沿，超过DSPy的MIPROv2</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502440&amp;idx=1&amp;sn=921ea3cb6ab8e243342f161b1b788353&amp;chksm=ceb875cfd8b71a8fb3d6009826bccafae459772cadcc5c27d78c6cc02ddb75161323cc98d211&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在人工智能的研究中，我们关心的是在序贯决策里如何实现长期目标的最优化；然而，一旦缺乏全局校正，哪怕每一步看似合理，仍可能在错误前提上越走越偏。在多步骤任务中，Agent 可能由于对指令的误解、知识的缺]]></description><author>AI修猫Prompt</author><pubDate>Tue, 30 Sep 2025 19:02:16 +0800</pubDate></item><item><title>太重要了，文档智能中的LLMs：综述、进展、和未来趋势</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502410&amp;idx=1&amp;sn=0d5016b4c1dc9f1ea37289deca351d76&amp;chksm=ce4044ec48a6368ec5ce65f55a5e8b832a493edcf3fc311704dfdaa95022d95715398fe94676&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[随着数字化时代的到来，文档数量急剧增加。文本文件、网页、幻灯片、海报、电子表格数据，甚至场景文本图像。这些文档不仅封装了不同行业内部和外部事务的处理细节和积累的知识，还涵盖了大量的行业相关实例和数据，]]></description><author>AI修猫Prompt</author><pubDate>Fri, 26 Sep 2025 17:37:34 +0800</pubDate></item><item><title>你的多轮对话「焦点漂移」有救啦，试下状态更新多轮对话策略，一条Prompt搞定！</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502385&amp;idx=1&amp;sn=6a0f8fddab65120a3c568f5f73ffab6b&amp;chksm=ce702801c18b8f1b886a40d06049187fb249601e917fdbcaab4eb073fef154c1736f9a9aec41&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[长程、多轮对话（long-horizon, multi-turn dialogues）一直是当前AI应用领域中一个非常核心且常见的场景。无论是进行复杂的推理、利用外部知识库（RAG）还是使用工具（To]]></description><author>AI修猫Prompt</author><pubDate>Thu, 25 Sep 2025 21:00:26 +0800</pubDate></item><item><title>少即是多！78条数据完胜1万条？ 高质量数据才是AI真壁垒｜上交大/SII最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502367&amp;idx=1&amp;sn=5608a077f78e53d9a8d2a3d510d3a266&amp;chksm=ce321900416ed48333cd27069e6c3fe330bf48bfee126aaf5126415cc4bb9ce2eeb22d8374c6&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[对于提升AI能主动发现问题、提出假设、调用工具并执行解决方案，在真实环境里闭环工作，而不只是在对话里“想”的智能体能力（Agency）。在这篇论文之前的传统方法认为，需要遵循传统语言模型的“规模法则”]]></description><author>AI修猫Prompt</author><pubDate>Wed, 24 Sep 2025 18:09:10 +0800</pubDate></item><item><title>帮你把Agent从玩具变成产品，Google发布重磅指南，3章内容填平生产化鸿沟</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502345&amp;idx=1&amp;sn=c74157a9f7aa833a970f52d5c115d758&amp;chksm=ce9df81aa942affe8d9de3186db560e62ad38ad7779ee0067c77519a21c16b299a9f62adee7c&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[谷歌云刚发布了一篇《Google Cloud Startup technical guide: Al agents》（Google Cloud 创业公司技术指南：AI 代理）这是一份非常详尽和全面的手]]></description><author>AI修猫Prompt</author><pubDate>Tue, 23 Sep 2025 15:31:13 +0800</pubDate></item><item><title>IBM发布LLM工具调用判断器ToolRM，工具调用准确率提高25%</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502305&amp;idx=1&amp;sn=27fa1884e0b537c9708f0017b14adcb8&amp;chksm=ce2447fb4fecfc6fb06ed0844a814eb0f06fc92d2c56294116a71914ad98599b921e31219a7e&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Tool-Calling作为Agent的核心模块，智能体的双手，这项关键能力允许 LLM 调用外部函数，例如应用程序接口（APIs）、数据库、计算器和搜索引擎，决定了AI Agent的可执行边界。但在]]></description><author>AI修猫Prompt</author><pubDate>Mon, 22 Sep 2025 05:30:00 +0800</pubDate></item><item><title>Agent不用掏钱学了，Agent的21个设计模式，理解了这21张流程图就是高手</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502284&amp;idx=1&amp;sn=248ea533052c307181dd5ec019520161&amp;chksm=cee0c2e4939ac9dad4df7dd03943af83ac01c03963b03f38b9b63ffaeba03c74c682d7d5a220&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>AI修猫Prompt</author><pubDate>Fri, 19 Sep 2025 15:46:48 +0800</pubDate></item><item><title>谷歌前CTO办公室总监近500页巨著，Agent的21个设计模式，从小白走向大师</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502169&amp;idx=1&amp;sn=5240c849c45361a422e4d1ed1ea67324&amp;chksm=ce5808b96b8ae161cbd15887af50b7dbf8fe895e1614fcf6a7d276f55316e69418752c3f9e9d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[从LLM到Agentic的产业拐点上，最难的并不是让模型会写一段代码或生成一份报告，而是把能力稳定地固化进工程体系：如何拆解任务、如何在多人，多Agent协作下保证可追溯、如何做异常恢复与安全护栏、以]]></description><author>AI修猫Prompt</author><pubDate>Thu, 18 Sep 2025 23:12:47 +0800</pubDate></item><item><title>微软警告：大模型ICL并非真正意义上的学习，你的AI Agent随时可能“失忆”</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502132&amp;idx=1&amp;sn=862b1e0770ca1a24b785ab7ab47b6aab&amp;chksm=ce0c4f55bad7861c11177454f722bc76504c21cde98fa95cce484248781a1a8f33dcb99b32a8&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[上下文学习”（In-Context Learning，ICL），是大模型不需要微调（fine-tuning），仅通过分析在提示词中给出的几个范例，就能解决当前任务的能力。您可能已经对这个场景再熟悉不过]]></description><author>AI修猫Prompt</author><pubDate>Wed, 17 Sep 2025 17:28:38 +0800</pubDate></item><item><title>想让LLM内心戏更丰富？试下苏黎世理工基于MBTI框架的Agent</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502114&amp;idx=1&amp;sn=7c71242b3a974ddca80eda6f05baa9b1&amp;chksm=ce2d771840d81692de819ea35cc8ebb94fd781e6a771d6110880fa4259135c356c10db6d7625&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[有很多朋友都研究过MBTI，大家对MBTI已经很熟悉了。但也有一些朋友，对MBTI并不了解，什么是MBTI？迈尔斯-布里格斯类型指标（Myers-Briggs Type Indicator）简称MBT]]></description><author>AI修猫Prompt</author><pubDate>Tue, 16 Sep 2025 21:14:25 +0800</pubDate></item><item><title>想让LLM精确输出？试下XML格式Prompt语法约束解码GCD，帮你迭代收敛到稳定解</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502086&amp;idx=1&amp;sn=33f02cb5378b7a16a9cdc394c837db20&amp;chksm=cee81dbe5438c3681fbf54a5ffbffd447ffc4a5cd5e6ead54535f3e689980e7aac8ed128be60&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[随着Agent的爆发，大型语言模型（LLM）的应用不再局限于生成日常对话，而是越来越多地被要求输出像JSON或XML这样的结构化数据。这种结构化输出对于确保安全性、与其他软件系统互操作以及执行下游自动]]></description><author>AI修猫Prompt</author><pubDate>Mon, 15 Sep 2025 00:43:43 +0800</pubDate></item><item><title>你知道吗？相较于产生幻觉，LLM其实更会「说谎」｜卡梅隆最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502066&amp;idx=1&amp;sn=9062ffb90ade76aefdb45fa2d2cb98d6&amp;chksm=ced6fb84a7b91c2441338507ae62150e7b9b20c4ad07a27e6947630d167ba2c67bec3f4f7c67&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[幻觉并非什么神秘现象，而是现代语言模型训练和评估方式下必然的统计结果。它是一种无意的、因不确定而产生的错误。根据OpenAI9月4号论文的证明，模型产生幻觉(Hallucination)，是一种系统性]]></description><author>AI修猫Prompt</author><pubDate>Thu, 11 Sep 2025 20:38:25 +0800</pubDate></item><item><title>通用问题求解器雏形已现！谷歌DeepMind重磅研究，自主发现40种全新算法</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502031&amp;idx=1&amp;sn=37402c6ccb4fc731e02dcfa27e182cb7&amp;chksm=ce573e7413a3178785038430ba7454664710ddf39a2af03cdeba4ddf0b6c29f3c70579ba0dd3&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在现代科学中，几乎所有领域都依赖软件来进行计算实验。但开发这些专用的科学软件是一个非常缓慢、乏味且困难的过程，开发和测试一个新想法（一次“试错”）需要编写复杂的软件，这个过程可能耗费数周、数月甚至数年]]></description><author>AI修猫Prompt</author><pubDate>Wed, 10 Sep 2025 05:39:01 +0800</pubDate></item><item><title>中国AI弯道超车，国产GPU训练！无需Transformer，原生类脑脉冲大模型「瞬悉」横空出世</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247502009&amp;idx=1&amp;sn=2c4668a7ee24d9776b1cbd8186db85b3&amp;chksm=ce6d7d1e02b2270b0072bccd95fddd61b1fb3e79cbe0bc42dbec45a94aedc24cb66e3441e185&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[自2017年Transformer架构提出以来，依托GPU集群的大规模计算能力，人工智能迈入大模型时代并取得巨大成功。但其核心的Softmax Attention机制，训练开销会随序列长度呈平方级增长]]></description><author>AI修猫Prompt</author><pubDate>Tue, 09 Sep 2025 21:30:25 +0800</pubDate></item><item><title>不微调，让LLM推理准确率暴增到99%！试下DeepConf，一个轻量级推理框架｜Meta最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501973&amp;idx=1&amp;sn=e53c0cfb0020bd115c3e797ee3c4a257&amp;chksm=cec351e46d297291ac4304ac8c6513968fbdc6f36dc8d97ec7dd5557d711253ccc467b33f446&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在大型语言模型（LLM）进行数学题、逻辑推理等复杂任务时，一个非常流行且有效的方法叫做 “自洽性”（Self-Consistency），通常也被称为“平行思考”。它的逻辑很简单：不要只让模型想一次，而]]></description><author>AI修猫Prompt</author><pubDate>Mon, 08 Sep 2025 17:42:58 +0800</pubDate></item><item><title>断供？会“刻意练习”的Qwen2.5-3B，竟然超越Claude3.5！斯坦福最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501944&amp;idx=1&amp;sn=d456fb2cd154cd7d22bd222a1df725a7&amp;chksm=ced96d3a48893fa76a237bb6a3e1e80055fa4dac4799279b47d6b6ffc3f20769072f574f6789&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[什么断供不断供，不存在的。。。拳打在沙袋上，沙袋会给你一个反作用力，让你感觉到这次出拳的力量和效果，却也让新手只爱打更快的拳。同样，在强化学习（RL）当中，模型生成的代码在环境中运行后，会返回一个分数]]></description><author>AI修猫Prompt</author><pubDate>Fri, 05 Sep 2025 21:54:48 +0800</pubDate></item><item><title>隐式推理，继CoT思维链之后，LLM的下一个技术奇点系统性综述来了｜港科大最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501915&amp;idx=1&amp;sn=37a76c2b73ced572651f4171b38029cc&amp;chksm=ced2e8dbc8de5700468f2d3d01af6ad342f9697c04520f53601574a71d0923888ac68c39df01&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[您对“思维链”（Chain-of-Thought）肯定不陌生，从最早的GPT-o1到后来震惊世界的Deepseek-R1，它通过让模型输出详细的思考步骤，确实解决了许多复杂的推理问题。但您肯定也为它那]]></description><author>AI修猫Prompt</author><pubDate>Thu, 04 Sep 2025 15:38:00 +0800</pubDate></item><item><title>你的RAG系统有个数学BUG，DeepMind首次证明嵌入向量检索召回能力有限</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501892&amp;idx=1&amp;sn=6fb57a5eec1e931ca3b416c4c5e023f7&amp;chksm=ce7e28019fe5763d8e65e19bd1907cb1093584bb48792c3d31bab37c0b6436192f21b3b9e5bf&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[最近，工业界“RAG已死”甚嚣尘上。过去几年，AI领域的主旋律是“规模定律”（Scaling Law），即更大的模型、更多的数据会带来更好的性能。即便偶然有瑕疵，也认为只是工程上的不足，并非数学上的不]]></description><author>AI修猫Prompt</author><pubDate>Tue, 02 Sep 2025 19:35:01 +0800</pubDate></item><item><title>你的设想被证实了！不微调模型也能微调Agent，Memento霸榜GAIA｜UCL最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501867&amp;idx=1&amp;sn=df1851bfe7f21383b6dd93120c343472&amp;chksm=ceeee43bbc4ca610676a10a8b90494b61b778fcf605c64b90b7f65162d0b2a85785a4659cc84&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[你或许也有过这样的猜想，如何让AI智能体（Agent）变得更聪明、更能干，同时又不用烧掉堆积如山的算力去反复微调模型？前天一个来自UCL《Memento》的框架给出了一个非常有意思的答案，它就像是在说]]></description><author>AI修猫Prompt</author><pubDate>Mon, 01 Sep 2025 05:50:00 +0800</pubDate></item><item><title>你的怀疑是对的！LLM作为Judge，既无效又不可靠，终于有论文向LLJ开炮了</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501846&amp;idx=1&amp;sn=7c88e0b20d612581e03e869b43af80a2&amp;chksm=cecaf0a4edce26b16b1e224498af470b82e25484e890eef1aeef3479a96e5f376ab7861bbd5d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[让LMM作为Judge，从对模型的性能评估到数据标注再到模型的训练和对齐流程，让AI来评判AI，这种模式几乎已经是当前学术界和工业界的常态。我之前也介绍过这方面的研究，但没想到打脸来得这么快！之前也有]]></description><author>AI修猫Prompt</author><pubDate>Thu, 28 Aug 2025 17:53:54 +0800</pubDate></item><item><title>普林斯顿、清华等20家高校联合发布，「自进化」Agent综述</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501809&amp;idx=1&amp;sn=ef79e97b68ec8c4735c43f2b59457b66&amp;chksm=cedc0145d80ddd15559b19f67405c58e104a483c6f794aa542f937777e517a4827314d28f802&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[It is not the most intellectual of the species that survives; it is not the strongest that survives;]]></description><author>AI修猫Prompt</author><pubDate>Wed, 27 Aug 2025 18:52:40 +0800</pubDate></item><item><title>搞不定有表格数据和多模态的Prompt？试下微软最新的提示词编排标记语言POML</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501776&amp;idx=1&amp;sn=b81743a54be254aaaefec36b9565c744&amp;chksm=ce81ef88a35298e334df5111735a42176154f404a98b3bf83154d17fedf5d9eb88f6eb60addb&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[总是小心翼翼地调整Prompt措辞、格式，甚至标点符号，反复测试，却常常得到不稳定的结果？整个过程充满了不确定性。尤其是在构建复杂的AI应用时，这种混乱状态真是让人头疼。不过！最近来自微软的研究者们带]]></description><author>AI修猫Prompt</author><pubDate>Tue, 26 Aug 2025 23:11:28 +0800</pubDate></item><item><title>并非95%的AI项目都失败！麻省理工MIT《2025年商业人工智能现状》</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501749&amp;idx=1&amp;sn=7bc6a8a83c6099f31436dbc0495eb41f&amp;chksm=cede22a7bc311fae7e887161adbd535cfc7a828882b086025037529803febcdc567459db9e30&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[这份来自麻省理工学院的2025年商业AI现状的研究报告最近在网上炸锅了，该报告称 95% 的人工智能试点都失败了，这吓坏了美国股市的投资者。报告提到大多数公司都陷入了困境，因为 95% 的 GenAI]]></description><author>AI修猫Prompt</author><pubDate>Mon, 25 Aug 2025 05:40:00 +0800</pubDate></item><item><title>自主深度研究DR代理究竟走向何方？四步操作「流程」让你不迷糊 |华为最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501728&amp;idx=1&amp;sn=2cd312ae76892a33e7daa91e72aa8b45&amp;chksm=ce17420f674b832fdd3a561ba3f3e9b6d565f0fb138461a992249b684915949f825b64e26710&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[华为诺亚方舟实验室最近联合香港大学发了一篇针对"Deep Research Agents"（深度研究代理）的系统性综述，在我的印象中，这是他们第二次发布关于Deep Research的综述论文。上一篇]]></description><author>AI修猫Prompt</author><pubDate>Fri, 22 Aug 2025 23:39:23 +0800</pubDate></item><item><title>多Agent集体失忆？试下内在记忆框架，每个Agent都有自己的异构笔记本</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501715&amp;idx=1&amp;sn=15c042804dea9780dc3096bbc823ee6e&amp;chksm=ce2cd0faa06b56fb0b82bd95f94c3d5fd0a41adda7f8cda1145a1bc704d3d64bb79064abc1a6&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[精心设计了一个由多个AI智能体组成的强大团队，期望它们能像人类专家一样协作解决复杂问题，但却发现这个团队聊着聊着就“精神涣散”，忘记了最初的目标，甚至连彼此的角色都开始混乱。这并非您的设计失误，而是当]]></description><author>AI修猫Prompt</author><pubDate>Thu, 21 Aug 2025 22:48:10 +0800</pubDate></item><item><title>LLM中最难搞的表格最新梳理，需要什么请自取</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501694&amp;idx=1&amp;sn=8b2a15ca1599db829a9423fd0bd1f806&amp;chksm=cefb6151947e4cb168812fdcc6bb33f69e996005add1df0e6ab1addc4c53428a33c70f0b357c&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[您可能已经在产品里放进了问答、总结、甚至自动报表模块，但表格一上来，体验就变味了，这不奇怪。表格是二维、带结构、还经常跨表跨文，和纯文本完全不一样；项目作者在《Tabular Data Underst]]></description><author>AI修猫Prompt</author><pubDate>Wed, 20 Aug 2025 16:08:55 +0800</pubDate></item><item><title>海量文本秒转结构化，试下谷歌的LangExtract，Github上12.3k star</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501677&amp;idx=1&amp;sn=75724ff8cbf85a730678e65a17c7f360&amp;chksm=cecd6e523bb012c7a53be6cae6b5be6a59022ebe9c64a9fe0afe4e29dc075b44f515afc0e17d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[真正的业务宝藏往往就埋藏在那些看似杂乱无章的文本数据之中，即非结构化文本，但问题是，如何高效、可靠地把这些宝藏精准地挖出来，一直是个令人头疼的难题，今天我们就来聊聊最近GitHub12.3k star]]></description><author>AI修猫Prompt</author><pubDate>Tue, 19 Aug 2025 22:46:47 +0800</pubDate></item><item><title>AI时代还用德尔菲法？其实“少数人”远比“多数人”更有价值 ｜谷歌最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501666&amp;idx=1&amp;sn=72f529d648c0bc9756fd1ea03971f845&amp;chksm=ce951d7dbf28609aa3bfad24de18d3ce3f48025d45b47a832d2a101e827c4560af39da0f96e9&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[每当需要处理复杂领域中高度不确定性或缺乏历史数据的问题时，纯粹的科学证据不足、存在矛盾或过于复杂，通常我们就需要依赖专家们的集体智慧来形成共识，指导实践。德尔菲法（Delphi method）是半个多]]></description><author>AI修猫Prompt</author><pubDate>Mon, 18 Aug 2025 17:25:47 +0800</pubDate></item><item><title>腾讯AI团队最新研究戳穿AI“智力”泡沫：百万上下文正在误导所有人</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501654&amp;idx=1&amp;sn=9339ae899e530e7251072f24e024e108&amp;chksm=ce396edcba3fc26619205f594ef137770f1eae01b4aadd321b8c4a05d2d135c4ceb50ab4382e&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[AI领域一度陷入“上下文窗口”的军备竞赛，从几千token扩展到数百万token。这相当于给了AI一个巨大的图书馆。但这些“百万上下文”的顶级模型，它究竟是真的“理解”了，还是只是一个更会“背书”的复]]></description><author>AI修猫Prompt</author><pubDate>Fri, 15 Aug 2025 23:23:58 +0800</pubDate></item><item><title>LLM幻觉第一次被定义：你必须掌握的3个理论和能上手的4套工程解法</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501641&amp;idx=1&amp;sn=243b0b859cad12e3fe5c65cc9483b10b&amp;chksm=ceb62bae71f38a9e01439ebcc24b0469bb4bff857a52755f9891b0e4ede9770ea6bae2853e23&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[幻觉，作为AI圈家喻户晓的概念，这个词您可能已经听得耳朵起茧了。我们都知道它存在，也普遍接受了它似乎无法根除，是一个“老大难”问题。但正因如此，一个更危险的问题随之而来：当我们对幻觉的存在习以为常时，]]></description><author>AI修猫Prompt</author><pubDate>Thu, 14 Aug 2025 20:48:05 +0800</pubDate></item><item><title>AI代码生成，上下文示例怎样写最有效？港科大最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501621&amp;idx=1&amp;sn=3171c0381bc0fb90b2e1f0371b1cde5b&amp;chksm=ceeb0d7f90d01d6d3a315172009cc275ff2849c04ca8701e4bb0bfad8172ae425472252cf209&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[长久以来我们都知道在Prompt里塞几个好例子能让LLM表现得更好，这就像教小孩学东西前先给他做个示范。在Vibe coding爆火后，和各种代码生成模型打交道的人变得更多了，大家也一定用过上下文学习]]></description><author>AI修猫Prompt</author><pubDate>Tue, 12 Aug 2025 21:03:04 +0800</pubDate></item><item><title>Agent怎么运维？中科院清华重磅发布：AgentOps来了！</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501605&amp;idx=1&amp;sn=49ded1f40b84f38c42471e180fbf3231&amp;chksm=ce7b36d0e9c5ffa8c99ba534207475636dc0888f4f268acc3caab1a39d9e45ecaaf68febc260&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[从“模型即服务”（MaaS）到“智能体即服务”（AaaS）的转变，标志着AI行业进入了新的发展阶段。我们不再满足于AI的“对话能力”，而是期望它能成为自主完成复杂任务的“全能机器人”。但当我们兴奋地将]]></description><author>AI修猫Prompt</author><pubDate>Fri, 08 Aug 2025 16:46:22 +0800</pubDate></item><item><title>腾讯AI Lab开源即王炸：GAIA同级最强Agent框架</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501575&amp;idx=1&amp;sn=08cb7acceb1ed23cdf9561fdec73c5d3&amp;chksm=ce121630676a0caa84cc0ee08699865c9eff36c3b26e77ec46cec5b359de72effcbe5588e9d9&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[当AI智能体（Agent）开发的浪潮涌来，很多一线工程师却发现自己站在一个尴尬的十字路口：左边是谷歌、OpenAI等巨头深不可测的“技术黑盒”，右边是看似开放却暗藏“付费墙”的开源社区。大家空有场景和]]></description><author>AI修猫Prompt</author><pubDate>Thu, 07 Aug 2025 05:30:00 +0800</pubDate></item><item><title>gpt-oss专为Agent而生，16G显存就能跑，昨晚开源。</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501563&amp;idx=1&amp;sn=4abccd94a3e2185bc42ae6372db03142&amp;chksm=ceffabae11e1e621ba253d76aff99a1275a362f938b9de85f77c357e3da87a3b0b5fd398a315&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[昨晚OpenAI官方放了个大招，发布了gpt-oss-120b和gpt-oss-20b两款开源模型，这是一个专为Agent而生的模型，而且开源了。这背后其实藏着OpenAI对未来AI应用形态，特别是A]]></description><author>AI修猫Prompt</author><pubDate>Wed, 06 Aug 2025 04:59:09 +0800</pubDate></item><item><title>RAG也能推理思考！彻底解决多源异构知识难题</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501548&amp;idx=1&amp;sn=f462e6767579c6cf6618ea254b64e3c3&amp;chksm=ce861f7b59855e8fb0243292b13e593e197f8b25f10b6f91c4e99397e24a752ca80f219bff96&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[现在的RAG（检索增强生成）系统。您给它一个简单直接的问题，它能答得头头是道；可一旦问题需要稍微拐个弯，或者知识源一复杂，它就立刻“拉胯”，要么返回一堆不相干的东西，要么干脆就开始一本正经地胡说八道。]]></description><author>AI修猫Prompt</author><pubDate>Mon, 04 Aug 2025 21:19:22 +0800</pubDate></item><item><title>你的Prompt已达性能极限？试试这个0成本的优化 | 马里兰大学最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501538&amp;idx=1&amp;sn=ee9da18cb2a0ad3aa012f30715459b80&amp;chksm=ce1e1492b9f6c8b4b8cca3cdfbd8f50cc445eb51e47e2e16b0ffca666470771f1643e98ce302&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[上下文学习（In-Context Learning, ICL）、few-shot，经常看我文章的朋友几乎没有人不知道这些概念，给模型几个例子（Demos），它就能更好地理解我们的意图。但问题来了，当您]]></description><author>AI修猫Prompt</author><pubDate>Fri, 01 Aug 2025 16:00:51 +0800</pubDate></item><item><title>LLM产品开发边界究竟在哪，我们终将面对AI的归纳偏差，哈佛MIT重磅研究</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501527&amp;idx=1&amp;sn=ec32d5a9ee47c0b1b2269cf765b47d96&amp;chksm=cefb406ad8430aa778fff6a23c7dd1bedd8c51e06ab66f8094fcdbc5c0aa8dac16c59799a380&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[几百年前开普勒通过观测数据，总结出了行星运动的规律，例如行星沿椭圆轨道运行，这让他能精确预测行星未来的位置。这就像今天的基础模型，通过学习海量数据，可以很好地进行序列预测（比如接下一句话）。后来牛顿提]]></description><author>AI修猫Prompt</author><pubDate>Wed, 30 Jul 2025 18:37:51 +0800</pubDate></item><item><title>上下文灾难有救了，Claude Sub-Agent的隐藏功能，99%的开发者还没发现</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501514&amp;idx=1&amp;sn=ce838b93ee63dbd25e86ee01a4337fad&amp;chksm=ceadaf419c0d6bbf27092819a1a5f4ffa5bfdf7b48ee02ccda490de44c28fa9775b2d73238cd&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Claude Code中的Sub Agents是专门化的AI助手，可以被调用来处理特定类型的任务。它们通过提供具有自定义系统提示、工具和独立上下文窗口的任务特定配置，从而实现更高效的问题解决。—Ant]]></description><author>AI修猫Prompt</author><pubDate>Mon, 28 Jul 2025 21:40:55 +0800</pubDate></item><item><title>上下文工程难吗？试下Claude Code写入Kiro的Spec，自动搞定上下文</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501499&amp;idx=1&amp;sn=26304eb4018babe68f63366154d9af21&amp;chksm=ce6ebfb5cabf75230aecc615ae6a65500f596cc28616842ffcb21ba13c8be8fadf3f3baa1b4b&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[10天前Amazon发布了他们自己的开发平台，Kiro IDE，其中有一个很厉害的交互功能“Spec（Specification）”，强调的是规范的文档，说明书，以一套非常结构化的方法确保开发过程的系]]></description><author>AI修猫Prompt</author><pubDate>Fri, 25 Jul 2025 23:58:04 +0800</pubDate></item><item><title>上下文工程怎么用？三星SDS这个E2E的Agent案例说明白了</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501319&amp;idx=1&amp;sn=8299f1ecf4fc0de406e34aa82295ca45&amp;chksm=cedc2256e475f5827b8985439480b853a10f990b4f95b0f29e6bb36acb431b765e502748c410&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[今年5月，SAMSUNG SDS发布了一份财务费用自动化处理的案例研究报告。当时，"Context Engineering"这个概念还没有成为AI圈的热词，大部分工程师还沉浸在Prompt Engin]]></description><author>AI修猫Prompt</author><pubDate>Fri, 11 Jul 2025 21:59:55 +0800</pubDate></item><item><title>复杂Agent怎么设计？IBM用一个YAML，性能提升4倍| ICML 2025</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501302&amp;idx=1&amp;sn=15bab3911f80a728b0ad4ce3d6bb2f75&amp;chksm=ce558afed3ee56ea103f868e4c71766bfa464ce93f7d2d0ae752be4f4c42fc7db66780d6c858&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[您有没有遇到过这样的场景：为了调试一个LLM应用的效果，您需要在一大堆Python代码中翻找那些零散的提示词字符串？每次想要A/B测试不同的提示时，就像在做开颅手术一样小心翼翼。IBM研究团队最近发布]]></description><author>AI修猫Prompt</author><pubDate>Thu, 10 Jul 2025 21:46:47 +0800</pubDate></item><item><title>剑桥UCL重磅发布：Vibe Coding深度报告，这才是“人机协同”的最终形态</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501285&amp;idx=1&amp;sn=cf34ad2917a1426c56bf842de0832f21&amp;chksm=ce9a2cfa2a41a193ef56a3abb4484d1df519a35b51bfdf773eb709e6b9a2026aca30fa0bb383&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[编者按：vibe coding不是编程的终点，而是Context Engineering驱动的协作智能的起点。那些能够最早理解并应用这种整合视角的人，将在下一轮技术变革中获得决定性优势。自今年2月AI]]></description><author>AI修猫Prompt</author><pubDate>Wed, 09 Jul 2025 21:33:21 +0800</pubDate></item><item><title>第一性原理的Context Engineering工具、指南</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501255&amp;idx=1&amp;sn=9b01d7033772a3887a343fda62da2b7d&amp;chksm=ce8b446715605451a4926bdf24600124be32d20799fdf5db507c8051ee5049c473d1ebb7c939&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[就像是播放音乐，Prompt Engineering是在调音响的音量，那Context Engineering就是在设计整个音响系统，从音源、功放、音箱到房间声学，每个环节都要精心设计。Context]]></description><author>AI修猫Prompt</author><pubDate>Tue, 08 Jul 2025 21:27:40 +0800</pubDate></item><item><title>Context Engineering不是造新词，IBM揭示LLM推理的认知秘密</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501243&amp;idx=1&amp;sn=a285d95cad2f80c828984768f350b68e&amp;chksm=ce864c16db83da2a7ddbdc8bd2d0eb33fed92577bdd06f387354a8502abebaaa96266ef19337&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[当LangChain在6月23日发布那篇著名的Context Engineering博客时，IBM Research的研究者们早在10天前就已经用严格的学术实验证明了这套方法的有效性。只不过那时候上下]]></description><author>AI修猫Prompt</author><pubDate>Mon, 07 Jul 2025 21:45:49 +0800</pubDate></item><item><title>GitHub上5.4k+Star爆火，构建生产级Agent 的12因素</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247501217&amp;idx=1&amp;sn=587af366b64650939d07c918d8c3f59f&amp;chksm=ce19725d7b8782fe3785d45b6df129555285cd95e008f708676e98699941e6c8fbcace96b301&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[这是一篇在GitHub上获得5.3k+星标的重要技术文档，其中蕴含的洞察值得每一位AI产品开发者深度思考。作者Dex是一位资深的AI工程师，他试遍了市面上几乎所有的Agent框架——从广受欢迎的Lan]]></description><author>AI修猫Prompt</author><pubDate>Fri, 04 Jul 2025 20:42:43 +0800</pubDate></item><item><title>别瞧不起「提示词」芝大论文爆火：Prompt Science已被定义</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500813&amp;idx=1&amp;sn=85ce2f98662b5809aa9f582405190d24&amp;chksm=ce62fb1287811c7217859a56d088cc20ac056e69c4b444327f1c3d8d18f419de1bf4719d4e54&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[最近网上出现了一些很有趣的声音——"提示词已死"、"写提示词把自己写死了"，这些文章认为随着模型变得越来越智能，精心设计提示词的时代已经过去了。但芝加哥大学的最新研究却给出了完全相反的结论：promp]]></description><author>AI修猫Prompt</author><pubDate>Thu, 03 Jul 2025 21:37:13 +0800</pubDate></item><item><title>Doc2Agent“爬”了所有API文档，一键API，MCP简单了</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500675&amp;idx=1&amp;sn=fd2e962d9dfe3ee0dd82c55f1c174e6c&amp;chksm=cefd63a28248f03f815f937356813e1267cad794a03555f9173daae6b2fa2687d3ca2ce81882&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[我想问您一个问题：上次为了让AI代理调用某个第三方API，您花了多长时间写包装代码？一天？三天？还是一周？不过现在，Brandeis大学的研究者们带来了一个让人眼前一亮的解决方案——Doc2Agent]]></description><author>AI修猫Prompt</author><pubDate>Fri, 27 Jun 2025 21:24:21 +0800</pubDate></item><item><title>连不上Gemini CLI，试下DeepSeek-R1接入Claude code</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500648&amp;idx=1&amp;sn=781d597fb20c8f21aa903bdea54e0046&amp;chksm=cecfb907af31e22cd64c658d5cc072f0bb30a29bddb81eb1d41b564e0024f0a50afcdcfeef8f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[这两天Google推出了Gemini-CLI这个编程工具，功能和Claude Code基本一致，结果根本排不上队，登录一下很快闪退，和下图一样，使用感受令人不愉悦。很多人都在等着体验这个新工具，但现实]]></description><author>AI修猫Prompt</author><pubDate>Thu, 26 Jun 2025 22:06:10 +0800</pubDate></item><item><title>放弃幻想！伯克利重磅：消灭幻觉，就是消灭AI！</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500583&amp;idx=1&amp;sn=dd006edcdc8fedcc91cf7ac2bf213a27&amp;chksm=ce98b1b27c04f006eb166650e6f9ef9fcbb93a5c710dadfc70eecd11fbc2c2db695adfe4ffde&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[关于大模型产生幻觉这个事，从2023年GPT火了以后，就一直是业界津津乐道的热门话题，但始终缺乏系统性的重磅研究来深入解释其根本机制。今天，伯克利的研究者们带来一个重要研究成果：让基于Transfor]]></description><author>AI修猫Prompt</author><pubDate>Sun, 22 Jun 2025 21:37:50 +0800</pubDate></item><item><title>能自我提升的Agent需要内在的元认知学习能力。| 剑桥ICML最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500547&amp;idx=1&amp;sn=3474486485e792c67f9946b1d3ed832e&amp;chksm=ce314a17c3e4290b8cba580936913f3f6d12b6e6a48dfc4994b4e3812dc19a18acfa43ac4d95&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[剑桥大学和范德夏尔实验室在 ICML 2024 上发表的立场论文，直接挑战了当前Agent开发的核心假设：我们一直在用错误的方式让Agent"自我改进"。论文作者 Tennison Liu 和 Mih]]></description><author>AI修猫Prompt</author><pubDate>Thu, 19 Jun 2025 21:28:21 +0800</pubDate></item><item><title>未来「含人量」多少，决定你值多少钱？斯坦福发布2025年重磅AI「工作内参」</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500540&amp;idx=1&amp;sn=5abda63223c61c0050b1f11566e44876&amp;chksm=ce705b7cc4418ddfc0534309fc74d222bc446c1005a2fa583e9b3a7a31c88b3839d32e93d846&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[您最近是不是老听同事讨论"我的工作会被AI替代吗"？别慌，斯坦福大学刚刚发布了一份重磅研究报告，用史上最大规模的数据告诉您真相。你敢想象吗？你的工作“含人量”多少，决定你值多少钱？“含人量”是我首次创]]></description><author>AI修猫Prompt</author><pubDate>Wed, 18 Jun 2025 22:03:44 +0800</pubDate></item><item><title>微软已为Agent悄然调转船头，当大厂都在卷“通用Agent”</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500519&amp;idx=1&amp;sn=778a1461fd92dd42039671d07eed0383&amp;chksm=ce642bfc350739c9653572ada8450a8cfd0cc416bc3fb09af7a2f47d778d12a863938c0421a0&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[您有没有这样的体验？一天的工作里，您可能用GPTo3写了个方案，然后切换到Cursor或者Trae里写代码，接着又打开Notion或者飞书整理文档。每个工具都挺聪明，但它们彼此之间就像生活在平行宇宙—]]></description><author>AI修猫Prompt</author><pubDate>Tue, 17 Jun 2025 21:43:45 +0800</pubDate></item><item><title>Agent不长记性咋整？试试G-Memory，可进化的有组织“集体大脑”</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500503&amp;idx=1&amp;sn=ee310c4fdabd98122fbbf8bc7d1980f4&amp;chksm=ce84eaf923c9ca54fe26845e31902d53d6b9c07319cf99d9234c26ce60dd86eceb43a8e50e13&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[G-Memory研究团队 投稿新加坡国立大学、同济大学等 | 技术解读自Agent火了以后，有关"记忆"的框架如雨后春笋般涌现，但绝大多数仍是为"单兵作战"设计，难以适应需要复杂协作、信息交互量暴增1]]></description><author>AI修猫Prompt</author><pubDate>Sun, 15 Jun 2025 21:57:21 +0800</pubDate></item><item><title>专治不服！Amazon重磅发布！AI的SOP高考来了！顶级Agent能考几分？</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500454&amp;idx=1&amp;sn=ec5ce186a05cd103f80fa01cb5ff2cd7&amp;chksm=ce1ad7a58973ca45b94d71e0410dde5f49752f941e9f0a3c1d333f40bb8f74aa0e9ba983d538&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[您可能会问，LLM Agent的SOP到底是什么，为什么称它为AI的高考？SOP全称是标准操作程序（Standard Operating Procedures）很多朋友可能很熟悉，但它绝不是简单的步骤]]></description><author>AI修猫Prompt</author><pubDate>Fri, 13 Jun 2025 06:50:00 +0800</pubDate></item><item><title>别再信“LRM无需优化提示词”了，你至少输掉23%的性能，以R1为例</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500436&amp;idx=1&amp;sn=42eaf5a6d4d06a98ce503098fba8ead5&amp;chksm=ce3930d0f39812e0f6e7f4d26997b55725447af3a8cf68fc6dc5b6af3bda2fa05c0ac3df433a&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[还记得DeepSeek-R1发布时AI圈的那波狂欢吗？"提示工程已死"、"再也不用费心写复杂提示了"、"推理模型已经聪明到不再需要学习提示词了"......这些观点在社交媒体上刷屏，连不少技术大佬都在]]></description><author>AI修猫Prompt</author><pubDate>Thu, 12 Jun 2025 00:03:13 +0800</pubDate></item><item><title>14种主流Prompt技术，顶级团队2000次实验，只有这几种真能打</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500428&amp;idx=1&amp;sn=b2343c313ab3c822d950b7bcdc8d174a&amp;chksm=cee1921d530f04bb732d9d228b73e217098144d4d12d0be7869d7850568e45489b48ee6ef787&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[现在市面上有46种Prompt工程技术（论文中引用的数据，和我去年这个时候介绍的论文是一致的《防骗| 连这些引用量最高的核心Prompt都不知道，还敢打着专家大师旗号蒙人》），但真正能在软件工程任务中]]></description><author>AI修猫Prompt</author><pubDate>Wed, 11 Jun 2025 00:03:00 +0800</pubDate></item><item><title>沃顿商学院重磅Prompt报告：别再对AI&quot;循循善诱&quot;了！我们在错误地使用它！</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500403&amp;idx=1&amp;sn=d6e30f708db5e33e369ea4b6d0c90fd2&amp;chksm=ce3e52e9d0f247948ad901abe289c81ab24b29fd6abf27bcd2085820ae41ca6dabe7cb21c2d7&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[宾夕法尼亚大学沃顿商学院生成式AI实验室刚刚发布了两份重磅研究报告，通过严格的科学实验揭示了一个令人震惊的事实：我们可能一直在用错误的方式与AI对话。这不是胡说八道，而是基于近4万次实验得出的硬核数据]]></description><author>AI修猫Prompt</author><pubDate>Tue, 10 Jun 2025 00:26:50 +0800</pubDate></item><item><title>LLM已进入「组装」时代，CAIS复合人工智能系统来了</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500373&amp;idx=1&amp;sn=3e8bb262967138b9480bcb20f9c5c5bb&amp;chksm=cef7d7ed6f841afffc39e869ab5d19c5af58ab2bbcbb9a8244c3b54e0c2fb04e8e904583bc5a&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[2024年，伯克利人工智能研究中心（BAIR）率先提出了一个新概念——复合人工智能系统（Compound AI Systems，简称CAIS）。这个看似简单的术语背后，蕴含着AI系统架构的根本性改变：]]></description><author>AI修猫Prompt</author><pubDate>Mon, 09 Jun 2025 06:40:00 +0800</pubDate></item><item><title>大语言模型(LLM)面试50题（含答案）</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500352&amp;idx=1&amp;sn=6d3449956f4e1b5f720ca5bd10fabca9&amp;chksm=ce3e9208c0d4e01cb31d44bb7e92a84d2b1117f031c5fe22d51f51c29a33e2b89ffdbe8b8d86&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[通过这份全面指南探索大语言模型(LLMs)的关键概念、技术和挑战，专为AI爱好者和准备面试的专业人士精心打造。引言大语言模型(LLMs)正在革命性地改变人工智能领域，支持从聊天机器人到自动化内容创建的]]></description><author>AI修猫Prompt</author><pubDate>Sat, 07 Jun 2025 22:49:13 +0800</pubDate></item><item><title>RAR让Agent学会「成为角色」那样思考，而不仅是「像角色」一样说话 |最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500287&amp;idx=1&amp;sn=afe2cc10f0a79e8869da21fce6629706&amp;chksm=ceaf1e328c9aa83cab7ff842b078db12a9e06322a91ec85604b85b7d5529548c233d92e96dff&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[您有没有发现，现在市面上的AI角色扮演的Agent总有种「隔靴搔痒」的感觉？用户和AI聊天时，AI虽然能说出符合角色设定的话，但总觉得缺了点什么——就像演员在背台词，而不是真的在思考。感觉很假，也很奇]]></description><author>AI修猫Prompt</author><pubDate>Fri, 06 Jun 2025 00:20:03 +0800</pubDate></item><item><title>RMoA残差提取Mixture-of-Agents，让Agent发现新东西，并自适应停止「ACL2025」</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500273&amp;idx=1&amp;sn=49a17d9fa353159e9c449e8fc34b3b21&amp;chksm=cea105fa68cc0d656739a74f9d18dc54c712d526ec82cad14ea4e3846209800407c0e43aff86&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[华东师范大学、美团、东华大学、清华大学联合研究团队提出的RMoA框架，最大限度地提高模型响应的信息利用率，同时最大限度地降低计算成本，本文已被ACL2025接受。论文地址：https://arxiv.]]></description><author>AI修猫Prompt</author><pubDate>Thu, 05 Jun 2025 04:12:50 +0800</pubDate></item><item><title>自进化零监督多Agent框架： MAS-ZERO，让AI因地制宜动态适应</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500181&amp;idx=1&amp;sn=34b33f7344d04d75e6d3eef68818c7dd&amp;chksm=ce39d0c4025a599a6554a33dfceab426c16a0d301e19e4034ee6b11d91d385e900dd91c0779d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[📋 TL;DR💡 启发：主席在《矛盾论》中强调"具体问题具体分析，是Marxism的活的灵魂"。而在AI领域，我们终于有了一个能够践行这一哲学思想的技术框架——MAS-ZERO，帮我们构建能够因地制]]></description><author>AI修猫Prompt</author><pubDate>Fri, 30 May 2025 01:03:05 +0800</pubDate></item><item><title>MetaMind元认知多智能体，让LLM理解对话背后的深层意图，首次达到人类水平 | 最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500154&amp;idx=1&amp;sn=bd44dd45c361e259d36dd8aec943fdd5&amp;chksm=cedbae3d74bf13af9a115eff5d5c97669393eabb71ea9d345dd6f7be9c57010a628969804ddd&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[TL;DRMetaMind是一个多智能体框架，专门解决大语言模型在社交认知方面的根本缺陷。传统的 LLM 常常难以应对现实世界中人际沟通中固有的模糊性和间接性，无法理解未说出口的意图、隐含的情绪或]]></description><author>AI修猫Prompt</author><pubDate>Thu, 29 May 2025 01:28:48 +0800</pubDate></item><item><title>动态数据太折磨人！静态RAG搞不定，就试下ZEP，让Agent调用实时知识图谱。</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500135&amp;idx=1&amp;sn=e73155fee46b4c453cb9e2ca70decddb&amp;chksm=cefbb80813838ac83dba4993ef41b48f3cea1b1707800789e0b2e5c1933c0952967fd988054b&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[您是否遇到过这样的困扰：明明搭建了完善的RAG系统，但Agent总是回答过时的信息，或者面对历史偏好变化时一脸茫然？三个月前说喜欢激进投资策略，两周前改口要稳健配置，今天又想尝试新兴市场，传统RAG]]></description><author>AI修猫Prompt</author><pubDate>Wed, 28 May 2025 07:58:45 +0800</pubDate></item><item><title>99%的人都理解错了，AI Agent ≠ Agentic AI，康奈尔大学发33页论文澄清关键区别。</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500120&amp;idx=1&amp;sn=ad2c32d979a1deeb883e9829e9d2a366&amp;chksm=cea0731cf40537f98f069e2b274188efb90aa495b96d82e1cb0a9f291f31ed5fa46279098372&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[TL;DR：如果您有一个AI产品，用户问您这是AI Agent还是Agentic AI？如果您回答不出来，或者认为这两个概念是一回事，那您可能需要重新审视自己的技术认知了。不过没关系，因为99%的人]]></description><author>AI修猫Prompt</author><pubDate>Tue, 27 May 2025 02:04:59 +0800</pubDate></item><item><title>没有银弹，没有免费午餐！KtR用算法思维重构Multi-Agent设计</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500075&amp;idx=1&amp;sn=31776816c6b81bc8806d369d2f9cc5e2&amp;chksm=ce1372e57a51231b72bc1565125c91ba772ecfa3cda8c770c3a5096d0a44f4bdb38560513b6b&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[🌟 TL;DR：多智能体的美好愿景与残酷现实1986年，图灵奖得主Fred Brooks在软件工程领域提出了著名的"没有银弹"理论：没有任何一种技术或方法能够独自带来软件工程生产力的数量级提升。近四]]></description><author>AI修猫Prompt</author><pubDate>Mon, 26 May 2025 07:28:39 +0800</pubDate></item><item><title>Claude4来了。。。太卷了，已超越Gemini2.5Pro</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500056&amp;idx=1&amp;sn=7f80665b28c310fa8ec743955e3b9c21&amp;chksm=ce9260cddf4c79992222fd11c18a424f635d790d06d6801c21ac7f44eaea660800c3314b05a0&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Anthropic公司正式发布Claude 4系列模型，在编程能力和推理表现上全面领先，发布后10分钟，Cursor也可以用了。。。📢 重磅登场：AI界迎来新标杆Anthropic公司在2025年5]]></description><author>AI修猫Prompt</author><pubDate>Fri, 23 May 2025 01:19:04 +0800</pubDate></item><item><title>HALO，基于MCTS的层次化动态提示框架，让Agent总能找到最优路径 | 最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500037&amp;idx=1&amp;sn=c133db4a08478ef7b7e14f5b40f7a295&amp;chksm=cede506e0e8fec2641c472e2c5642e790c1dc0d53dc2314e3b43c8faa5478a8747ad42d74888&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[导读：HALO框架通过三大创新机制重塑多Agent(MAS)协作方式：层次化推理架构克服了认知过载问题，让智能体各司其职；动态角色实例化能针对不同任务匹配专业智能体；基于MCTS的搜索引擎自动探索最]]></description><author>AI修猫Prompt</author><pubDate>Thu, 22 May 2025 07:30:00 +0800</pubDate></item><item><title>缺乏高质量用户数据咋整？试下J.P.摩根的最新框架，帮你无中生有撒豆成兵</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247500019&amp;idx=1&amp;sn=30c8606360340edd7b2a78eaf1dd5362&amp;chksm=ce8701b0c57a1058009ae387a36bedd26f29ec4aafb83059a77287bdff1929ae2d49794d91f6&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[📌 导读产品刚上线缺乏用户数据，巧妇难为无米之炊，怎么办？JPMorganChase团队开发的框架完美解决了这一痛点！针对金融领域短文本查询识别难、新产品缺乏用户数据的冷启动问题，该框架创新性地结合]]></description><author>AI修猫Prompt</author><pubDate>Wed, 21 May 2025 07:10:00 +0800</pubDate></item><item><title>可靠的Agent该用哪个模型，LLM多轮对话中的「迷失」现象 |微软最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499992&amp;idx=1&amp;sn=7ed070468254005c874503c03d8890fb&amp;chksm=ce4e666ca80bff12c0a0a2d002024b097e83fb20cc7ddf3fe888e8fb09d9ea151e56295e433f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[导读：微软最近与Salesforce Research联合发布了一篇名为《Lost in Conversation》的研究，说当前最先进的LLM在多轮对话中表现会大幅下降，平均降幅高达39%。这一现]]></description><author>AI修猫Prompt</author><pubDate>Tue, 20 May 2025 07:40:00 +0800</pubDate></item><item><title>换模型就得重新优化提示词？用下MetaSPO，专门优化系统提示的Meta-Learning框架 | 最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499968&amp;idx=1&amp;sn=cae106098c03b06c505600b9c0f5ac63&amp;chksm=ce81868a4142d59be7efa26cf0d279e21a17bc12e6180ee4ab56c7da9e462dce4dac7bedf919&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[导读： 每次更换语言模型就要重新优化提示词？资源浪费且效率低下！本文介绍MetaSPO框架，首个专注模型迁移系统提示优化的元学习方法，让一次优化的提示可跨模型通用。我在儿童教育场景的实验验证了效果：]]></description><author>AI修猫Prompt</author><pubDate>Mon, 19 May 2025 06:55:00 +0800</pubDate></item><item><title>表格RAG语义割裂，用Pneuma+SAT增强检索准确性和效率 |最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499952&amp;idx=1&amp;sn=963dec37a71fcdbe0436afd462f479da&amp;chksm=ce625682bc8d0c18fba72d855784e76a951e25f7e1de326698813307f40a0852fca3f7118fec&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[导读：在上一篇文章中，我为大家介绍了SAT如何通过神经网络驱动的智能分段技术，解决传统文本处理中的语义割裂问题。今天，我将继续与您探讨SAT如何与Pneuma系统融合，开创表格数据检索与表示的新范式]]></description><author>AI修猫Prompt</author><pubDate>Fri, 16 May 2025 06:50:00 +0800</pubDate></item><item><title>讨厌RAG生成幻觉？试一下SAT重构文本分块，按语义而不是Token</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499936&amp;idx=1&amp;sn=47850fcee1c29c7edc396bce7e3db045&amp;chksm=cea0944e25267282f3b667b5cc492d3f126a7b32eda65ccc2283290f24af937d46ae3393c9d5&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[导读：搞RAG开发，一个被普遍忽视却又至关重要的痛点是：如何避免Token分块带来的语义割裂问题。SAT模型通过神经网络驱动的智能分段技术，巧妙解决了这一难题。它不是RAG的替代，而是RAG的强力前]]></description><author>AI修猫Prompt</author><pubDate>Thu, 15 May 2025 07:39:00 +0800</pubDate></item><item><title>精准提取数据太折磨人，试下pip install -U contextgem，自动生成提示 | 痛快</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499921&amp;idx=1&amp;sn=6878c1be954f6fd0ea0840d66ba465f4&amp;chksm=ceb2ffb6f7c3cf887e77354c8051fe5d44a7fbe59a625d61c14132a23c1b92ce9e368b83bcf3&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[导读：最近ContextGem很火。它既不是RAG也不是Agent，而是专注于"结构化提取"的框架，它像一个"文档理解层"，通过文档中心设计和神经网络技术(SAT)将非结构化文档转化为精确的结构化数]]></description><author>AI修猫Prompt</author><pubDate>Wed, 14 May 2025 06:55:50 +0800</pubDate></item><item><title>忘掉那个「4+4」吧！Agent开发你至少看过这4个PDF+4个开源项目。 | 万字长文</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499896&amp;idx=1&amp;sn=28b1a1ecccc5a746106d371ddc5e62fe&amp;chksm=cefa00e29f1bee09dce383853b4063568256fb8df5353e82a8016d2de870c9b1b4916d33b376&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[2025年已过近半，当很多朋友还在为社交媒体上的4+4新闻激动时，不少默默钻研技术的开发者已经在Agent开发热潮中抢占先机。如今，Agent技术已成为AI领域的制高点，不论是微软、Google还是]]></description><author>AI修猫Prompt</author><pubDate>Tue, 13 May 2025 06:50:00 +0800</pubDate></item><item><title>斯坦福的以弱驭强W4S，用Meta-Agent驾驭更强的LLM，准确率提升至95.4% | 最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499860&amp;idx=1&amp;sn=2490b2f1641da77105f8f49d1047838b&amp;chksm=ce71a786ef1b7cd7f2356d98024e3e6c548cd82011317e88073edd1a92b5cd1e5dbcf6c4897a&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[[读者导读]本文详细介绍了斯坦福大学最新提出的"以弱驭强"（W4S）范式，这一创新方法通过训练轻量级的弱模型来优化强大语言模型的工作流。核心亮点包括：1. 通过马尔可夫决策过程和强化学习实现弱模型自]]></description><author>AI修猫Prompt</author><pubDate>Mon, 12 May 2025 07:54:35 +0800</pubDate></item><item><title>谷歌DeepMind&amp;CMU：过去引导LLM规划的方法是错的？ 用GRASE-DC改进。ICLR2025</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499830&amp;idx=1&amp;sn=b169eef4820bdf838c5997583ce41008&amp;chksm=ce274d73a8274ed8b45899112dcd75b530880bf7ce1a562253006313445db73d5ad540ae5cb7&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[当您的Agent需要规划多步骤操作以达成目标时，比如游戏策略制定或旅行安排优化等等，传统规划方法往往需要复杂的搜索算法和多轮提示，计算成本高昂且效率不佳。来自Google DeepMind和CMU的研]]></description><author>AI修猫Prompt</author><pubDate>Thu, 08 May 2025 23:59:06 +0800</pubDate></item><item><title>南加州大学和苹果重磅：用「心理支架」PB&amp;J提升AI角色扮演能力，让Agent更懂用户</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499813&amp;idx=1&amp;sn=0cdac4089b4290fda8fd05b607d407f7&amp;chksm=ce2577367fd59b25e2da9f89273931d69edc73f1458d74984f1379f55ec49f41520e5e0bf2a6&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[文章导读照这个发展速度，不远的将来AI不仅能模仿你的行为，还能理解你为何做出这些选择。PB&J框架正是这一突破性技术的代表，它通过引入心理学中的"支架"概念，使AI能够构建合理化解释，深入理解人类决]]></description><author>AI修猫Prompt</author><pubDate>Wed, 07 May 2025 06:50:00 +0800</pubDate></item><item><title>最新发现：大规模值，注意力机制的关键密码。ICML2025</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499791&amp;idx=1&amp;sn=91ae8f8a5f24602bd3d34c718bf2c350&amp;chksm=ce79dbaebb4889529cae188d0f21ada1d801c649aa484bdcabab3db47dcaf67cda3718462798&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[当我们惊叹于大语言模型强大的上下文理解能力时，你是否好奇它们是如何做到这一点的？本文详解罗格斯大学张永峰团队的突破性发现——注意力机制中的"大规模值"现象，这一被ICML顶会收录的研究揭示了LLM处]]></description><author>AI修猫Prompt</author><pubDate>Tue, 06 May 2025 07:30:00 +0800</pubDate></item><item><title>如何在LLM「排行榜幻象」中导航？2025AI界震撼大瓜，披露学术造假</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499774&amp;idx=1&amp;sn=ab449b02d4fa7bedcb6054b2269628f2&amp;chksm=ce97e9db66da99e39228f03ea5013231df2276c0606460fde5898d2efe00a8c4320fd9cef6c7&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[编者按：你信任的AI排行榜，可能只是一场精心策划的骗局！震惊业界的Cohere Labs最新研究彻底撕破了Chatbot Arena这一所谓"黄金标准"的华丽面纱，揭露了科技巨头们如何肆无忌惮地操控评]]></description><author>AI修猫Prompt</author><pubDate>Fri, 02 May 2025 01:49:02 +0800</pubDate></item><item><title>Agent评估「必知」的核心方法论和8个工具，揭示如何评估Agent？</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499756&amp;idx=1&amp;sn=8e746d4db4d632b5324f16c6e6c27090&amp;chksm=ce36d626f4c3006d14b0c651bb33f8c1f89a7e2c74312a864cafb77e0e9703f4bf9e18fdc68d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[编者按：随着基于大语言模型的智能代理（LLM-based Agents）迅速走向实际应用，一个关键问题日益凸显：我们如何有效评估这些系统的真实能力？表面上的流畅对话或单一任务完成率已不足以判断Agen]]></description><author>AI修猫Prompt</author><pubDate>Wed, 30 Apr 2025 13:30:01 +0800</pubDate></item><item><title>如何打造TTRL测试时强化学习+Memory的Agent，做经验时代AI的主人。| 最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499743&amp;idx=1&amp;sn=6e12dc6db085af603e963ac2bd313672&amp;chksm=ce05ec0e3e4a06d64c0a191774887d256ad7b939fefc87ce992732b7fb25d132fe3177ae1188&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[编者按：AI能像人类一样不断从经验中学习、进化，而不仅仅依赖于人工标注的数据？测试时强化学习(TTRL)与记忆系统的结合正在开启这一全新可能！本文深度解析了这项突破性技术如何让AI实现自我监督学习，在]]></description><author>AI修猫Prompt</author><pubDate>Mon, 28 Apr 2025 06:50:00 +0800</pubDate></item><item><title>用&quot;ADL&quot;Agent声明式语言，让你几分钟上线一个Agent | UCSB最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499729&amp;idx=1&amp;sn=728418b4955e1540c6a2c1874ac2b58f&amp;chksm=ce16e6e5db09035137ad23773a06ef9f2143305a9361a5c8d60a95a147af06af336460f5eba2&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[今天的Agent框架虽然功能强大，但对于没有编程经验的客户服务专业人员来说却过于复杂。这些框架如AutoGen、LangGraph、CrewAI等通常将Agent声明嵌入到复杂的Python代码中，使]]></description><author>AI修猫Prompt</author><pubDate>Fri, 25 Apr 2025 01:02:59 +0800</pubDate></item><item><title>校准LLM元认知能力，Agent才能清晰地向用户传达不确定性 | 重要</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499717&amp;idx=1&amp;sn=eb12713f0bdbb0d44e9c886072fd613d&amp;chksm=ce8fa362310207a035154345e62cf5ca147fca90022582a337f1532bc661422283ec27f50899&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[编者按：随着大型语言模型（LLMs）日益融入关键决策场景，其元认知能力——即识别、评估和表达自身知识边界的能力——变得尤为重要。本文基于Steyvers和Peters的前沿研究，全面剖析了人类与大模型]]></description><author>AI修猫Prompt</author><pubDate>Thu, 24 Apr 2025 07:20:00 +0800</pubDate></item><item><title>哇！首个MCPBench来了，MCP竟然不比Function Calls更有优势？ | 最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499707&amp;idx=1&amp;sn=0355e3540cc863a58318257ba8f33cee&amp;chksm=cea90527be1e248a51273c29654c09a6625c7ba4ac9ee44df1f3764b342179eb06cfd65d87f6&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[【编者按】你是否正在投入大量资源开发基于MCP的Agent，却从未质疑过一个基本假设：MCP真的比传统函数调用更有优势吗？ 2025年4月的这项开创性研究直接挑战了这一广泛接受的观点，其执行摘要明确指]]></description><author>AI修猫Prompt</author><pubDate>Wed, 23 Apr 2025 07:30:00 +0800</pubDate></item><item><title>用ToM激活Agent的&quot;共情引擎&quot;，让Agent真正&quot;懂人心&quot;。 | 最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499680&amp;idx=1&amp;sn=13bb029896a9cc3c64ce8d6a9de129c9&amp;chksm=cea183af355009fda5f8166d1dde50d809e21e8a9102c94c54dbab2c714262dbffd178bb1b4a&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[编者按：在当今对话式AI的发展浪潮中，技术门槛不断降低，但真正打动用户的Agent却寥寥无几。差距在哪里？根本原因是大多数AI系统缺乏对人类心理状态的深度理解能力。本文深入解析了一项突破性研究，揭示了]]></description><author>AI修猫Prompt</author><pubDate>Tue, 22 Apr 2025 06:50:00 +0800</pubDate></item><item><title>谷歌联合强化学习之父：通过经验学习的4大核心，Agent将获得超人能力 |最新战略瞭望</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499665&amp;idx=1&amp;sn=7ab30be6b3e6b5e62bfc6a00e33616c6&amp;chksm=cefdfced7143485d391e04086974af9da0cf2e5bd09f983495b67b4fefdf48e5d7d158d7e549&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[编者按这不是一篇介绍研究方法或某种技术改进paper的文章，本文对DeepMind两位泰斗级科学家David Silver和Richard Sutton的重磅论文《Welcome to the Era]]></description><author>AI修猫Prompt</author><pubDate>Mon, 21 Apr 2025 07:01:00 +0800</pubDate></item><item><title>两个脑袋比一个好。自适应Multi-Agent框架M500实现41%的提升。| 最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499651&amp;idx=1&amp;sn=c4b9efa879ac186d243d044262cb9d17&amp;chksm=ce347a1dc3fc5c2fde5d2cb2d33eb70751984c20fe708eddd0e6187c1e67b21e0471e6baf1bd&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Two Heads are Better Than One"（两个脑袋比一个好/双Agent更优）源自英语中的一句古老谚语。MAS-TTS框架的研究者将这一朴素智慧应用到LLM中，创造性地让多个智能]]></description><author>AI修猫Prompt</author><pubDate>Fri, 18 Apr 2025 07:10:00 +0800</pubDate></item><item><title>142页重磅，DeepSeek-R1的&quot;甜蜜点&quot;，开创了一个崭新的研究领域“思维学”。 | 最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499635&amp;idx=1&amp;sn=8e07e5207b2468c801b4d84c52d701c7&amp;chksm=cec7ffa49a8cc3fea56550cb26ed148ef8172cdd767ca0a63e2c9db9367f409b490930b8b9d4&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[【编者按】这是一份142页的研究论文，本文深入解析了大型推理模型DeepSeek-R1如何通过"思考"解决问题。研究揭示了模型思维的结构化过程，以及每个问题都存在甜蜜点"最佳推理区间"的惊人发现。]]></description><author>AI修猫Prompt</author><pubDate>Thu, 17 Apr 2025 07:10:00 +0800</pubDate></item><item><title>究竟该用哪一个？A2A 与 MCP 协议及三大核心差异，PocketFlow作者重磅解析 | 最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499634&amp;idx=1&amp;sn=28d96920ac8ff145afa7824159558636&amp;chksm=cedb442cc360554efb6b6be30776eea50440b38846acb851a3110cf55cb9b39e531e866dde09&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[想象一个世界：AI 智能体不再仅仅为你工作，更能彼此协作，形成强大的合力。谷歌的智能体到智能体（A2A）协议，正致力于将孤立的 AI 执行者转变为高效的协作团队。但它与 Anthropic 的模型上]]></description><author>AI修猫Prompt</author><pubDate>Wed, 16 Apr 2025 06:21:03 +0800</pubDate></item><item><title>搞定Agent的&quot;失忆症&quot;，TME树状记忆引擎让Agent再也不会&quot;忘记&quot;之前做过什么。| 最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499609&amp;idx=1&amp;sn=387d86683addb1a83a2cbc14b991fdfb&amp;chksm=ce2e8ffc814a6a251ef76a905a71305df1cb0625f53f503880bd1f9db822dd7791ec1a85294c&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[开发Agent的工程师们都曾面临同一个棘手问题：当任务步骤增多，你的Agent就像患上"数字健忘症"，忘记之前做过什么，无法处理用户的修改请求，甚至在多轮对话中迷失自我。不仅用户体验受损，token]]></description><author>AI修猫Prompt</author><pubDate>Tue, 15 Apr 2025 07:10:00 +0800</pubDate></item><item><title>用IBM的AutoPDL，让Agent的prompt实现数据驱动的自动优化，性能飙升68.9% |重磅</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499596&amp;idx=1&amp;sn=05d79000f397195a089b63ff423240aa&amp;chksm=ce24ba64fa7c2c415b5cce02b231afa2bda9152b0becd543a84fd6a9715f2693dd285ef6ab7d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[早在去年10月底IBM推出了PDL声明式提示编程语言，本篇是基于PDL的一种对Agent的自动优化方法，是工业界前沿的解决方案。您可以移步：重磅！IBM：PDL提示词声明语言，帮你拿回Prompt控]]></description><author>AI修猫Prompt</author><pubDate>Mon, 14 Apr 2025 13:40:00 +0800</pubDate></item><item><title>用PocketFlow为Github庞大代码库自动生成教程，一次性彻底搞懂庞大项目！| 最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499573&amp;idx=1&amp;sn=e8b5c9b0e4bddfb3252aa0f71557e2bd&amp;chksm=ced2de8b79f17975af100fd698c391918971890d19990a5af7857ef09463b17f201239806cba&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[你是否曾被一份体量巨大的代码库困住，找不到下手的方向？是否希望有个 AI 能帮你快速梳理出项目的整体架构、关键模块及设计思路？今天就来介绍一款强大工具——"代码库知识构建器 (AI Codebase]]></description><author>AI修猫Prompt</author><pubDate>Thu, 10 Apr 2025 08:14:17 +0800</pubDate></item><item><title>别让AI想太多！思考的临界点，运行长度才是推理精确度的决定因素 | 康奈尔哈佛最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499561&amp;idx=1&amp;sn=28b00484dd584d004afbefeddecb9985&amp;chksm=ce3a5f04c343ca33226b55715c4c7a9706252d22dfa48beeef99510bf41355f83e48f7a7d035&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[探寻最优推理长度的科学路径大语言模型（LLMs）在推理任务中的表现往往依赖于推理过程中生成的token数量，但究竟是任务难度的哪些方面决定了这一需求？康奈尔大学和哈佛大学的研究者（arXiv:250]]></description><author>AI修猫Prompt</author><pubDate>Wed, 09 Apr 2025 12:59:38 +0800</pubDate></item><item><title>用思维干预直接干预LRM内部推理，三种方式实现DeepSeek-R1有效控制。 | 最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499540&amp;idx=1&amp;sn=6210b85528e7a9b06e3d26924a75f3b9&amp;chksm=ce6b99318fb5fd57bdede0ad7c6522362c6821b0fcbc84f19d5e79852967927bacc078516666&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[从传统到创新：推理模型的控制方式之变推理增强型大语言模型LRM（如OpenAI的o1、DeepSeek R1和Google的Flash Thinking）通过在生成最终答案前显式生成中间推理步骤，在]]></description><author>AI修猫Prompt</author><pubDate>Tue, 08 Apr 2025 06:56:00 +0800</pubDate></item><item><title>开源深度搜索ODS：释放推理Agent的力量，比GPT-4o Search Preview的准确率提高9.7%</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499526&amp;idx=1&amp;sn=8e5aeecfaa23d59a889ddf9ad1f37b04&amp;chksm=ceb3db8b16a92f607495b55b507f792d5932b57d97816943af33d7b6d903724f9a32b5fd32f3&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[专有搜索AI的壁垒与开源解决方案当前搜索AI市场面临着一个显著的断层：Perplexity的Sonar Reasoning Pro和OpenAI的GPT-4o Search Preview等专有解决]]></description><author>AI修猫Prompt</author><pubDate>Mon, 07 Apr 2025 06:45:00 +0800</pubDate></item><item><title>当LLM遇到结构化思维困境，这个70年前的心理学框架竟成为救星 | 最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499500&amp;idx=1&amp;sn=f6e74c7bccf8a01d1f95b4f5ff09bfad&amp;chksm=ce490a03aaedd9ea8615a22a03e2d73a84b8aaab40b0be5dd4f4b975501aacc849969e9c2fb6&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[编者按：当大多数AI Agent仍在挣扎于结构化推理能力不足的困境时，本文带来了一个来自认知科学领域的突破性解决方案。作者Oliver Kramer来自德国奥尔登堡大学（University of]]></description><author>AI修猫Prompt</author><pubDate>Thu, 03 Apr 2025 15:01:58 +0800</pubDate></item><item><title>请立即删除不当图片、标识！立刻，马上自查自纠，不要因为“没注意”站在历史对立面</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499489&amp;idx=1&amp;sn=d39bfe212edb8bdf3f4c9d426626ceb7&amp;chksm=ce8bee3dc2cbd8cadcd985ea8ca0fa79d72be4e99a815ba41a7db3adc8e346a56d3e02d58f68&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[v 尊敬的读者朋友、技术同仁：当前，祖国统一大业已进入关键历史阶段，每一位中华儿女都在以不同的方式为民族复兴，祖国统一贡献力量。作为技术领域的探索者，广大AI学者和开发者既是科技创新的先锋，也理应是网]]></description><author>AI修猫Prompt</author><pubDate>Wed, 02 Apr 2025 06:56:00 +0800</pubDate></item><item><title>这篇综述，LLM代理的方法、应用和挑战，2025的Agent势头特别猛。| 重磅</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499472&amp;idx=1&amp;sn=b74b9cb1f8a6959bb75861269e5b5e94&amp;chksm=ced5b856a9a4da4fe6049ef316452f06758e197c5b10800e785fa7e58c5be9cafd70dd61d272&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Agent浪潮来袭2025年，人工智能领域正在经历一场由LLM Agent引发的深刻变革，不管普通人的衣食住行还是研究者的尖端研究，都很难不受Agent的影响。这篇来自中美顶级研究团队的综述论文，全]]></description><author>AI修猫Prompt</author><pubDate>Tue, 01 Apr 2025 06:57:00 +0800</pubDate></item><item><title>被LangChain折磨够了吗？试下100行代码打造的LLM有向图框架PocketFlow | 独家最新</title><link>http://mp.weixin.qq.com/s?__biz=Mzg4MzYxODkzMg==&amp;mid=2247499458&amp;idx=1&amp;sn=a57752a8007e64d94f2f4503c0934edb&amp;chksm=ce8127552ad75a51edb2514ac17cd2fbcb135777d43e39082391824fb8e2499f8ec5fd9b4df0&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[你是否曾对着一个繁复的AI框架，无奈地想："真有必要搞得这么复杂吗？"在与臃肿框架斗争一年后，Zachary Huang博士决定大刀阔斧地革新，剔除所有花里胡哨的部分。于是Pocket Flow诞生]]></description><author>AI修猫Prompt</author><pubDate>Mon, 31 Mar 2025 07:02:00 +0800</pubDate></item></channel></rss>