<?xml version="1.0" encoding="utf-8"?><rss version="2.0"><channel><title>字节跳动Seed</title><link>https://wxrss.reinject.top/3b624ae9fc775ca722f9318f466a0330/</link><description>An RSS feed.</description><language>zh-cn</language><lastBuildDate>Sun, 01 Mar 2026 15:47:46 +0800</lastBuildDate><generator>wxrss -- https://github.com/0xlane/wxrss</generator><item><title>Seed2.0 正式发布</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247493260&amp;idx=1&amp;sn=0e5cb2fe7f772d98a6a7d28b0a5d9053&amp;chksm=c3e63aeab69a09c066e3cfbc745b8be5262022793f0f9dbe2a7ace42b494d6d7e7fca6086b89&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[大语言模型驱动的产品已深刻融入我们的生活。过去一年多，Seed 开发的 LLM 模型系列已支持豆包等拥有上亿用户的 C 端产品，同时，我们也注意到，随着 Agent 时代到来，LLM 将在现实世界的复]]></description><author>字节跳动Seed</author><pubDate>Sat, 14 Feb 2026 13:57:21 +0800</pubDate></item><item><title>“思考”更深，生成更准｜Seedream 5.0 Lite 发布</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247493186&amp;idx=1&amp;sn=faa34cfb2a17c66da163ffd28448aedb&amp;chksm=c390f3d63bb08cce5e58dbe8b6a4220fda9e7756bebcdd431772b4fa0fa424fa49f912b2488d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[去年 9 月，我们发布统一编辑与生成的图像创作模型 Seedream 4.0，它融合了部分常识和一定的推理能力，受到不少用户的欢迎。今天，我们推出 Seedream 5.0 Lite 智能图像创作模型]]></description><author>字节跳动Seed</author><pubDate>Fri, 13 Feb 2026 13:32:23 +0800</pubDate></item><item><title>Seedance 2.0 正式发布</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247493139&amp;idx=1&amp;sn=cbfcb3b1187cada134a23c94efb38cf7&amp;chksm=c342d34baacf2eef1df8f2bbf359771113ec118d953fd03ecb1409db638a919e5f2377c1b1f7&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[今天，我们正式发布新一代视频创作模型 Seedance 2.0。Seedance 2.0 采用统一的多模态音视频联合生成架构，支持文字、图片、音频、视频四种模态输入，集成了目前业界最全面的多模态内容参]]></description><author>字节跳动Seed</author><pubDate>Thu, 12 Feb 2026 12:50:05 +0800</pubDate></item><item><title>Seed Prover 1.5：全新 Agentic 架构，更强数学推理表现</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247492949&amp;idx=1&amp;sn=0e144a6b26a00d4911a9ab0c50ceb505&amp;chksm=c3623b8d78cc96e57c37e941ab5010a10b9042fe76daf202c43438f126de4b18d53d5838d45a&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[今年 7 月，字节跳动 Seed 团队受邀参加了 IMO 2025。我们的形式化数学推理模型 Seed Prover 通过 3 天的尝试，完整解决了 6 道题目中的 4 道以及一道题的部分证明，达到官]]></description><author>字节跳动Seed</author><pubDate>Wed, 24 Dec 2025 11:43:33 +0800</pubDate></item><item><title>通用Agent模型Seed1.8正式发布</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247492932&amp;idx=1&amp;sn=9f3a361b05486f3259b2de0ac98407a3&amp;chksm=c33dcba8419c0791e156ba71d255704bfa76645255b0f34eecd28bb3afa3e3b021a30798cdb7&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[随着大模型任务范围不断扩展，我们注意到，用户需求正从获取建议、查询信息，转向让模型直接执行复杂工作流。这意味着，通用模型必须具备更广泛的能力，超越现有语言生成的范畴。在此背景下，我们正式推出通用 Ag]]></description><author>字节跳动Seed</author><pubDate>Thu, 18 Dec 2025 12:10:32 +0800</pubDate></item><item><title>声画俱全，一镜入戏 | Seedance 1.5 pro 音视频创作模型正式发布</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247492897&amp;idx=1&amp;sn=c749c48beb3a26dfdf5307d2a6282831&amp;chksm=c36650a035992272e6ca209da59f4b9b696c354336d244b5b0a0753066743cbfb9564bc2e733&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[舞台中央，灯光聚焦，随着一段高亢的旦角唱腔，角色完成了一连串配合鼓点的长枪动作。这并非真实演出，而是 Seedance 1.5 pro 尝试一镜生成的创作片段，其演绎与专业戏曲表演尚有很大差距，但声韵]]></description><author>字节跳动Seed</author><pubDate>Tue, 16 Dec 2025 18:43:01 +0800</pubDate></item><item><title>Seed Research｜GR-RL 发布：突破VLA精细操作瓶颈，首次实现真机强化学习穿鞋带</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247492836&amp;idx=1&amp;sn=fc7a463bf2a409fe03edceff606a4876&amp;chksm=c38ba3ecf03bea51c856811be22d92106d3b31cd50699dadb7d5792e6971c86173db9e8da351&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在 Scaling Law 的推动下，具身智能正迎来关键突破，基于海量数据预训练的视觉-语言-动作（VLA）模型已展现出不错的通用泛化能力。然而，当我们将机器人的应用场景从理想的实验室环境搬进复杂的家]]></description><author>字节跳动Seed</author><pubDate>Tue, 02 Dec 2025 12:23:19 +0800</pubDate></item><item><title>Seed Research￨Depth Anything 3：单一Transformer架构实现任意视角空间重建</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247492792&amp;idx=1&amp;sn=c8db8f4ab5d6bb3e1d4f4751761c8be7&amp;chksm=c305e82fa09c57f2d5c52220d224070563887f5762fe7a6a00b8a0635cc9db64ec8c3d371efe&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[人类能够通过一张照片、一段视频，迅速在脑海中构建出一个空间的立体样貌。这种能力源于我们对不同视角空间几何关系的理解与推理，而机器想要理解、参与物理世界，就需要提升空间智能，对场景精准重建。当前的视觉空]]></description><author>字节跳动Seed</author><pubDate>Thu, 27 Nov 2025 11:30:00 +0800</pubDate></item><item><title>Seed3D 1.0 发布，一张图生成高精度 3D 模型，纹理生成能力 SOTA</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247492735&amp;idx=1&amp;sn=55ec7ab528a5cea7a808576cea4873bf&amp;chksm=c36e251ea7e7f9391abb0fe224d414810be24e13b959c2b5ed18af381879c2ae5cc041921f5d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[世界模拟器对具身智能的发展至关重要，理想情况下可为机器人训练提供复杂的场景模拟和高质量的合成数据，还能支持实时交互的训练环境。然而，当前技术依然面临瓶颈：基于视频生成的模拟器虽能产生逼真画面，但缺乏物]]></description><author>字节跳动Seed</author><pubDate>Thu, 23 Oct 2025 11:58:02 +0800</pubDate></item><item><title>不止会“画”，更会“想”｜Seedream 4.0 图像创作模型正式发布</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247492678&amp;idx=1&amp;sn=cb847c637e6becf1fb4d4f3f3eeaae65&amp;chksm=c3d28292e4d9cebbbc7439ce6251a13ade94704ca9ac08706c1721ca9c045f793d86d2becc1c&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[字节跳动 Seed 团队正式发布新一代图像创作模型 Seedream 4.0。Seedream 4.0 采用同一套构架实现文生图与通用编辑能力，融合常识和推理能力，相比前代模型 Seedream 3.]]></description><author>字节跳动Seed</author><pubDate>Tue, 09 Sep 2025 10:31:16 +0800</pubDate></item><item><title>解锁任意模态模型训练，字节跳动Seed开源VeOmni框架</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247492570&amp;idx=1&amp;sn=2c742663d81e4c65b06c87507243a2e3&amp;chksm=c30779cacf5ee95ac80f9dc9666115b5f636a5a01bbe67c7b8ab2c75759f93d214ff411b0a63&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[近年来，大模型技术正从单一文本模态，向包含图像、语音、视频等多种信息的“全模态”（Omni-Modal）理解生成方向演进。但目前训练一个能“看”、能“听”、能“说”的全能模型，依然面临着系统性的工程挑]]></description><author>字节跳动Seed</author><pubDate>Thu, 14 Aug 2025 16:26:37 +0800</pubDate></item><item><title>字节跳动Seed助力清华获机器人足球世界杯冠军</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247492500&amp;idx=1&amp;sn=99c046baac090afc7588fde082d1e29d&amp;chksm=c3d3d269f2709ad62c8cfa67d5d7838b89db3eda608bf5e3a3ab4c66f089117a50da5a4feea7&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[近日，2025 RoboCup 机器人世界杯人形组成人组比赛，即：RoboCupSoccer Humanoid League AdultSize，在巴西萨尔瓦多落下帷幕。由字节跳动 Seed 团队与清]]></description><author>字节跳动Seed</author><pubDate>Fri, 01 Aug 2025 12:38:27 +0800</pubDate></item><item><title>Seed Research￨每秒推理速度2146 tokens，扩散语言模型Seed Diffusion Preview发布</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247492498&amp;idx=1&amp;sn=bd557b41938c9477a439183abb1571a1&amp;chksm=c3bfcfd506c2b7050bf9da581ebd849a88abb430d9970a0e48110031ea360b466071bd5a391d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[固有的串行解码延迟是自回归（AR）模型无法回避的瓶颈。离散扩散（DD）模型为此提供了极具潜力的并行化解决路径，但此前其理论上的并行优势与实际可达成的推理加速效果存在显著差距。今天，字节跳动 Seed]]></description><author>字节跳动Seed</author><pubDate>Thu, 31 Jul 2025 19:54:45 +0800</pubDate></item><item><title>字节跳动Seed与比亚迪锂电池深化合作：将成立AI联合实验室加速电池研发</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247492014&amp;idx=1&amp;sn=d971ca44e1a3385263f19ecfbec8b0bd&amp;chksm=c3a4a39adde5c0836ad360fd53361e828727c083909eef98132bdd0f8e9772d7b35716bfb9f8&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[6 月 11 日，火山引擎 Force 大会公布，字节跳动 Seed 及火山引擎，将与比亚迪锂电池深化合作，通过联合实验室等形式，共同探索 AI for Science 结合高通量实验，加速锂电池研发]]></description><author>字节跳动Seed</author><pubDate>Wed, 18 Jun 2025 12:05:00 +0800</pubDate></item><item><title>Seedance 1.0 视频生成模型技术报告公开</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247491995&amp;idx=1&amp;sn=f13b4aca85af330f81442ee7e9badbeb&amp;chksm=c32969537fda0a6b016db3e69c22cace30d2984cb07df92902693a686ccd2b01a7e4e5c752cd&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[字节跳动 Seed 团队正式发布视频生成基础模型 Seedance 1.0。Seedance 1.0 支持文字与图片输入，可生成多镜头无缝切换的 1080p 高品质视频，且主体运动稳定性与画面自然度较]]></description><author>字节跳动Seed</author><pubDate>Wed, 11 Jun 2025 12:23:11 +0800</pubDate></item><item><title>12篇成果入选，2场Talk，字节跳动Seed邀你相聚CVPR 2025</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247491964&amp;idx=1&amp;sn=1d370d3e63833b284c8aec476b5306f8&amp;chksm=c344fc2c0658d12cb824ba8a1a1bbf1922df61578f558f7972105ef1238ee13c7b82eb56127f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[CVPR 2025 将于 6 月 11 日至 15 日在美国田纳西州纳什维尔举行。在本届会议中，字节跳动 Seed 团队共有 12 篇论文入选，其中包括 4 篇 Highlight，研究内容涵盖视觉推]]></description><author>字节跳动Seed</author><pubDate>Tue, 10 Jun 2025 12:07:36 +0800</pubDate></item><item><title>图像编辑模型SeedEdit 3.0发布！更强保持力，更高可用率</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247491884&amp;idx=1&amp;sn=cf15efa8bf998ae41b1b496cc266e363&amp;chksm=c3beb294a65db04c89eef4f07257d212343fda9a88b5fa28d3217325958e3868aa7eac767339&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[依靠 AI 完成指令式图像编辑的需求，广泛存在于视觉内容创意工作中。但此前，图像编辑模型在主体&背景保持、指令遵循等方面能力相对有限，导致编辑图像可用率不高。图像编辑模型 SeedEdit 3.0 基]]></description><author>字节跳动Seed</author><pubDate>Fri, 06 Jun 2025 12:03:34 +0800</pubDate></item><item><title>Seed Research｜理解与生成统一模型 BAGEL 开源，All-in-One Model！</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247491825&amp;idx=1&amp;sn=3b922db27b7ac01a9f24cd5add9ceee1&amp;chksm=c326a64ee800f4aef7b65917d9215eb1d033db55bcd879df2e93727f34ea6da745ecf779646a&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[BAGEL 是字节跳动 Seed 最新开源的多模态基础模型，支持文本、图像和视频的统一理解和生成。团队实验发现，随着预训练用到的跨模态交错数据不断扩展，模型还涌现出了更强的复杂推理和组合能力，为更广泛]]></description><author>字节跳动Seed</author><pubDate>Wed, 28 May 2025 17:17:28 +0800</pubDate></item><item><title>Seed-Coder开源代码模型发布，依托LLM构建代码数据</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247491770&amp;idx=1&amp;sn=012c1e478da1c53c9ec036f6d07b377c&amp;chksm=c3d96a1e4ecb4365e6a3872771e6242c0fd92e98c7ce6a15b87b9b8c46d67d228ff69d43fb5f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[字节跳动 Seed 近日公开了以模型为中心的代码预训练数据构建流水线（Model-centric Data Pipeline）实现方法。通过研究，我们验证了——基于 LLM 即可实现对代码数据的评分、]]></description><author>字节跳动Seed</author><pubDate>Mon, 19 May 2025 12:27:56 +0800</pubDate></item><item><title>Seed VLM 技术报告首次公开：图像、视频、GUI、Game 完全体</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247491739&amp;idx=1&amp;sn=c89b29424e27d777cbe4647de1bd52ef&amp;chksm=c32b717ef8d9b9d46f68f8e9364d56c92d576302a715dff7230a98de78aade3b26ee6badc542&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Seed1.5-VL 是字节跳动 Seed 团队最新发布的视觉-语言多模态大模型，具备更强的通用多模态理解和推理能力，且推理成本显著降低，在 60 个公开评测基准中的 38 个上取得 SOTA 表现。]]></description><author>字节跳动Seed</author><pubDate>Tue, 13 May 2025 14:08:46 +0800</pubDate></item><item><title>向量检索能力SOTA，字节Seed1.5-Embedding模型训练细节公开</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247491676&amp;idx=1&amp;sn=b682f533462ed5ae4eb1a5d8b4fbae8f&amp;chksm=c3984e8c81b34cbc2c47ed0f94eb322a5fe8af09a1b60d0172dce893146bb17eaced6fb59231&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[字节跳动 Seed 团队最新向量模型 Seed1.5-Embedding 公布技术细节，该模型基于 Seed1.5 (Doubao-1.5-pro) 进一步训练。在权威测评榜单 MTEB 上，Seed]]></description><author>字节跳动Seed</author><pubDate>Mon, 12 May 2025 12:01:00 +0800</pubDate></item><item><title>字节跳动 Top Seed 人才计划 2026 届正式启动</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247491176&amp;idx=1&amp;sn=b11760500249a9e693f1e15855bb3673&amp;chksm=c36c62d75941d650fae2fb5a77e0f8c11aa05f7f33d42f448f1aefb78bac6c8add44039dd629&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>字节跳动Seed</author><pubDate>Sun, 27 Apr 2025 16:24:04 +0800</pubDate></item><item><title>23篇成果入选，2场交流活动，字节跳动Seed邀你相聚ICLR 2025</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247491139&amp;idx=1&amp;sn=14f44329e24e20d2ea4679c746105c76&amp;chksm=c3541c939d39c4eacd8e42823ab5c0cf06e60cb514840d98a6323c97819f22f78888e6b095ab&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[ICLR 2025 即将在新加坡拉开帷幕。作为机器学习领域的顶级学术会议之一，ICLR 聚集了来自全球的学者与产业界代表。今年，字节跳动 Seed 团队共有 23 篇成果被接收或邀请分享，包含 1 篇]]></description><author>豆包大模型团队</author><pubDate>Wed, 23 Apr 2025 18:52:05 +0800</pubDate></item><item><title>字节跳动 Seed Edge 研究计划启动招聘</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247490845&amp;idx=1&amp;sn=5128269bbb0e23c1549ab77d45e207b0&amp;chksm=c36ac82144e9efb4f5f0d1a053dba7f43e66b4938972c804bdcb64f5bc0619a34697afc2879f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>豆包大模型团队</author><pubDate>Fri, 18 Apr 2025 12:00:00 +0800</pubDate></item><item><title>字节 Seed 智能体模型 UI-TARS-1.5 开源！多项 Benchmark 取得 SOTA 表现</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247490844&amp;idx=1&amp;sn=e518e26d459d5d34fd800aba221ccec8&amp;chksm=c3a30ece805ee8ece4e16ae5b0618ced41e1ba3dd60b6b9dfeb9af619cfee90574281af2704e&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[今天，我们发布并开源 UI-TARS-1.5，这是一款基于视觉-语言模型构建的开源多模态智能体，能够在虚拟世界中高效执行各类任务。目前，UI-TARS-1.5 已在 7 个典型的 GUI 图形用户界面]]></description><author>豆包大模型团队</author><pubDate>Thu, 17 Apr 2025 19:24:35 +0800</pubDate></item><item><title>Seedream 3.0 文生图模型技术报告发布</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247490727&amp;idx=1&amp;sn=11f3bc489e0ebd2034f3fb6df5a42ab2&amp;chksm=c3e2d6151713aa78c2d9e04c0df74ab11aeea6afb51a8f4deb9dd00d70029a42377a67a9276f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[字节跳动 Seed 团队正式发布 Seedream 3.0 技术报告。Seedream 3.0 是一个原生高分辨率、支持中英双语的图像生成基础模型，对比 Seedream 2.0，这一版本的整体性能表]]></description><author>豆包大模型团队</author><pubDate>Wed, 16 Apr 2025 13:47:54 +0800</pubDate></item><item><title>字节跳动最新思考模型，Seed-Thinking-v1.5技术细节公开</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247490396&amp;idx=1&amp;sn=f3aad78c2ee3742f9953e27ba08d4137&amp;chksm=c347c05b207b59d1cb01489aedc682c5503d921b115e785c676868ad10b6300bd18227b9d5e5&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[字节跳动 Seed 最新思考模型 Seed-Thinking-v1.5 技术报告发布，涵盖我们在数据体系、奖励模型、RL 算法、基础设施等维度的探索：通过数据层面的精细化处理提升推理能力，融合可验证数]]></description><author>豆包大模型团队</author><pubDate>Mon, 14 Apr 2025 11:30:00 +0800</pubDate></item><item><title>Multi-SWE-bench：首个多语言代码修复基准开源</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247490381&amp;idx=1&amp;sn=234578b604f16784d882706f82a65fe8&amp;chksm=c3e37dc91125b2143aad7be28c85dbad9f3deb25c419cbbd3ac8a8ad96cc2a707648e60a6e96&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[字节跳动豆包大模型团队正式开源首个多语言类 SWE 数据集——Multi-SWE-bench，可用于评估和提升大模型“自动修 Bug”能力。在 SWE-bench 基础上，Multi-SWE-benc]]></description><author>豆包大模型团队</author><pubDate>Thu, 10 Apr 2025 13:15:45 +0800</pubDate></item><item><title>字节跳动 Top Seed 研究实习生专项启动</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247490313&amp;idx=1&amp;sn=b2140e137390de9bec9d8e8abe33ac0a&amp;chksm=c34577b9e98d3f87d8d9d62edc6f9f612b44c31eebf7c9ac76b23ad35674cee34022462a5349&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>豆包大模型团队</author><pubDate>Thu, 20 Mar 2025 19:13:54 +0800</pubDate></item><item><title>豆包文生图技术报告发布！数据处理、预训练、RLHF全流程公开</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247490132&amp;idx=1&amp;sn=77dfaa7c4b94525283654e34d735cec0&amp;chksm=c31c95cabfc1c1cc1894e7163928d6f3cd877d370adadcb3dbe8d422b765c94f1b3b22aa64f8&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[今天，豆包大模型团队正式发布文生图技术报告，首次公开 Seedream 2.0 图像生成模型技术细节，覆盖数据构建、预训练框架、 后训练 RLHF 全流程。该报告针对 Seedream 2.0 原生中]]></description><author>豆包大模型团队</author><pubDate>Wed, 12 Mar 2025 13:06:21 +0800</pubDate></item><item><title>万卡集群真实部署，已节省数百万 GPU 小时！MoE 通信优化技术 COMET 开源</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247490058&amp;idx=1&amp;sn=d9ba25653437194a3e1b8563172ba95a&amp;chksm=c39859a004e3be41ae71ad7b9828a14de51ab596530ff8c045ee8b244d08c9cdef659b63dd68&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[当前，MoE 架构是业界拓展模型规模的重要方向，然而，其在分布式训练中存在的大量通信开销，仍严重制约了训练效率和成本。为攻克这一瓶颈，豆包大模型团队提出了一个全新的通信优化系统 COMET，通过更精准]]></description><author>豆包大模型团队</author><pubDate>Mon, 10 Mar 2025 17:58:10 +0800</pubDate></item><item><title>285 学科全覆盖！豆包大模型团队开源基准测试集 SuperGPQA</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247490028&amp;idx=1&amp;sn=95152ad328cefe2f17b826418517e3ec&amp;chksm=c3cf0df2b8154cbf2239c8802267fc5c7a3cf9a1666844e3a1770209f4a2bf788ea02dab4217&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[近日，豆包大模型团队开源 SuperGPQA，一个领域全面且具备高区分度的知识推理基准测试。该数据集构建了覆盖 285 个研究生级学科、包含 26529 道专业问题的评估体系，不仅涵盖主流学科，更将轻]]></description><author>豆包大模型团队</author><pubDate>Tue, 04 Mar 2025 11:40:23 +0800</pubDate></item><item><title>Seed Research | 形式化数学推理新SOTA！BFS-Prover模型最新开源</title><link>http://mp.weixin.qq.com/s?__biz=MzkzMDY5MzYxNg==&amp;mid=2247489980&amp;idx=1&amp;sn=4ba56520ff7410ea876b901308a78ef9&amp;chksm=c3184d5b893a4dceb89efafacb00bab681b238855c7d72c4eb838653fe71dd4fb051afadc8ab&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[近日，豆包大模型团队提出 BFS-Prover，一个基于大语言模型 (LLM) 和最优先树搜索 (BFS) 的高效自动形式化定理证明系统。团队通过该成果发现，简单的 BFS 方法经过系统优化后，可在大]]></description><author>豆包大模型团队</author><pubDate>Tue, 25 Feb 2025 17:59:00 +0800</pubDate></item></channel></rss>