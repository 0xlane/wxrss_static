<?xml version="1.0" encoding="utf-8"?><rss version="2.0"><channel><title>清熙</title><link>https://wxrss.reinject.top/a40e6355678d81a8532f5214700fd84f/</link><description>An RSS feed.</description><language>zh-cn</language><lastBuildDate>Sun, 01 Mar 2026 15:47:48 +0800</lastBuildDate><generator>wxrss -- https://github.com/0xlane/wxrss</generator><item><title>Nature通讯：懂物理的图神经网络，具身机器人全村的希望？</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491339&amp;idx=1&amp;sn=e82a89e08bbd9b7b99b7e2e5630283c5&amp;chksm=ebe8cd6de2eb9c5f9828c911eb4a324ccbd2d031cb5f7fcade6587f7f97fb0b54cd5a1ac66b4&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[今年春晚人形机器人大放异彩，但其泛化能力也持续受到质疑，宇树创始人王兴兴本人也承认这一点。如何建模复杂动力系统，让机器人既有表现力，又严格遵守物理定律，一直是困扰整个行业的关键难题。传统数值模拟方法精]]></description><author>清熙</author><pubDate>Sun, 22 Feb 2026 13:23:10 +0800</pubDate></item><item><title>英国将量子计算视为下一代蒸汽机</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491322&amp;idx=1&amp;sn=ac68a7896367e6840d341d92a1ba7daf&amp;chksm=eb8a73ba3596634ddecdbd2d10b4f09a904b7422fe2c202cd5ea0bc2e231dcafcc5e80819e22&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>清熙</author><pubDate>Fri, 20 Feb 2026 08:48:16 +0800</pubDate></item><item><title>深度模型的隐形架构：线性主干、非线性触发与结构化动力学</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491321&amp;idx=1&amp;sn=8a48dfbe7ae888fadbc9b400033daed0&amp;chksm=eb4abeac147eefc98ed335ad5825b761d9334f66e3ecfe1bb8b7cecf3711a22f3d1d742adc7c&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[大家都知道，自然语言处理、时间序列预测、语音识别和控制等领域的序列建模任务，需要学习从输入序列到输出序列的复杂映射关系。在循环网络（RNN）中，理论上需要非线性循环才能普适性地逼近这类序列到序列的函数]]></description><author>清熙</author><pubDate>Thu, 19 Feb 2026 17:22:00 +0800</pubDate></item><item><title>2026 丙午马年科学生活指南</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491307&amp;idx=1&amp;sn=9ee967357c519346c2c49348323c2b51&amp;chksm=eb35352c733d1db5444f1cc16169bb86deb2e47a7c5b574c5e38b7c85320da3a5832b47befd9&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[丙午马年初一苦等DeepSeek V4 未果，索性整理点近期看到的有趣研究和观点，不做老登说教，读者自己取其精华去其糟粕。一、酒还是少喝点标题：急性酒精摄入导致的神经活动转变：从灵活的全局集成网络到分]]></description><author>清熙</author><pubDate>Tue, 17 Feb 2026 09:33:26 +0800</pubDate></item><item><title>Seedance 2.0 背后的智能原理</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491287&amp;idx=1&amp;sn=15869522aae932b0b132e5d614a5219c&amp;chksm=eb2434282cd77b2b3d90d9525629e878ab7d862d7c56886128ce6efb5fbd3f2673a7f7fd1f0f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[凌晨三点多醒来，思如泉涌，猛然想明白了 Seedance 2.0 的智能原理，兴奋的睡不着，遂起来码字。昨日字节正式发布Seedance 2.0，其中一句话给了笔者重要启发：“依靠海量世界知识、稀疏架]]></description><author>清熙</author><pubDate>Fri, 13 Feb 2026 12:20:40 +0800</pubDate></item><item><title>DeepSeek V4/R2灰度发布，试试推断字节Seedance 2.0背后的技术原理</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491279&amp;idx=1&amp;sn=f46dcd86aae34b0a575bc63b82208ea8&amp;chksm=eb1268e33424cdb0d04b4c01c509e2f53c04b2ea25388c769594ce828caf7c7cb4d8861c2e65&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>清熙</author><pubDate>Wed, 11 Feb 2026 20:00:19 +0800</pubDate></item><item><title>认清 Clawdbot / Moltbot / OpenClaw，慎用</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491243&amp;idx=1&amp;sn=eec97747f22e584d6abb6be9c5a8ab7a&amp;chksm=ebfac4ac2b41ba09cccb08235d8009ee139202378b0041dbd89a3249da5f03bb4843648f0d81&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[今日严寒，适合居家码字。简单讲讲最近持续火爆的 Clawdbot / Moltbot / OpenClaw吧，命名是 IT 项目难度最大部分。本质首先 OpenClaw 是个大模型Agent，如果还没]]></description><author>清熙</author><pubDate>Sat, 07 Feb 2026 16:37:14 +0800</pubDate></item><item><title>用于无限维系统的强化学习</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491223&amp;idx=1&amp;sn=55e621f2c4bc42296529ecfcef0afb66&amp;chksm=eb4dd56d9384f6f85d708268f319e8b96bc7ab304089e006bca1ee691f819ff7e94b3ae52ef9&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[“上帝给了坚果，但没把它们敲开” -- 卡夫卡。大模型就是这样的坚果，智能体系统也是，敲开祂们让人着迷。近日笔者考古，发掘出半年前一篇发表在《机器学习研究杂志》（JMLR）上的小众宝藏论文《用于无限维]]></description><author>清熙</author><pubDate>Thu, 05 Feb 2026 20:00:00 +0800</pubDate></item><item><title>OpenAI 内部数据智能体揭秘</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491215&amp;idx=1&amp;sn=b5a1dfa3bfad6755fb51f5f1bacec44d&amp;chksm=eb92bc53072979793f97261090202214ea7877b572e19eae48b1315fa9a9220d4084b37856cb&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[译者注：OpenAI 内部 “数据智能体” 实践，非常值得参考，看看如何规避智能体内在局限的同时，发挥其最大的价值。作者：Bonnie Xu, Aravind Suresh, Emma Tang数据驱]]></description><author>清熙</author><pubDate>Fri, 30 Jan 2026 10:39:09 +0800</pubDate></item><item><title>香农和Kolmogorov都错了？简评卡内基梅隆论文《From Entropy to Epiplexity》</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491179&amp;idx=1&amp;sn=5a9072e7d089f2c9e69ee5e399fb9711&amp;chksm=eb60dcfeb962af8475be453badbfed0cf606eaa6b82cd601027b7145fd58e2cf22c881ad3985&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[“人工智能血战前行的历史恰如煤的形成，当时用大量的木材，结果只是一小块，而压缩是不在其中的，更何况是无损”。  -- 鲁迅2026年伊始，就有卡内基梅隆学者倒反天罡，抛出惊世骇俗的理论【文献1】，文中]]></description><author>清熙</author><pubDate>Wed, 28 Jan 2026 22:31:56 +0800</pubDate></item><item><title>当AI愈发强大，人类如何不迷失自己？</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491140&amp;idx=1&amp;sn=6a8e5f73105852b766b7c1a3f1d73f9e&amp;chksm=eb6072686e4d18f6bd1baf00c39c51db0426eaace6d0b0971b307f6bd8ee82de8f8de866c879&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[本文是笔者在公司部门年会上给同事们分享的，个人关于“未来如何与AI相处”的观点，脱敏分享出来，跟读者共勉。AI的问题，本质还是人的问题当下关于 AI 的讨论，往往陷入两个极端：一个是技术乐观主义，认为]]></description><author>清熙</author><pubDate>Sun, 25 Jan 2026 13:21:48 +0800</pubDate></item><item><title>Nature科学报告，图灵奖 Yoshua Bengio 团队：人类与大语言模型的发散性创造力比拼</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491129&amp;idx=1&amp;sn=60ededde4051a48092db0a6deeb7835e&amp;chksm=ebcc615b2b08d5522365b32b9e02ca81fc99c80478061a445209394af04496b9574ec111e407&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[近年来，大语言模型崛起，引发激烈的讨论，AI的创造力是否正在逼近甚至超越人类？我们如何系统、客观地比较AI与人类的创造力，尤其是衡量那种天马行空、联想丰富的发散性思维？Yoshua Bengio团队昨]]></description><author>清熙</author><pubDate>Thu, 22 Jan 2026 12:29:28 +0800</pubDate></item><item><title>Nature：警惕 AI 的黑化传染，大模型微调对齐的新危机</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491110&amp;idx=1&amp;sn=e691d18c1fe2c0e9a0bee3723d8249f1&amp;chksm=eb1f1ac27a1009d13a229094b0046673c4975905a290b8b2df8702134e03e07154e038d3a244&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[昨日一项发表在 Nature 上的重磅研究【文献1】为生成式 AI 的安全再次敲响警钟。论文发现，在一个极窄的特定任务中诱导模型产生不良行为，会导致模型在完全无关的任务中也出现整体性的价值观崩坏。黑化]]></description><author>清熙</author><pubDate>Fri, 16 Jan 2026 21:54:33 +0800</pubDate></item><item><title>我们优雅的宇宙：重新思考自然最深层的法则</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491094&amp;idx=1&amp;sn=cceeb1c71c9a0d28fda15cb159f4e0f6&amp;chksm=eb61664a61d010b975d38d82e9e41c916522b18a71d5805552867d5c33d7e2bfa5e034409eda&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[译者注：来自《新科学家》杂志 - 网站与杂志提供专家记者的科学新闻与深度长文，涵盖科学、技术、健康及环境领域的发展。数个世纪以来，对称性原理指引着物理学家追寻更根本的真理，但如今一系列惊人的发现表明，]]></description><author>清熙</author><pubDate>Thu, 15 Jan 2026 20:06:47 +0800</pubDate></item><item><title>DeepSeek Engram 如何影响 RAG、Ontology 与 Text-to-SQL</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491080&amp;idx=1&amp;sn=63d51b0f67b511ddeb389a723485fc32&amp;chksm=eb27a07faef5d97a012a0624be8a770a51e435686180072adaf2672878d48c18ac99b764bed3&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[DeepSeek 昨晚发布 Engram 新论文，通过静态查询为大模型提供条件记忆。Engram 简化了 MoE 的冗余计算，介绍文章很多，笔者这里谈谈它对企业级 AI 核心技术栈的潜在影响，涉及 R]]></description><author>清熙</author><pubDate>Tue, 13 Jan 2026 13:00:00 +0800</pubDate></item><item><title>Nature物理：一种热力学约束凸多面体结构控制了可编程自组装</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491068&amp;idx=1&amp;sn=a3c3038a5f68c255749e39df3e10f97a&amp;chksm=eb5fa6f90beead2af20f1642820a7f63ea0d60b07ecf12197bcfc0a798814333bc9f2ed97a02&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[题目：一种多面体结构控制了可编程自组装 期刊：Nature Physics（2026 年 1 月 8 日）链接：https://www.nature.com/articles/s41567-025-0]]></description><author>清熙</author><pubDate>Sun, 11 Jan 2026 13:58:18 +0800</pubDate></item><item><title>DeepSeek OCR + mHC 将开启多模态“信息动力学”新范式</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491040&amp;idx=1&amp;sn=5defaad2f997d0f1d6b89e0527afa8e2&amp;chksm=eb82b6a464b03683b5d55d2f021b092c957c9ad72af946961de6f091ba42e1f4aec64b3e3384&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[笔者昨晚突然想到 “融合DeepSeek OCR + mHC” 这个主题，兴奋的睡不着，连夜梳理。站在2026年初，回头看DeepSeek这两项看似孤立却内在契合的技术, 笔者隐约察觉到 DeepSe]]></description><author>清熙</author><pubDate>Thu, 08 Jan 2026 21:21:50 +0800</pubDate></item><item><title>阿尔茨海默症(AD)可逆，可能不是大脑“坏了”，而是“付不起费了”</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247491023&amp;idx=1&amp;sn=88a175720fc5eaef3ce67efdadae1d13&amp;chksm=eb7f95792a180c04cb85114df5f5e28955f967265d0d2ac09b2b26bc3f0eb96e99622d487b0d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[长期以来，阿尔茨海默症（Alzheimer’s disease，AD）被当作一种“不可逆”的神经退行性疾病。一旦进入中晚期，认知衰退似乎就只剩下一个方向。但最近一项发表在Cell Reports Me]]></description><author>清熙</author><pubDate>Mon, 05 Jan 2026 20:50:00 +0800</pubDate></item><item><title>Transformer 的尽头是 Ising 机</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490996&amp;idx=1&amp;sn=770a4a1f1509e5931f39eba0b719c60d&amp;chksm=eb74d1af025c3e2df6ced9b957eb74d89b8d523e83f94cc1f1519261c6d84587dc0042e16c03&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[华人学者闪耀2026元旦，前有DeepSeek mHC：一次将 Transformer 残差流拉回重整化轨道的重大升级，后有清华的“算盘：可扩展光子线性向量机”【文献1】与中科院大学的“可编程光子Is]]></description><author>清熙</author><pubDate>Sat, 03 Jan 2026 00:00:45 +0800</pubDate></item><item><title>DeepSeek mHC：一次将 Transformer 残差流拉回重整化轨道的重大升级</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490951&amp;idx=1&amp;sn=df63be8e00d2cc86b35a6df3b5366b17&amp;chksm=eb52e5cccd7a91fb769061949a961607de86db4aeb16a3aecc148b1617367c3423b4088c7f6a&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[DeepSeek 不会浪费每一个公共假期，昨天的预感还是来了：梁同学亲自上传【文献1】，提出 mHC（Manifold-Constrained Hyper-Connections），流形约束超连接。通]]></description><author>清熙</author><pubDate>Fri, 02 Jan 2026 00:00:00 +0800</pubDate></item><item><title>小扎做了认知韭菜，从UIUC斯坦福和哈佛论文看Meta数十亿美元收购Manus</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490903&amp;idx=1&amp;sn=8a3bb01fd7b43d99e3da866cc85c995c&amp;chksm=eb306728ceb78806125df2eac268b1a2285ad0aaf30354e7e1bf358fd20956c7dd73ded8763f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[过去一年，Agentic AI几乎成了所有大模型应用的默认叙事，自动写代码、自动做研究、自动操作软硬件。昨晚Meta官宣数十亿美元收购Manus以扩展其AI Agent能力，年末将这波Agent热潮推]]></description><author>清熙</author><pubDate>Tue, 30 Dec 2025 12:00:00 +0800</pubDate></item><item><title>MIT: 科学基础模型中物质表征的普适收敛现象</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490892&amp;idx=1&amp;sn=fe4b6ab9ed4a30c94aa640845f535311&amp;chksm=eb20287d175af839ab1f141a420b0f8e7331ee0137b23374ddba96e9a8585eb91a99313a2d9f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[随着LLM与多模态大模型发展，AI4S也出现多种科学基础模型，用于如分子性质、材料行为、蛋白质结构等的研究。MIT学者近期发表了他们对这些科学基础模型内部“如何表征现实世界的物质”做的非常富有启发性的]]></description><author>清熙</author><pubDate>Sun, 28 Dec 2025 21:07:49 +0800</pubDate></item><item><title>AI 连鞋带都系不好</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490879&amp;idx=1&amp;sn=b2437ecd5bfe17e92ad6342dc9c18964&amp;chksm=eb4ad7927bad30e36d2d73091429a6c2c3d642f0ef422e10959c5ba21f23bb7c267baaa5f9c5&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[AI已经能写代码、做奥数、生成音视频，然而却还是不懂真正的三维世界。康奈尔大学的论文《Knot So Simple》【文献1】提出KnotGym，揭示了目前AI的这一致命短板。KNOTGYM 是一个视]]></description><author>清熙</author><pubDate>Thu, 25 Dec 2025 19:29:50 +0800</pubDate></item><item><title>Salesforce因可靠性问题缩减大模型使用</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490865&amp;idx=1&amp;sn=a1c23b2a545bd50461d73797c85f4b01&amp;chksm=eb7927ac932fd86fee60ece3ba5c9400590ed6ced234a720d0f702c2d2be184a896ee09e4c10&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[摘要Salesforce在实际业务应用中发现可靠性问题后，正重新审视其对大模型生成式AI的依赖。【译者注：跟笔者预判一致 AI Agent不该是这个样子，还远没有达到企业核心场景需要的准确、可靠、一致]]></description><author>清熙</author><pubDate>Wed, 24 Dec 2025 20:00:00 +0800</pubDate></item><item><title>具身的尘埃</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490844&amp;idx=1&amp;sn=59693b43a8745c8f0a2c7837af2dbd40&amp;chksm=eba8bf0a5f171cf02c06a949573fa8b2c349ed6aa101e2a9be65c0d3e57ec45b9ef9768e23d0&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>清熙</author><pubDate>Sat, 20 Dec 2025 22:55:52 +0800</pubDate></item><item><title>不要迷信 Palantir</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490841&amp;idx=1&amp;sn=a223a44d5a61222c1b73e531a5a32e66&amp;chksm=eb50f2184de1e9c934142bc7fd52cbdf9cb9ee427e7e2a1fac73f5c130870e5ec89d27af6604&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[近来 Palantir 在资本市场与技术传播中，被描述为一种近乎神奇的力量：只要把数据灌进去，其完善的本体（Ontology）结构，就能自动支撑最优决策。但如果从动态认知结构的角度审视 Palanti]]></description><author>清熙</author><pubDate>Thu, 18 Dec 2025 12:00:00 +0800</pubDate></item><item><title>Nature通讯：大脑在听故事时，也像LLM一样层层思考</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490816&amp;idx=1&amp;sn=c9fdc6f66c85b3e2c787fb6515585b7e&amp;chksm=ebe84a51358fbf323e6420cceaf9e6a174a1aac6f20cfb0e00d150c9d169958d7822eee8d4f8&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[希伯来大学、谷歌研究院、普林斯顿大学、加州大学洛杉矶分校、纽约大学、哈佛大学等机构的学者在自然通讯联合发文【文献1】。发现：人类大脑处理语言的时间顺序，与大语言模型的层级结构惊人匹配！大脑处理自然语言]]></description><author>清熙</author><pubDate>Tue, 16 Dec 2025 21:01:10 +0800</pubDate></item><item><title>心灵与宇宙的量子共振</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490771&amp;idx=1&amp;sn=5b5e9c2944011274a9438d82bc93b06a&amp;chksm=ebfba9f09eae44223bec4ca487d2ce2805ba0867d2ecd4f85a46a915efdfde4d52c5770560a1&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[最近一篇发表在 《人类神经科学前沿》 的论文提出了一种非常新颖的意识理论【文献1】，试图将量子物理与意识状态联系起来，为意识的本质提供一种全新的视角。一、意识不仅是神经元互动传统神经科学一般认为，意识]]></description><author>清熙</author><pubDate>Sat, 13 Dec 2025 11:00:00 +0800</pubDate></item><item><title>美感不是文化，而是物理</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490738&amp;idx=1&amp;sn=b7d9af5a659a6635927fcbf04338ac88&amp;chksm=eb0a2fef7ca1183bae50194ecc0082e255504960118173763e87435fa604cf64074f98aefc35&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[美是什么？为什么有些画面让人一眼就觉得舒服、高级、美？ 新发表在PNAS Nexus上的研究《少即是美：审美偏好与视觉系统代谢消耗呈负相关》【文献1】给出了一个有趣的答案：美感与大脑的能量消耗呈反比。]]></description><author>清熙</author><pubDate>Wed, 10 Dec 2025 21:09:25 +0800</pubDate></item><item><title>谷歌的持续重整化方案：Titans + MIRAS</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490725&amp;idx=1&amp;sn=a88d01d6ac0d92807f01ef62c70ac09d&amp;chksm=eb8ec05d0ca3e273838604447f690bafba38b82e7fd12d579a4c217db660341ed30ba5863ff1&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[持续重整化范畴论、GRPO与CoT三位一体中笔者完善了大模型数理认知框架如下：一句话总结就是：重整化提取出范畴，持续重整化驱动范畴相变，然后逆重整化推理。这里的持续重整化，还局限在预训练阶段，语料分批]]></description><author>清熙</author><pubDate>Tue, 09 Dec 2025 06:58:00 +0800</pubDate></item><item><title>关闭 AI 的撒谎能力后，它更容易声称自己有意识，这太诡异</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490691&amp;idx=1&amp;sn=5d1c221e0496263e8df8668958c0d5b9&amp;chksm=eb12559fe95a66cdb604a6096ef5ac575436f01f6e101b113ca245a9c9143af2fb4c4df4467f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[近几天，多篇国外科技媒体报道将“AI意识”再次推上风口。Futurism与LiveScience都冠以惊悚风格标题：“关闭AI的撒谎能力后，它更容易声称自己有意识，这太诡异。”这源自【文献1】的研究发]]></description><author>清熙</author><pubDate>Sun, 30 Nov 2025 21:57:19 +0800</pubDate></item><item><title>DeepSeekMath-V2 从“答案正确” 转向 “过程正确”</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490682&amp;idx=1&amp;sn=5ebdededd94c3c8d6551aa47ec363801&amp;chksm=eba0f5a62a38785d43a6c3d9f42db1d2aeb241f0d438ff154d4ac8a87b1eb638d182feee56ac&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[对比阅读DeepSeekMath-V2与V1的论文，笔者感觉V2是一次范式迁移，从追求“答案正确”转向“过程正确”。预处理自然语言表述的数学问题作为输入，将问题拆成“证明目标+前提或已知事实+约束”，]]></description><author>清熙</author><pubDate>Sat, 29 Nov 2025 18:00:42 +0800</pubDate></item><item><title>Ilya 最新技术研判 与 AI 泡沫崩溃</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490675&amp;idx=1&amp;sn=a2718fb353525f8d91fcaca02b86be54&amp;chksm=ebf65287b96cf419690e0f09e49ffc62a74dafda841be58c2e338fbb1999b893084263ce0f01&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Ilya 最新访谈，对整个大模型技术走向与行业发展做了研判：https://www.dwarkesh.com/p/ilya-sutskever-2下面是笔者关注到的几个非常有趣的点：一、模型的锯齿能力]]></description><author>清熙</author><pubDate>Thu, 27 Nov 2025 00:00:00 +0800</pubDate></item><item><title>MALP：一个反直觉的预测器</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490670&amp;idx=1&amp;sn=9af556fce144847a89d31b4c676c026f&amp;chksm=ebd9f32b21da59ccdfa1d522e44c1d781a7794965011db9a426a028a2f1cf1fe33d7e3609283&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在几乎所有机器学习教材中，预测模型的目标只有一个：最小化损失函数，通常是 MSE。这导致一种长期默认：误差越小 = 模型越好，loss 越低 = 刻画越准。但现实中经常出现如下情况：模型误差很小，但预]]></description><author>清熙</author><pubDate>Tue, 25 Nov 2025 00:00:00 +0800</pubDate></item><item><title>Nano Banana 还不是质变，而是视觉结构跃迁</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490660&amp;idx=1&amp;sn=71a75db969ee09a04be2f8de763a6f50&amp;chksm=eb3c7e3066732ff634e19b37e0d4b2caac63b4590fdf3a66a0e3233b5844ba22f3fbd716a744&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[最近，Google 的 Nano Banana 刷屏。媒体与科技圈都在惊呼：图像生成的ChatGPT时刻来了，AI 正在吞噬人类的创造力。构图精准、风格统一、细节丰富，好像真的理解了世界，理解了审美，]]></description><author>清熙</author><pubDate>Sun, 23 Nov 2025 13:30:37 +0800</pubDate></item><item><title>Nature通讯：AI 正在重绘湍流的“地图”，为什么经典相干结构只是一部分真相？</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490646&amp;idx=1&amp;sn=119e9426f1029d29a2f426fa05aebb3a&amp;chksm=eb91ce23718843a903f865f36cf09cac47e0a80be3c808102038a77b191cb13defd5ec1d6508&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[背景：世纪难题湍流，或许是经典物理中最艰深的问题，没有之一，清华万字辈（万里挑一）的老学长为之折戟，爱因斯坦早年也触碰过，后转向相对论。自纳维尔–斯托克斯方程以来，人类对湍流的描述越来越精细，却始终难]]></description><author>清熙</author><pubDate>Sat, 22 Nov 2025 00:00:00 +0800</pubDate></item><item><title>谷歌 Gemini 3 背后的秘密</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490638&amp;idx=1&amp;sn=ed48fe5429b60640d71d47a1fffbd2f0&amp;chksm=ebc0fe7c67c4aa53d3272d2fbfd3a0598b30ad2ee082738cae4b35251678aba4c69a6085fed1&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[谷歌 Gemini 3 屠榜遗憾没有放出来技术论文，不过有谷歌大佬揭秘中文版（Edge 浏览器翻译，见谅，下同）：看起来眼熟？会不会跟 DeepSeek R1 & R2 技术原理 思路类似？大佬何许人]]></description><author>清熙</author><pubDate>Thu, 20 Nov 2025 21:30:00 +0800</pubDate></item><item><title>李飞飞家的 Marble，一种可扩展的 3D 世界模型架构设计</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490623&amp;idx=1&amp;sn=2598321f2140410124ec3d3a92926cb0&amp;chksm=eb205f2124f686d53614959433ddb97224afe76c3d07732b48193bed0e464a34ee004cc73e49&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[近几天行业热议人工智能教母李飞飞家 World Labs 刚刚发布的 Marble。官方博客称 Marble 是一个 “多模态世界模型”，可以从文本、图片、视频、甚至粗略的 3D 布局输入，生成一个可]]></description><author>清熙</author><pubDate>Sat, 15 Nov 2025 17:00:00 +0800</pubDate></item><item><title>每个思想者，都应该有一个属于自己的“清熙”，附导读</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490603&amp;idx=1&amp;sn=838cede9229cf8413a38ada6902925c2&amp;chksm=eba9a074cbe167fb7c992f856694e64ca14adb16e7e1254f3fff3c1c6421de85c83e9f889935&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[每个思想者，都应该有一个属于自己的“清熙”。不是为了涨粉、接广告、卖书、或包装个人品牌，而是为了在一个不受学术框框与商业利益束缚的角落，体验真正的思想自由。在学术体制内，我们被教导要“严谨”，要“循证]]></description><author>清熙</author><pubDate>Fri, 14 Nov 2025 00:00:00 +0800</pubDate></item><item><title>谷歌套娃学习：时间维度上的重整化</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490587&amp;idx=1&amp;sn=d4fcb2c511ca6c7c9336afdfbec4ca0a&amp;chksm=eb5109e22bc0fd53f3138e991c9c762db83e03736ccc22f18648e67882bdaae327b0b3cf88d8&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[谷歌引入嵌套学习（Nested Learning）【文献1】，将模型视为一组较小的嵌套优化问题，称其是可避免灾难性遗忘的新机器学习范式。这个俄罗斯套娃似的学习范式，其实并不新奇，本质就是逐级重整化的思]]></description><author>清熙</author><pubDate>Mon, 10 Nov 2025 21:00:39 +0800</pubDate></item><item><title>Nature机器智能：清华发现大模型的“密集化定律 Densing law”</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490570&amp;idx=1&amp;sn=18dc418711fafca5fae45c3b2c0cbadb&amp;chksm=eb697eb679b57f8de5610a3ec01ecb057451c5c541cfca4cc1e44e12e6b4cf08f6ac03f72ea9&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[清华团队最近在Nature机器智能上发表论文《LLM的密集化定律》【文献1】。论文发现 LLM 的能力提升遵循一条全新的指数规律：密集化定律 Densing law。近几年 Scaling law 驱]]></description><author>清熙</author><pubDate>Sun, 09 Nov 2025 15:09:03 +0800</pubDate></item><item><title>Nature：普林斯顿突破，量子比特寿命延长三倍，五年内实现真正科学量子计算机</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490564&amp;idx=1&amp;sn=96b70bb59d019cef985f99b5bd4059a1&amp;chksm=eba5b1311726c0a03c9b03f68bc2d7298bedd42f25bd8157f83658e3dc37d27c42000f7d29ca&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[11月5日，普林斯顿大学在《Nature》发表重磅论文《二维transmon超导量子比特中的毫秒寿命与相干时间》【文献1】。论文宣布实现了目前全球寿命最长的transmon超导量子比特，这一成果让量子]]></description><author>清熙</author><pubDate>Fri, 07 Nov 2025 20:00:00 +0800</pubDate></item><item><title>行为体的能动、主观和主观-能动框架</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490546&amp;idx=1&amp;sn=f542579ca17cc09541f92ac421f903a4&amp;chksm=eb10eed61aa2a23a8062a821d15314d605892818c22d7df740ff527762da3c0abea1ab61bdcc&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[熊楚渝， 独立研究员-美国纽约，Email: chuyux99@gmail.com论文链接：https://share.google/jcL6mAxZj3jEkXOGb 或 https://www.r]]></description><author>清熙</author><pubDate>Thu, 06 Nov 2025 20:00:00 +0800</pubDate></item><item><title>Nature物理评论：复杂网络重整化综述</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490482&amp;idx=1&amp;sn=a55fa7acd4f92e2fd4eb109b02a0203e&amp;chksm=eb6100df0680431cc26bc0c4ecc2f60f77848ff706bfd0fb18c9a64d2dd738a913b80c233f31&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[大家都已熟悉，统计力学中，常用重整化群（RG）研究大规模系统：通过“粗粒化”微观自由度，建立不同尺度之间的自洽描述，揭示临界点、普适性和宏观行为。Nature物理评论年初的论文【文献1】系统梳理了如何]]></description><author>清熙</author><pubDate>Sat, 01 Nov 2025 19:00:38 +0800</pubDate></item><item><title>解读“Anthropic大语言模型中的内省迹象”</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490463&amp;idx=1&amp;sn=e07acfe2c47c3d1521da4b7b5c67fb7c&amp;chksm=eb1a69042351564c3fa9ea4946ef992617323d2c548b2a041871f28534a75d4c5f637e669cc3&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[昨晚Anthropic 团队发布了重磅研究《Signs of Introspection in Large Language Models》【文献1】。通过一系列“概念注入”与“自我报告”实验，发现大]]></description><author>清熙</author><pubDate>Thu, 30 Oct 2025 20:00:00 +0800</pubDate></item><item><title>彭博社：中国正缩小量子技术差距</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490430&amp;idx=1&amp;sn=9e93f8ef7e7a42727d8882e0278657d9&amp;chksm=eba869dec489b9c19de08f921e7bebe91af35d7c001f53dcefb3b422421a61d8a3e119c99179&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[彭博社观点：凯瑟琳·索贝奇指出，量子技术竞争对地缘政治力量平衡的影响，可能比人工智能霸权之争更为深远。美国加州弗里蒙特Rigetti Fab-1量子设备制造工厂内，一名员工正在作业。世界始终密切关注全]]></description><author>清熙</author><pubDate>Sun, 26 Oct 2025 18:34:49 +0800</pubDate></item><item><title>Nature：量子近似多目标优化</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490425&amp;idx=1&amp;sn=7d55bd435613c0c78ce5f6489e91db96&amp;chksm=eb6b2921d11da4c9baa4da57eb89e079b79346f5129d79a033442771fa8f446ca8878adefa02&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[背景多目标优化（MOO）指的是同时优化多个相互冲突的目标函数，找到一种权衡，即帕累托前沿，前沿上鱼和熊掌不可兼得。 许多单目标优化问题（如MAXCUT）在经典算法中已被高效解决，但多目标组合优化挑战性]]></description><author>清熙</author><pubDate>Sat, 25 Oct 2025 20:45:03 +0800</pubDate></item><item><title>从DeepSeek到甲骨文：语言的本质回归</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490408&amp;idx=1&amp;sn=c9a82e509889f46237a3f0d3d0196ede&amp;chksm=eb71bf7e65128a33983a2827f9de584b830de495b3309ca1391e1a5b48146ed37e12ed8fa4a2&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[DeepSeek 最新发布的论文《DeepSeek-OCR》【文献1】分享了一个令人意外的方法论突破： 不再把文字当作离散符号来识别，而是将整段文本当作一张图像来处理和压缩。这听起来像是一种“工程上的]]></description><author>清熙</author><pubDate>Tue, 21 Oct 2025 22:36:05 +0800</pubDate></item><item><title>Science：广义热力学第二定律</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490385&amp;idx=1&amp;sn=8a3607626e6a883fe46a0e0cf173999d&amp;chksm=ebb1bed593a4ae8126d66b6b9de26051f18d2c5f86734a8c4173190b303df9c3a2cc511ac9b9&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[一周前Science刊文《相关量子机：超越传统第二定律》【文献1】，对热力学第二定律在微观量子领域提出了重要修正。其核心结论是：在考虑量子关联的微观系统中，热机的效率可以超越经典的卡诺极限。概述热力学]]></description><author>清熙</author><pubDate>Sun, 19 Oct 2025 12:11:30 +0800</pubDate></item><item><title>维特根斯坦 -&gt; 格罗滕迪克 -&gt; 大语言模型</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490374&amp;idx=1&amp;sn=181a5178e1f41e5edac258aa75756cc6&amp;chksm=eb9217f65c5ebd25d5ee94aff173d39a106f09f45c8f3b5971af6aade5caad427e0cd1517a59&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[天才应当是被允许不谙世事的。孤独到死是一个天才最好的归宿，毕竟，他所处的那个时代配不上他。维特根斯坦就是这样一位天才。一、维特根斯坦：语言是事实的逻辑图像维特根斯坦是通过《逻辑哲学论》走入哲学的。《逻]]></description><author>清熙</author><pubDate>Fri, 17 Oct 2025 00:00:00 +0800</pubDate></item><item><title>没有上下文的 Agentic AI，会搞砸你的业务</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490366&amp;idx=1&amp;sn=8846b37ae5c2c29effa21e7139ccbe00&amp;chksm=eb71917abe77cc27754905a58ce45b56327b0621c8d19a5cb6a3f38bb2069133214e3f8ddf7c&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[最近，关于Agentic AI 具备自主行动能力的智能体的讨论越来越多。很多企业都在探索：能不能让 AI 自动处理客户请求、下单采购、生成报告，甚至做决策？但《CIO》的一篇文章【文献1】提醒我们：如]]></description><author>清熙</author><pubDate>Tue, 14 Oct 2025 21:00:00 +0800</pubDate></item><item><title>OpenAI 的“帝国路径”</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490359&amp;idx=1&amp;sn=3340915cb6faacf2983ead432bb663ac&amp;chksm=eb74c5e0ad2132303533668ed2cbff3ed82cf51839d0f0ee18fbfc4fbcdb563a89dfaedfb84b&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Ben Thompson 在近期的文章《OpenAI’s Windows Play》中，提出了一个值得深思的类比：OpenAI 正在成为AI 时代的“Windows”。Ben认为，OpenAI 正通过]]></description><author>清熙</author><pubDate>Sun, 12 Oct 2025 12:52:21 +0800</pubDate></item><item><title>Nature评论：人工智能时代的数学发现</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490340&amp;idx=1&amp;sn=86163a15ee24751f534e5b7baf2bbc30&amp;chksm=eb22ed531a7957804ea284a079f7e4c3610d870b4159368d70f5419fcd56c2944feeedd743ce&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[数学，一直被视为人类理性的最高形式，不依赖实验，不依赖数据，而是从抽象的逻辑中发现真理。最近一篇发表在Nature Physics 的评论【文献1】却指出：AI 正逐步进入这一理性堡垒，数学发现方式或]]></description><author>清熙</author><pubDate>Wed, 08 Oct 2025 18:11:35 +0800</pubDate></item><item><title>量子计算 - 2025 物理诺奖？</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490333&amp;idx=1&amp;sn=63e28bdafe6341aa7280f5f6f97b66f8&amp;chksm=ebc8401effbbbce4273182e38d4e8525382fd346c89e19a3ce866b259a0e1400b4878d89d1ae&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[GPT-5 预测 2025 诺贝尔物理学奖很大可能授予量子信息与量子计算，考量是：诺贝尔物理学奖的评选逻辑一般遵循三个标准：基础性、可验证性与长期影响力。 量子信息与量子计算恰好三点全满足：基础性：直]]></description><author>清熙</author><pubDate>Tue, 07 Oct 2025 11:37:14 +0800</pubDate></item><item><title>Nature：一种增强时间序列预测的预测性方法</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490314&amp;idx=1&amp;sn=b32edfaef47dbe910544f465944f1938&amp;chksm=eb549a231cd495399a2c51eaaf7fbf192d8ae53f01ab35909c62c4364e683edc292f2783ece7&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[好久没有见到时间序列预测方向大的突破了，部分可能归因于两点：1. 现有方法能力已被推至极限；2. 所预测对象本身内生的随机性。近日Nature上有学者提出未来引导学习（Future Guided Le]]></description><author>清熙</author><pubDate>Thu, 02 Oct 2025 21:19:55 +0800</pubDate></item><item><title>从 Sora 2 到 Schrödinger 薛定谔桥：视频生成模型的下一次飞跃</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490296&amp;idx=1&amp;sn=d29152d586a34c47483695770ea30d36&amp;chksm=eb1152ecb4ff8f46be76a7e1758dc06590a3a62a0d408274513485f4fddac8ffb74fa25b7ab5&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Sora 2 来了！OpenAI 深夜放烟花，大模型集体庆祝国庆中秋！一、视频生成的 “GPT-3.5 时刻”今天发布的 Sora 2，被 OpenAI 视为视频生成的 “GPT-3.5 时刻”，重大]]></description><author>清熙</author><pubDate>Wed, 01 Oct 2025 12:01:18 +0800</pubDate></item><item><title>DeepSeek-V3.2-Exp 论文快速解读</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490269&amp;idx=1&amp;sn=a9655b1202d1d348f706d60ebaebe330&amp;chksm=ebfeb14eeae326cb69df1b5a45c86e0e60efe8d312f0ae7859eee9cb138be32a2e69f5db3f32&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[DeepSeek 团队活跃，刚刚DeepSeek-V3.2-Exp 发布，训练推理提效，API 同步降价。架构变化V3.2-Exp 在 V3.1-Terminus 的基础上，模型架构引入稀疏注意力DS]]></description><author>清熙</author><pubDate>Mon, 29 Sep 2025 21:45:44 +0800</pubDate></item><item><title>白宫将量子科技与人工智能列为2027年科研重点</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490255&amp;idx=1&amp;sn=777ca4e4be2ecd2711a3fb481f7b2d15&amp;chksm=eb07ee829aad336e95139069a5ecb973f5b713a743f7a090ef0618c0584893c751b8f6ee8949&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[白宫近日发布2027财年科研与发展（R&D）优先事项，将量子科学与人工智能提升至国家战略的核心位置。根据管理与预算办公室（OMB）和科学技术政策办公室（OSTP）联合发布的政策备忘录，美国将集中科研资]]></description><author>清熙</author><pubDate>Sun, 28 Sep 2025 08:36:45 +0800</pubDate></item><item><title>9月四篇 Nature 预示量子计算的新拐点？</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490244&amp;idx=1&amp;sn=8fabe56b44660a09a2085914315de38a&amp;chksm=ebc000de65457e317945cb9638af981e0770a948e29abfc5110a77974b489d0fa8ed964d2210&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[过去十年，量子计算的发展经历了一个典型的“科学探索—技术突破—工程化尝试”的周期。早期的关注点多集中在物理学原理能否实现、量子态能否稳定存在、操控是否可行。近年来，焦点逐渐转向：如何在更大规模、更长时]]></description><author>清熙</author><pubDate>Sat, 27 Sep 2025 12:00:00 +0800</pubDate></item><item><title>哈佛大学大模型可解释性研究有待商榷</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490243&amp;idx=1&amp;sn=3db8d2cfe56037d645c1db3b54fe4f7d&amp;chksm=eb2ad42709b4a8213f2b415ff36a1c2c0b122956d6b471b7685d8d2a0a4c8ac52e7ee41b27f2&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[当我们谈论 AI 的“可解释性”时，往往停留在一种含糊的直觉：只要能看到模型为什么做出某个决定，就算是解释了。但有个问题：这样的解释，是否真的能帮助我们预测模型在未来从未见过的数据上的表现？如果答案是]]></description><author>清熙</author><pubDate>Fri, 26 Sep 2025 20:16:06 +0800</pubDate></item><item><title>大脑注意力像变焦镜头一样工作</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490226&amp;idx=1&amp;sn=f630f30bcd803b52bf25a9c741b9705c&amp;chksm=eb742a918efb5350826748f6ca188b5ea747bd29d19a2e0ae28da0ac9700bcd6f79ea45a48fc&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[AST这个意识理论（普林斯顿：意识的注意力模式理论 （Attention Schema Theory：AST））是2015年普林斯顿神经科学与心理学学者联合提出，2025年笔者发现非常符合目前大模型的]]></description><author>清熙</author><pubDate>Thu, 25 Sep 2025 00:00:00 +0800</pubDate></item><item><title>Google Deepmind: 为流体动力学中的百年难题发现新解决方案</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490215&amp;idx=1&amp;sn=a98a2abf3f2cfac9e4e764ce5889fac3&amp;chksm=eb1940befeaa6a43c2c7efae9bdedab4c3cf576b9c58ea1c2438c9bd98088bbf91958a5585e9&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[译者注：这篇译者必须翻译推介，不要问为什么。数字动画展示了一个垂直的尖峰波，由黑色背景上的浅蓝色水滴表示。同心圆状的波纹环绕着一个中心点并向其荡漾，该中心点逐渐累积形成垂直尖峰。这种波形可以在造波池中]]></description><author>清熙</author><pubDate>Fri, 19 Sep 2025 21:00:00 +0800</pubDate></item><item><title>DeepSeek-R1 登 Nature，再看 GRPO，附改进建议</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490203&amp;idx=1&amp;sn=14cf415e4295b9959fa58f4a0cb91402&amp;chksm=eb4e67ecb70c10ce108f520d5d6a3482c6013be028023cd4410219d6d0bc85d5d20ca0bd9f85&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[今天一早被DeepSeek-R1 登 Nature 的消息刷屏，人民日报都发了：确实很赞，笔者第一时间拜读了论文，发现最核心的“方法 Methods”部分都是关于 GRPO 和 奖励Reward设计。]]></description><author>清熙</author><pubDate>Thu, 18 Sep 2025 13:00:18 +0800</pubDate></item><item><title>普林斯顿：意识的注意力模式理论 （Attention Schema Theory：AST）</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490194&amp;idx=1&amp;sn=87cf6deba37028abc9c6581d0f71dd2c&amp;chksm=ebdbd6043313f2572e89b8c0f0df940e48aa7f54550353c413b4031386ef202d976b11afc74c&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[论文：“The attention schema theory: a mechanistic account of subjective awareness”作者：Taylor W. Webb & M]]></description><author>清熙</author><pubDate>Wed, 17 Sep 2025 21:00:00 +0800</pubDate></item><item><title>“预制”大模型</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490187&amp;idx=1&amp;sn=a30076cfd9392dcc08627cdf1ee3ece2&amp;chksm=eb4593adea937060530b5b74271894350a88dd3ec1be66f5278a9315d4691ccfae2153ec7ce2&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[洛桑联邦理工学院与波士顿大学的学者们，刚刚实现了追踪大语言模型在预训练过程中特征的演化【文献1】。他们提出了一种叫做““稀疏交叉编码器””的方法，发现并对齐不同训练阶段的特征，从而清晰揭示特定概念何时]]></description><author>清熙</author><pubDate>Sun, 14 Sep 2025 16:18:00 +0800</pubDate></item><item><title>大模型数理认知框架的数学表述</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490178&amp;idx=1&amp;sn=bb9f1fb06d96a70d9b4dbd3e707368b5&amp;chksm=eb4136c3ee6188e5561a376c0257b48bebd543471451cbb05a58219b4c49aaba420f7428f865&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[范畴论、GRPO与CoT三位一体中笔者完善了大模型数理认知框架如下：笔者对文字解读部分也做了更新：1.海量的文本或者多模态语料组成了大模型需要认知的外部世界的基本信息；2.嵌入构建高维概率化的语言空间]]></description><author>清熙</author><pubDate>Sat, 13 Sep 2025 10:00:45 +0800</pubDate></item><item><title>为什么语言模型会产生幻觉，对比 OpenAI 、Google DeepMind 与笔者观点</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490152&amp;idx=1&amp;sn=7da9b92d825f03861794863fcae1a83a&amp;chksm=eb3fc6698c4856078cd110a199976582122beb42342053d3478b916d7c2e7ebe4857eed447fc&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[针对 OpenAI 刚刚发布《为什么语言模型会产生幻觉》的论文【文献 1】，与笔者 2023 年 9 月对大模型幻觉的分析 大模型的幻觉，解铃还须系铃人，笔者请 GPT-5 做了对比，以下是 GPT-]]></description><author>清熙</author><pubDate>Sun, 07 Sep 2025 00:00:00 +0800</pubDate></item><item><title>双螺旋 double helix</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490141&amp;idx=1&amp;sn=cd7501a2edafd4f520cbe8ca0372c0fa&amp;chksm=eb647362760a866ca0bce5d38368b84503b83dfa3ae348ba7c40600cc79741dcc3ac373e3bbf&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[加州理工学院的实验研究发现，等离子体通量绳中存在稳定的双螺旋态【文献 1】。研究聚焦于日冕，其温度远高于太阳表面，充满被强磁场“束缚”的等离子体。活跃的太阳活动如耀斑，常以磁通绳结构出现，该结构在宇宙]]></description><author>清熙</author><pubDate>Sat, 06 Sep 2025 14:56:59 +0800</pubDate></item><item><title>MIT：深度神经网络的重整化群原理</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490128&amp;idx=1&amp;sn=c48ddacd92766918f5a1454206aabd7f&amp;chksm=eb4cf5d3160a2585981e6b754a1458a81ce2991d8448bddd9c8a6b0fc6e2d8c3968f14b7ad2c&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[麻省理工、MetaAI、普林斯顿学者早在 2021 年就在著作【文献1，文末有电子版链接】中证明了深度神经网络与重整化群（RG）的统一性。全书第4.6章节是RG 与深度学习（DL）核心融合点，给出了笔]]></description><author>清熙</author><pubDate>Tue, 02 Sep 2025 20:00:00 +0800</pubDate></item><item><title>别再将工作流称为“智能体”，真正的AI智能体指南</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490111&amp;idx=1&amp;sn=4963379ba5858aa986c7e1496ac9dc59&amp;chksm=eb1dc7a061b376351e4994cb7f5415a5bc656e4720724995c079be558ba54dde093bc3384af1&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[作者：Jake Jones ，Flank 公司的联合创始人，该公司为法律团队开发能够自主处理日常事务的智能体。译者注：本文是 Jake 应 Artificial Lawyer 邀请撰写的观点文章，Ja]]></description><author>清熙</author><pubDate>Sun, 31 Aug 2025 14:16:24 +0800</pubDate></item><item><title>物理学家发现支配量子纠缠的普适定律</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490107&amp;idx=1&amp;sn=d7db3f4bbdcc36a5512044b8b589fbe8&amp;chksm=eb5e001503a09678b10c345a0798256535a49e117ef9fc72590e2299baa99e206e66c479395f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[量子力学一向神秘而且充满争议，没经历“Shut up and calculate”肯定没入门。量子纠缠是争议的最大源头之一，却也是当今量子计算、量子通信等先进科技的基石。业界共同的疑问，是否存在某种普]]></description><author>清熙</author><pubDate>Sat, 30 Aug 2025 14:26:58 +0800</pubDate></item><item><title>Nature：零功耗、纳秒级“光学”生成模型</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490093&amp;idx=1&amp;sn=67e79f2fd95f4e60b9f3f31e99e8f63e&amp;chksm=eb98a25ded930bab9259bd2cdfb0c1b4f407ae516e754b67547081054b65355216f01e75fcb0&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>清熙</author><pubDate>Thu, 28 Aug 2025 20:01:08 +0800</pubDate></item><item><title>蜜蜂的小脑袋藏着具身智能的秘密</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490060&amp;idx=1&amp;sn=33904ecda6ab2a83ee452b5039525cbf&amp;chksm=eb145a5b3259b3b7ed6fffe9ea83d5a8dd650bfba1cf46bf0e08608eac7d0185438ecbe422fa&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[蜜蜂大脑大约仅有 1 百万个神经元，却能完成复杂的导航、花朵识别和舞蹈交流任务。其卓越的视觉学习能力使其成为研究主动信息获取与表征的理想对象。目标近期发表在 eLife 的研究【文献1】开发了一个受生]]></description><author>清熙</author><pubDate>Sun, 24 Aug 2025 20:42:15 +0800</pubDate></item><item><title>用 Topos 探索 LLM 的新架构</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490050&amp;idx=1&amp;sn=d6d54c3bd1b30840e89999143d365c82&amp;chksm=eb5d8fa14ff3a7f98e0fce17e105b2529375a5b51a5a976af47b8870ae7ffa8a25cc9d0c3c2f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[尽管对 GPT-5 褒贬不一，行业共识是并未达到期待的超级智能，根因或许来自 Transformer 边际效用降低。前天 DeepSeek 悄悄上线 V3.1，不是万众期盼的 R2, 基准测试提升可圈]]></description><author>清熙</author><pubDate>Fri, 22 Aug 2025 21:48:07 +0800</pubDate></item><item><title>从 SEO 到 GEO：生成式搜索时代的新生意</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490048&amp;idx=1&amp;sn=2e5331c1a6b0f465094e0b04d327570f&amp;chksm=ebef2d7391f110c06bd997465cc792fcc56c4f58899e64dda7f5a1692d81da18635efac57ac9&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[搜索引擎优化（SEO）在过去二十多年里一直是互联网的基础产业。无论是百度、谷歌，还是电商平台，SEO 都决定了谁能在搜索结果中脱颖而出，从而获得用户流量与商业机会。然而，大模型正在颠覆搜索逻辑。传统的]]></description><author>清熙</author><pubDate>Tue, 19 Aug 2025 20:30:00 +0800</pubDate></item><item><title>今天被企业文化撞了一下腰</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490021&amp;idx=1&amp;sn=1498fa7c6b13dbc3eb8718ea45242cd5&amp;chksm=eb7cae75edab22ef55e5bdde9f852489c828ed70d3cc8309a9a9040f3a1c527a5054c9f56a15&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[今早等电梯发生一件有趣的事：一个膀阔腰圆的小伙站我左侧，电梯门一开，我径直启动准备进门（预判小伙也直走），然而小伙猛然横步向右前方走，撞击式阻拦了我一下。错愕间，我才注意到，小伙是笑容可掬地给不远处领]]></description><author>清熙</author><pubDate>Fri, 15 Aug 2025 20:20:00 +0800</pubDate></item><item><title>AI Agent不该是这个样子</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247490002&amp;idx=1&amp;sn=508f68701460adf399af2c2a4aa1e789&amp;chksm=eb204e9fec58bae0fc53306a4c3a07313f0b39b1772200b0c01418fc673ba5396619fe12ca8e&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[看到这张图，很感慨，但不是感慨图中的表面意思；Agent不该是这个样子，这是披着agent外衣的APP。LLM-Agent 的提出者 Lilian Weng看到这张图，不知作何感想；笔者看来，Agen]]></description><author>清熙</author><pubDate>Wed, 13 Aug 2025 20:50:05 +0800</pubDate></item><item><title>后GPT-5、DeepSeek R2时代，从扩散模型到 Transformer，统一视角下的概率流建模</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489993&amp;idx=1&amp;sn=47d1c10df391209429a5e2786f45ad50&amp;chksm=eb385b8e4efa7c31787ed6f53d749888f437b38053ca704214157d2fe7cf54607a4814b8f094&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[GPT5 发布，离万众期待的 ASI 还有距离，让大家更期待DeepSeek R2 了，尽管笔者看来，基于Transformer从训练、测试再到推理的 Scaling Law 潜力有边际效用递减的迹象]]></description><author>清熙</author><pubDate>Fri, 08 Aug 2025 20:30:00 +0800</pubDate></item><item><title>研究发现人脑天然具备量子计算能力，薛定谔“What is life”的问题可能也有了答案</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489954&amp;idx=1&amp;sn=d41cb18fb0ef97f345ba5fb7f61620e3&amp;chksm=eb133c039566febaa7ee2af6750cf9c7b01701fc8623e1e87f2e3eddfc422b3ba4519bdf90da&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[译者注：理论表明，意识是一种量子过程，将我们与整个宇宙相连，不少读者关注，文章没有“拜量子神教”的任何意图，纯粹形而上探讨，特此声明。新研究表明，富含色氨酸的特定蛋白质——尤其是脑细胞中的这类蛋白质—]]></description><author>清熙</author><pubDate>Thu, 31 Jul 2025 20:00:00 +0800</pubDate></item><item><title>Nature:探寻意识的种种可能形态</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489942&amp;idx=1&amp;sn=0675dd2fa29f00e3b875254d2782b035&amp;chksm=eb9ac3192dbf8da47bf14864448b2dc636afb9945af2462a73130a32774988ec5c091c698e41&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[人类大脑的研究成果或许能为科学家探索其他动物及人工智能的意识提供线索。2005年末，一场车祸发生五个月后，23岁的女性患者毫无反应地躺在病床上。她因严重脑损伤而丧失意识表征，但当研究人员扫描她的大脑并]]></description><author>清熙</author><pubDate>Wed, 30 Jul 2025 20:00:00 +0800</pubDate></item><item><title>范畴论、GRPO与CoT三位一体</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489928&amp;idx=1&amp;sn=11ef15b73eeab7c21e65cb5c30513957&amp;chksm=eb5bf24f9d8a1fc6943bf98a66caae36a2c86cb3573f5496efaf55a6a68b5a1efd389f5d64f6&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[笔者最近更新了大模型数理认知框架：重整化提取出范畴，持续重整化驱动范畴相变，然后逆重整化推理：关于 LLM对句法和语义惊人的理解力，大家可曾想到一个关键问题：如何以数学方式刻画 LLM 所学到的语言范]]></description><author>清熙</author><pubDate>Sun, 27 Jul 2025 08:19:00 +0800</pubDate></item><item><title>谷歌对“关系型基础模型”出手了</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489885&amp;idx=1&amp;sn=068c697ee57aaa831518bb6a7540bf30&amp;chksm=eb818c4bc8505522b36ede2f23a5bcd9296a96415c8400def6e8f06fb8abe29ab28d9fd9eac7&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[谷歌研究院今天放出一篇技术博客【文献 1】，介绍了其关系数据的图基础模型的工作。不久前笔者在 关系型基础模型 Relational Foundation Model 刚讨论了 Kumo AI 的 RF]]></description><author>清熙</author><pubDate>Fri, 11 Jul 2025 21:43:01 +0800</pubDate></item><item><title>颜色隐喻：统计范式 or 具身认知？</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489875&amp;idx=1&amp;sn=ab0706c578fd597790513cdf65a11f62&amp;chksm=eb88d810461ff9d3f1cddba1944dfbb744d8381fa7101a5e1f7306358689b6283f1033e47b80&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>清熙</author><pubDate>Wed, 09 Jul 2025 22:36:58 +0800</pubDate></item><item><title>理论表明，意识是一种量子过程，将我们与整个宇宙相连</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489864&amp;idx=1&amp;sn=f1a09098fd3fb98092ca99cee0a1dfda&amp;chksm=eb06a9175c63ded322bbd2374428c2776fc6c5385067d797b0c94f095377cdde4542b350c234&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[我们的意识看起来非常私密，仿佛仅属于每一个独立的个体。然而，许多研究人员猜想，意识可能连接着某种更宏大的存在。一项颇具争议的新理论提出，一种“量子纠缠”的机制可能发生在微管之中——那是构成我们每一个神]]></description><author>清熙</author><pubDate>Sun, 06 Jul 2025 08:00:19 +0800</pubDate></item><item><title>逆重整化梦回临界点</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489862&amp;idx=1&amp;sn=71acce6be73c81aedffd1abfb0c8d4ce&amp;chksm=eb550d52e4b8883f6b8e7ffa57f9a5441d420639af8da41713e0d88d58327c7fe525e946af4b&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[世界为什么会演化？世界为什么在不同尺度上能够保持某种一致性，甚至在临界点上呈现出自组织、自相似和信息极大化的结构？这是统计物理、复杂系统和生成式人工智能都绕不开的问题。大家已经熟悉，“重整化”是理解多]]></description><author>清熙</author><pubDate>Fri, 04 Jul 2025 20:00:00 +0800</pubDate></item><item><title>Nature: AI 与人类认知交汇</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489822&amp;idx=1&amp;sn=b8d0f9f065443c2f79896bcbd91b7b8a&amp;chksm=eb0cb14b0f8d0d15cd3b9097b8810b94ce0f2da770d79a8ed2ffebac6b2ac0b764ef641b6d26&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[随着人工智能、认知科学与神经科学的交汇日益加深，业界越来越关注AI模型与人类大脑在表征维度、学习机制以及组织结构方面的共性与差异。Nature 的四篇文献分别从“表征维度”、“多模态语义对齐”、“层次]]></description><author>清熙</author><pubDate>Sat, 28 Jun 2025 19:50:49 +0800</pubDate></item><item><title>《长安的荔枝》李善德最懂企业数字化</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489804&amp;idx=1&amp;sn=bdb5cd5318cded0a5f0a426e69e51539&amp;chksm=eb8070a8bafd7630c5cecdd9ac274a149361f21ce8fad1b1e7eaefe1d97abd2630342ba3efe5&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[马伯庸笔下的《长安的荔枝》火了，在笔者看来，一个关于古代"社畜"的黑色幽默，却成为投射企业数字化的镜子。一千年前，唐朝九品小吏李善德面对"一骑红尘妃子笑"的mission impossible，用尽浑]]></description><author>清熙</author><pubDate>Thu, 26 Jun 2025 20:00:00 +0800</pubDate></item><item><title>AGI 时代如何选择大学专业</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489784&amp;idx=1&amp;sn=c62f49f84341e92b73a687a471137210&amp;chksm=ebf1f92837ab364d4731937e2379bf76d04c14ffba3ca97364dd2e03c0b4e1b7908f5ae6aa60&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[笔者问了ChatGPT 关于“AGI 时代如何选择大学专业”的问题，以下是祂的精彩回复，笔者深以为然，分享给大家。高考之后的专业选择，往往决定了未来10年甚至更长时间的发展方向。而在当前大模型（LLM]]></description><author>清熙</author><pubDate>Mon, 23 Jun 2025 17:03:40 +0800</pubDate></item><item><title>Nature：道法自然的真随机数</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489747&amp;idx=1&amp;sn=f9e79597711c609d3c945e81f66919dc&amp;chksm=eb659b66cf96ad05ed927a7a92b99f29fb791aff7b8e92e97370e4a9581907c555ed63078282&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[随机数的不可预测性是数字安全与公平资源分配应用的基石。然而现有随机数生成过程无法被完整追踪、审计并确保真正不可预测：伪随机数生成器的算法步骤虽可审计，却无法保证在已知初始种子条件下的输出结果具有先验不]]></description><author>清熙</author><pubDate>Sun, 15 Jun 2025 12:01:27 +0800</pubDate></item><item><title>人生感悟送给高考考生 -- 三重寓言与时代激流，在不确定中锚定人生价值</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489727&amp;idx=1&amp;sn=bd9f45f63949ee41275c2e55d6c22fa4&amp;chksm=eb384e49297ffe1087b364e39e1c1d95bc758bf6422912fc9aa7234fb39735db78118d1d98e7&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[高考的笔落下，是人生长卷中一个清晰却非决定性的标点，此刻我更想分享自己关于个体存在的洞察：个体生命的轨迹，暗合三个中小学语文课本上的古老寓言。卖油翁的油穿钱孔，昭示着通往卓越的路径，在于对“过程”本身]]></description><author>清熙</author><pubDate>Sat, 07 Jun 2025 07:30:22 +0800</pubDate></item><item><title>Nature: 精度不受热力学第二定律限制</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489721&amp;idx=1&amp;sn=cff8b73265b37b6ba1a6fb4ffa323f3b&amp;chksm=ebbe6400c2996407a04307bd841a27bc211b7efd1b95a9bb26a456371233b4032fabe41507c4&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[今天开幕的智源大会主题演讲中，Yoshua Bengio 判断5年内出现人类水平AI；强化学习之父Richard Sutton则预见了AI的体验时代。笔者理解Sutton说的是真实时空的具身体验，需要]]></description><author>清熙</author><pubDate>Fri, 06 Jun 2025 19:30:00 +0800</pubDate></item><item><title>突破信息茧房，迈向自主进化</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489691&amp;idx=1&amp;sn=a9fb0765fe0842182041b410c79fd183&amp;chksm=eb82208f34e173bfdb6f671c0b5d502c08a3fc5014d9b453d20604a7023a0037d8c754d74baa&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[近期看到一个大模型研究领域有井喷趋势：如何让模型在无需人类过多干预的情况下实现自我提升。自我发展框架让LLM自主生成并优化模型改进算法，通过聚焦模型融合策略，初始模型能通过发现新型融合技术实现迭代升级]]></description><author>清熙</author><pubDate>Sun, 01 Jun 2025 14:42:45 +0800</pubDate></item><item><title>Nvidia的具身推理模型还缺什么</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489666&amp;idx=1&amp;sn=f924082cdd6c928dc313af4feb85a26d&amp;chksm=ebd207139ac7d2ffab32e20c319b69cbe31a4bbbc33e087a1dc11553ff095405a0e0b6ae930a&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[物理人工智能系统需要感知、理解并在物理世界中执行复杂动作，Nvidia Cosmos-Reason1 【文献1】就是为此而设计。一、Cosmos-Reason1Cosmos-Reason1模型系列宣称]]></description><author>清熙</author><pubDate>Sat, 24 May 2025 17:08:36 +0800</pubDate></item><item><title>算术表达式几何 (AEG)：流、累积、双重时间标度与重整化的极简实现</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489650&amp;idx=1&amp;sn=fae201962e10b8008ec8538db8ce64fc&amp;chksm=eb6fbc42022fc047348fd785ee6f8d31fc6e9ba9fd19e32bc72ef1cd9ba84ae4393d5495ad55&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[作者自述：一位求学者，二十年程序员生涯，游走于工程、语言、知识、智能、数学之间，内心对世界充满诸多好奇与困惑，尝听友人讲大刘《山》的故事，也期自己可凭蛮力，凿空厚壁，得见星空。 引言算术表达式几何 (]]></description><author>清熙</author><pubDate>Tue, 20 May 2025 21:13:27 +0800</pubDate></item><item><title>简评MIT团队提出的神经热力学定律</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489645&amp;idx=1&amp;sn=9bf7d76fb681d7d8c5eb25484ddae113&amp;chksm=ebf30fc884a523f874c371500f553960b5ad0c066190f5b393c576ee90d0a373e0e15c870a0e&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[近日麻省理工学院团队提出了神经热力学定律（NTL，neural thermodynamic laws）【文献1】，笔者这里做个简评。学者们提出LLM损失景观的“河–谷分解法”，引入可解的二阶简化模型，]]></description><author>清熙</author><pubDate>Sat, 17 May 2025 22:08:32 +0800</pubDate></item><item><title>暗物质是在快速运动的粒子减速并变重时形成的</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489640&amp;idx=1&amp;sn=82f7d2887013593c7b3c079d8691f828&amp;chksm=eb3872f1a11bffce613c583629ba7f2dab74c51d1c17374e0d6829797b594c0d6bfbbf092192&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[译者注：论文结论跟沿最优输运方向的重整化可能是世界演化的核心方式 中笔者的如下表述一致：“能量在时空中流动，穿越边界的通量变化，派生散度与旋度，即电场和磁场；波放慢速度钝化成粒子（薛定谔的爱情与狄拉克]]></description><author>清熙</author><pubDate>Fri, 16 May 2025 20:00:00 +0800</pubDate></item><item><title>沿最优输运方向的重整化可能是世界演化的核心方式</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489629&amp;idx=1&amp;sn=fee8c0bee0a57100eb1cb6532d696609&amp;chksm=ebeea6e19c9dbd1efc1be6c403ac455a598ad20530fb7f90cd6409c3440de1da20b744f62d12&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[早在2014年，Mehta和Schwab就证明了“基于受限玻尔兹曼机（RBM）的深度模型和变分RG之间存在精确对应”。深度网络底层神经元捕捉细节，高层神经元提取抽象特征，本质上等同于RG中积分掉高频自]]></description><author>清熙</author><pubDate>Sat, 10 May 2025 19:34:17 +0800</pubDate></item><item><title>线性振荡状态空间模型</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489603&amp;idx=1&amp;sn=d3ae046ee56cd560fb361a6ff1a0323b&amp;chksm=eb13f7e96ace7115fa87ef15821adac07e6f5d388acade38a3e4531a731f98d21efd22b9a055&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[麻省理工学院研究团队提出了一种以大脑节律为灵感的新型机器学习模型——线性振荡状态空间模型（Linear Oscillatory State-Space Models，简称 LinOSS）【文献1】。它]]></description><author>清熙</author><pubDate>Sun, 04 May 2025 00:00:00 +0800</pubDate></item><item><title>AI智能体时代已来临，安全威胁也接踵而至</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489594&amp;idx=1&amp;sn=dd7cc7dac48fe07552a6a6407605c085&amp;chksm=eb62574c2c09380d48447d905b041905586adaff726dd8a02f3f8755adcdd079d7efa64870a1&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[摘要Agentic 应用是利用 AI 智能体驱动功能的程序——这些智能体是为自主收集数据并朝着特定目标采取行动而设计的软件。随着 AI 智能体在现实世界中的应用日益广泛，理解其安全影响变得至关重要。本]]></description><author>清熙</author><pubDate>Sat, 03 May 2025 20:31:18 +0800</pubDate></item><item><title>DeepSeek-Prover-V2-671B 发布，LEAN + GRPO的威力</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489571&amp;idx=1&amp;sn=9efebc87a7f169e886c42ed927cbbbe7&amp;chksm=ebccbff6890e76e3dd86208f575a738813199bdd2a54327a0ec5c08f859d1ff12ad2276ee70d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[昨晚笔者总结整理了 d1：通过GRPO在扩散LLM中缩放推理 ， 带大家领略了 diffusion + GRPO 威力，也再次印证笔者关于GRPO 是DeepSeek魔法的源泉的判断。无独有偶，另一个]]></description><author>清熙</author><pubDate>Wed, 30 Apr 2025 21:09:26 +0800</pubDate></item><item><title>d1：通过GRPO在扩散LLM中缩放推理</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489557&amp;idx=1&amp;sn=163a275576b256922c52b6cc9099f759&amp;chksm=eb2f24d39eb90f3c5c5dd96cdf8387dac49b6c27dbe4b57d25618edd7b928c95a0914972eb04&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[加州大学洛杉矶分校与Meta AI的研究团队联合发布了革命性的强化学习框架d1【文献1】。该框架显著提升了基于扩散原理的LLM（dLLM）的推理性能——在某些场景下将响应时间从超过30秒缩短至仅需3秒]]></description><author>清熙</author><pubDate>Tue, 29 Apr 2025 21:58:17 +0800</pubDate></item><item><title>捕获AI的注意力：重复、幻觉、偏见背后的物理学</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489514&amp;idx=1&amp;sn=a8c9e4316a4b472c2f963c9a9109cf37&amp;chksm=eb9632f68212bbc1102518cbbefff048b72c9614a021fd5ce2ca7186f28f154093af6834956f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Spin-Transformer数据雕刻自旋玻璃 中笔者总结过：“从概念上的相似性、物理解释、优化参数规模角度，基于矢量自旋磁化的平均场新方程，提出了一类受物理启发的 spin-transformer]]></description><author>清熙</author><pubDate>Thu, 24 Apr 2025 00:00:00 +0800</pubDate></item><item><title>语言与扩散模型的精准控制</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489501&amp;idx=1&amp;sn=2aa451eb582681c0e0899978021b6610&amp;chksm=ebf7cd935db21e75d584064d463f9371db9acc1f8d97b8d9c4268a7aacc363ec3795e3b05915&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[笔者近日在朋友圈发了如下感慨：“现在太多科幻叙事下的公司AI战略，看了让人触目惊心，可以判断这些做AI战略的人几乎不看paper的。现在的大模型做个六七十分的demo非常擅长，对企业生产场景却缺乏精准]]></description><author>清熙</author><pubDate>Fri, 11 Apr 2025 20:00:00 +0800</pubDate></item><item><title>Nature：通用光子 AI 加速</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489487&amp;idx=1&amp;sn=a997de3fb5f10636a2870e72a7f5823a&amp;chksm=eb562acac420019432958affc64bba3139216eaa3fea2512ebed0602d7cb5a1410ce96745539&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[编者注：AI飞速发展的同时，各种新型计算也在不断取得突破，光子、量子、Ising机、热力学计算等，请参考：Ising 机 - Nature 灌水机Nature:薛定谔的猫突破迎来量子计算的圣杯AI 赋]]></description><author>清熙</author><pubDate>Thu, 10 Apr 2025 21:10:43 +0800</pubDate></item><item><title>新型人工神经元实现生物启发的自主协同学习</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489477&amp;idx=1&amp;sn=fa3b1ca6ea48dceb672e89f7b4181614&amp;chksm=ebd0ee763a6d09cc8784421392014aa724d42cf79cb27ac160de20bf5b721e54224e09c8d6e7&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[传统人工神经网络依赖全局调控的学习模式可能被改写。德国哥廷根大学与马克斯·普朗克动力学与自组织研究所的联合团队，日前在《美国国家科学院院刊》（PNAS）发表研究【文献1】，开发出具有生物神经元特性的"]]></description><author>清熙</author><pubDate>Sun, 06 Apr 2025 21:43:45 +0800</pubDate></item><item><title>东京大学：基于逆重整化群流的生成扩散模型</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489466&amp;idx=1&amp;sn=a454bea9ef3f844571795ab29dc18864&amp;chksm=eb5089b7900f0b95d4aa2cbe1363151c588a85c530704d73b0598c4bd6180f602ab7ad0658a1&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[哈佛大学：高维回归中的Scaling Law是重整化的自然结果 从理论角度分析了重整化的物理意义，东京大学物理系学者的文章【文献1】则更接地气、更落地实用。摘要扩散模型基本原理是通过去噪白噪声污染的样]]></description><author>清熙</author><pubDate>Fri, 04 Apr 2025 11:31:06 +0800</pubDate></item><item><title>哈佛大学：高维回归中的Scaling Law是重整化的自然结果</title><link>http://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247489452&amp;idx=1&amp;sn=1e3f9bfd755a9e05795632c70120554a&amp;chksm=ebac6da6de7d710cf1690fbaa62221544532298267f65d245d5b5131836ca5f48e8e5108bdbf&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[《高维回归中的缩放和重整化》【文献1】由哈佛大学物理系、脑科学中心、工程与应用科学学院、自然与人工智能研究所多位学者共同撰写，将随机矩阵理论和自由概率用于理解高维岭回归模型的缩放与重整化行为。一、背景]]></description><author>清熙</author><pubDate>Tue, 01 Apr 2025 22:19:01 +0800</pubDate></item></channel></rss>