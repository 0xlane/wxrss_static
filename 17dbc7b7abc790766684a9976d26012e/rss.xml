<?xml version="1.0" encoding="utf-8"?><rss version="2.0"><channel><title>AI大模型调参指北笔记</title><link>https://wxrss.reinject.top/17dbc7b7abc790766684a9976d26012e/</link><description>An RSS feed.</description><language>zh-cn</language><lastBuildDate>Sun, 26 Oct 2025 03:32:53 +0800</lastBuildDate><generator>wxrss -- https://github.com/0xlane/wxrss</generator><item><title>nlohmann/json 库简介</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496204&amp;idx=1&amp;sn=3cb9cf4dfa2433e4333e55ca5aaeb58f&amp;chksm=c03de81735afdddcd7642a9058ee6f182acc0f6c6bb1ef93a6376d8c7cb75d28f52ab71c8158&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[nlohmann/json 是一个专为现代 C++ 设计的 JSON 库，以其直观的 API、强大的功能性和卓越的易用性而广受欢迎。下面综合介绍其主要特性、安装集成、核心功能及适用场景。主要特性nl]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 23 Oct 2025 22:02:31 +0800</pubDate></item><item><title>Intro to C++ Coroutines: Concept</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496184&amp;idx=1&amp;sn=d9285c83defdd115d7f09d7733894a1b&amp;chksm=c085fd2399821b6f0c372e9ca68bf585b5a15f5126428d10c59cd34fc32823bdc29740693953&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[各位开发者，时机已到。我们即将揭开 C++ 语言的最新概念——协程。它们已经被多种编程语言所采用，比如• C# 的异步任务和可生成迭代器，构成了 LINQ 的基础；• JavaScript 中的 a]]></description><author>AI大模型调参指北笔记</author><pubDate>Wed, 22 Oct 2025 22:00:00 +0800</pubDate></item><item><title>Hugging Face BPE Tokenizer 的资源文件</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496179&amp;idx=1&amp;sn=564faecef4a491325606285b0b4b5567&amp;chksm=c0a049e936610df2f83427469810425f543875016f9493a4d4b1deec8b54266ebf7b350a7f3d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在Hugging Face等平台的大语言模型中，vocab.json、merges.txt 和 added_tokens.json 是分词器（Tokenizer）的核心配置文件。它们共同定义了如何将]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 20 Oct 2025 22:00:00 +0800</pubDate></item><item><title>移动语义 std::move 和完美转发 std::forward</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496177&amp;idx=1&amp;sn=b4f08286105b09d7e670a7ccf1bd7558&amp;chksm=c04cf730ae9c9b2683974a31e320cbcc4e7860b85e8ad74ab98d27dc583553622b4768cf5bdf&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[移动语义和完美转发是现代C++中用于提升程序效率的两个重要特性。下面这个表格清晰地展示了它们的主要特点。特性核心目标关键机制主要应用场景移动语义转移资源所有权，避免不必要的深拷贝，提升性能。右值引用]]></description><author>AI大模型调参指北笔记</author><pubDate>Sun, 19 Oct 2025 21:57:41 +0800</pubDate></item><item><title>ACEBench: Who Wins the Match Point in Tool Usage?</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496154&amp;idx=1&amp;sn=2fa5d2799baab74aef8a09d4bae8584e&amp;chksm=c0dc98c7ff9a8076d5216a614dd5f66d46fd7e78275e1cb5eaed3189163a7feadc87d9aa22f4&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Abstract大型语言模型（LLMs）在决策和推理方面已展现出显著的潜力，尤其是在与各种工具相结合的情况下，能够有效地解决复杂问题。然而，目前用于评估 LLMs 工具使用能力的基准存在一些局限性：]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 14 Oct 2025 21:35:00 +0800</pubDate></item><item><title>什么是左值和右值</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496110&amp;idx=1&amp;sn=7262fe79228ae3b4a405366df75e284f&amp;chksm=c0dfff82b6e0f531f12b208d7b1bb17bd52841b91e1602feb7de9ae80500cb0711ed723bc265&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[左值和右值是编程中用于区分表达式两种不同性质的核心概念，理解它们对于掌握C/C++等语言的内存管理和性能优化至关重要。下面这个表格能帮你快速把握它们的主要区别：特性左值 (Lvalue)右值 (Rv]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 13 Oct 2025 21:00:00 +0800</pubDate></item><item><title>什么是 GN</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496102&amp;idx=1&amp;sn=9ebf0da11f5e372577f702143f28c380&amp;chksm=c042bd5ec8e04aa885f02fd6ce69b3f102fbd551c00d2caa6417769d40c2f3d0c2639cab9d04&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[什么是 GNGNgn与ninja类似于cmake和makeGN 是 Google 开发的一种元构建系统（Meta-Build System），用于生成 Ninja 构建文件（.ninja）。核心功能]]></description><author>AI大模型调参指北笔记</author><pubDate>Sun, 12 Oct 2025 14:28:25 +0800</pubDate></item><item><title>RULER: Relative Universal LLM-Elicited Rewards</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496097&amp;idx=1&amp;sn=2b3b27bfe3879050e3a38805d02f6395&amp;chksm=c0206df77f0ec691c9484a37ad0856b8b874a7f1ba21db44105312b8f95be553d4768a18626b&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在这里插入图片描述“RULER（Relative Universal LLM-Elicited Rewards）”是一种通用型奖励函数，它利用语言模型作为评判者来对多个智能体的行动轨迹进行排序。该机]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 09 Oct 2025 22:09:49 +0800</pubDate></item><item><title>古寺步道</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496095&amp;idx=1&amp;sn=0cad681a060e89c5df8208d722ba2061&amp;chksm=c065fff3a4ad944f4751f25350f88bc8fad46183d752d8a34037faf9fd8060005f5ac135e8c2&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>AI大模型调参指北笔记</author><pubDate>Sat, 04 Oct 2025 16:52:08 +0800</pubDate></item><item><title>阿基米德水系</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496089&amp;idx=1&amp;sn=0dbd5ee3e3eb794eed887af718f4cda9&amp;chksm=c04bef95a1d322d46e0dc1b251b59d005f65715fa52d9d981924cebd50d63020eb358cc1b532&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>AI大模型调参指北笔记</author><pubDate>Sun, 28 Sep 2025 18:41:38 +0800</pubDate></item><item><title>SFT和RFT的区别</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496084&amp;idx=1&amp;sn=7ed749bb89d0377d67782065a06349c2&amp;chksm=c09ceccc9017a4e9ad8466cc07302967c1b3e362b6204c378a4b7a21495f828279a67ff52474&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[SFT（监督微调）和RFT（强化学习微调）是优化大型语言模型（LLMs）的两种核心技术，它们在理念、实现方式和适用场景上有着显著区别。下面这张表格汇总了它们的主要差异，方便你快速了解：对比维度监督微]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 25 Sep 2025 21:00:00 +0800</pubDate></item><item><title>CosyVoice 3: 面向真实场景的大规模零样本语音生成模型</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496078&amp;idx=1&amp;sn=b69275f0bb5812e2b18a1138f46e803a&amp;chksm=c0effdc0370d8a34ebb4b1ffce5e8e53afde60823d5e0a5f0d3d3ee84858f670ba08f49cb462&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[一、研究背景与目标问题定位：• 前作局限：CosyVoice 2虽实现低延迟流式合成和接近人声的质量，但在语言覆盖（仅中英文）、领域多样性（广播场景为主）、数据规模（万小时级）和文本鲁棒性（特殊符号]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 16 Sep 2025 21:00:00 +0800</pubDate></item><item><title>逆转诅咒：在 A=B 上训练的语言模型无法学习 B=A</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496073&amp;idx=1&amp;sn=59cf8cc25803e3293728adbfe289dd58&amp;chksm=c0a97be0930698ca00aa4ee3c84a0e022fcb78eda7a19a2f8f636dcd2d155f56f0553f7d30ca&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[论文揭示了自回归大型语言模型（LLMs）在逻辑泛化上的一个根本性缺陷，即“逆转诅咒”（Reversal Curse）。以下是论文的核心内容：在这里插入图片描述比较早的论文了，现在是否还存在这个问题有]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 09 Sep 2025 22:07:09 +0800</pubDate></item><item><title>CosyVoice 3: Towards In-the-wild Speech Generation</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496072&amp;idx=1&amp;sn=6aad1476c76d8849f56e7c3a38050f09&amp;chksm=c0c6efb041248a13facf0fcb947657086de8808ceb57e7fe3b41a671ee91666dea6d83c7039b&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Abstract在我们之前的工作中，我们推出了一个可扩展的流式语音合成模型 CosyVoice 2，它将大型语言模型（LLM）与分块感知流匹配（FM）模型相结合，实现了低延迟的双流语音合成和人类同等]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 04 Sep 2025 21:40:34 +0800</pubDate></item><item><title>语音合成（TTS）中文自然度：问题、成因、解决方案</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496039&amp;idx=1&amp;sn=9c2ecf033713aa7f37526b9fbe0778ad&amp;chksm=c0a19411a32f3137bddacd958af7e7f9b3b06fd13907b6d5f9336dfdbee0076a1c15c38998c1&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[我们来深度解析这篇关于中文语音合成（TTS）自然度问题、成因与解决方案的文章。文章结构清晰，内容深入，聚焦于中文TTS的独特挑战和前沿解决方案。核心主题： 提升中文TTS的自然度，关键在于解决其特有]]></description><author>AI大模型调参指北笔记</author><pubDate>Wed, 03 Sep 2025 21:00:00 +0800</pubDate></item><item><title>上下文工程如何实现</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496036&amp;idx=1&amp;sn=b1533d247085c6a8728b1e534585c0d9&amp;chksm=c0499678f0fe71d82a93cb38cdb3c1cc58bcd0ac01a71e08b8f0e2958e7e28c489eab0e16423&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[核心技术更长的上下文并不一定会产生更好的响应，上下文过载可能会导致应用程序以意想不到的方式失败，上下文可能会变得有害、分散注意力、令人困惑或产生冲突。• 上下文污染（Context Poisonin]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 02 Sep 2025 21:00:00 +0800</pubDate></item><item><title>上下文工程（Context Engineering）</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496032&amp;idx=1&amp;sn=499a09ac3c3f7cef25bcb7113cbf8645&amp;chksm=c0c9fd873caa16aba8abdf1dd3f132f4a230d30ef52354dea1c62eed816360ea81c6c82676f2&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[背景目前Prompt工程已相对成熟，已有大量最佳实践和工具支持。但Prompt工程有一定的局限性，想象一下，你正在使用大模型解决一个复杂的工作问题，传统的做法是精心设计一个提示词，希望一次性得到满意]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 01 Sep 2025 21:00:00 +0800</pubDate></item><item><title>新手必看！LangGraph 101：手把手教你搭一个深度研究 Agent</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496031&amp;idx=1&amp;sn=db71f6829d9947d433333ba93bc3e1fb&amp;chksm=c09fe2c2be4af53d1e2964cdf2f86b1249ef97b067d0a574e74f5588b33747099d9c484ea6b2&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[构建能够在实际中真正发挥作用的大型语言模型（LLM）程序并非易事。您需要考虑如何协调这一多步骤的工作流程，跟踪各参与者的状态，实施必要的限制措施，并实时监控决策过程。幸运的是，LangGrap]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 28 Aug 2025 21:24:08 +0800</pubDate></item><item><title>LangGraph 简介</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247496027&amp;idx=1&amp;sn=9ca04a5b2f0e00378b44e37b33453aba&amp;chksm=c09ce52f001b7992075b3e80a382053aae1d9624aa5e5a8eae766d5bae40db4dc980106f0465&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在这里插入图片描述LangGraph 是由 LangChain 团队开发的开源框架，专为构建状态化、多智能体（Multi-Agent）动态工作流而设计。它通过图结构（Graph） 管理复杂任务流程，]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 26 Aug 2025 21:06:31 +0800</pubDate></item><item><title>SFT 泛化新解读：强化学习 + 奖励修正，一文读懂</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495996&amp;idx=1&amp;sn=5510a32a006f25036e1bc653c4f0dd99&amp;chksm=c070941f18d47942a907a116990c7fae91c46f5c83e03c9746664cb8d761ab0d25d75ecb33a8&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[1. 研究背景与问题• SFT的局限性：传统监督微调（SFT）在LLM任务适配中简单高效，但泛化能力弱于强化学习（RL）。RL依赖奖励信号探索策略，但计算成本高且需人工设计奖励函数。• 核心问题：能]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 21 Aug 2025 21:18:09 +0800</pubDate></item><item><title>程序员狂喜！Self-Instruct 框架全解析：无限生成高质量指令集，从此告别标注噩梦！</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495987&amp;idx=1&amp;sn=406bc88495a08edee680962314a19852&amp;chksm=c0c2da14a75597101264c494947c44a7d37b5db4129871525d64093b84a25fd8d03d5d2df69b&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在这里插入图片描述MotivationHigh-level overview of InstructGPT with human annotated outputs and ranking for]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 19 Aug 2025 21:51:07 +0800</pubDate></item><item><title>Evol-Instruct 竟能精准生成领域专属数据？实操技巧速看！</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495983&amp;idx=1&amp;sn=a7d40222007b4b32807524afb069dad0&amp;chksm=c0ce2f4e02d1ae09a24921f343d97f417949edf917734a185fc5bae2e0bcd32fcf4f60f49845&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在不断发展的人工智能领域，能够对模型进行微调以使其理解并适应特定领域至关重要。这一过程类似于音乐家在表演前调校乐器；调校得越精准，在特定的声学环境中表现就越出色。在这里，我们的“声学环境”就是希望人]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 18 Aug 2025 22:13:20 +0800</pubDate></item><item><title>Pygame RPG Tutorial 7 – Attack Animations</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495978&amp;idx=1&amp;sn=3e65232d4286674d2ce57ffcb68dc839&amp;chksm=c0191e0f94667a3197f8513b8afd417dc62d8f8880142d6edf59b116dbfe062af670ca5c5549&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[我们的球员目前缺少的一个主要组成部分是进攻系统。幸运的是，这与我们的运动动画系统的实现方式非常相似，所以本教程应该很容易理解。一旦我们创造了这个基本的攻击系统，我们就可以轻松地将其扩展为包含许多其他类]]></description><author>AI大模型调参指北笔记</author><pubDate>Sat, 16 Aug 2025 19:43:00 +0800</pubDate></item><item><title>《Pygame RPG 开发实战：1-6 系列第 1 期代码细评，从逻辑到效率的提升指南》</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495977&amp;idx=1&amp;sn=c25202989b61e68123ca5f02f7c2d3ef&amp;chksm=c0a2757f426854fa7d401823adaf1ce368704ca144b37290b4dd6f46330d9d21c5f26bfc7d95&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在这里，您可以查看我们到目前为止编写的Pygame RPG系列的完整代码。这次代码审查背后的主要原因是，到目前为止，我们一直在讨论小片段的代码（由于绝对的大小）。对于那些在将这些片段连接成一个整体时遇]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 14 Aug 2025 21:00:00 +0800</pubDate></item><item><title>指令微调数据-少即是多</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495976&amp;idx=1&amp;sn=bb3f607b9765c0263681ef0476615fb8&amp;chksm=c0ba44d8e4834531a93840f7b20622dcb8d0e5ff6dab6c4013a372229a4cdee2d7c9a5dd3452&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[如何对大型语言模型进行微调以用于通用问题解答？一种颇具吸引力的方法是采用对少量高质量样本进行有监督微调的方式。近期的 LIMA（“对于对齐而言，少即是多”）研究大胆宣称，通过仅基于 1000 对]]></description><author>AI大模型调参指北笔记</author><pubDate>Wed, 13 Aug 2025 21:33:30 +0800</pubDate></item><item><title>LLM generate 参数怎么用？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495962&amp;idx=1&amp;sn=9490fb5107441f310dc454146be348cd&amp;chksm=c00a82845ae78eb318415d938774da9eaca5ce8698e6de7532a0490c85d1297221b492ea3366&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[要让 LLM 模型的推理结果更稳定、更确定（即减少随机性、提高可预测性），需要合理配置 temperature 和 top_p 参数。以下是具体策略和推荐配置：一、参数作用机制1. temperat]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 12 Aug 2025 21:51:47 +0800</pubDate></item><item><title>语音合成（TTS）跳跃与重复问题的解析：成因、机制及解决方案</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495949&amp;idx=1&amp;sn=d614604962f9f25aea7f426b8530ad35&amp;chksm=c0b92ec30b7f49e7e13943a76c6ca23370998e6d7ee12196fbb555fca93d913a3cd1a3123926&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[一、问题本质与影响• 跳跃（Omission）：漏读音素/词/短语，表现为音频中断或静音段。• 重复（Repetition）：非预期重复音素/词/短语。• 根本影响：破坏语音清晰度、自然度与用户体验]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 11 Aug 2025 21:14:29 +0800</pubDate></item><item><title>大模型训练新思路：GEPA 靠 “反思” 赢过 RL，看完秒懂</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495946&amp;idx=1&amp;sn=8eb9847d63ac771219147bdac7532a90&amp;chksm=c01d17bc891d1624133c2b6ba2cad28ace454013fd045671eee8294a9afcedc7a9bf764b8dfb&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[倘若一种人工智能模型能够从自身的错误中吸取教训，不是通过机械的反复训练，而是通过深思熟虑的反思，就像人类那样，那将会是怎样的情景呢？这就是“GEPA（基因-帕累托）”所承诺的效果，这一开创性的方法由]]></description><author>AI大模型调参指北笔记</author><pubDate>Fri, 08 Aug 2025 20:45:07 +0800</pubDate></item><item><title>F5-TTS：用 Flow Matching 玩转语音，流畅度和真实感都 “拉满” 了</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495911&amp;idx=1&amp;sn=60b9c5e27b5241939e0ae3a15614a34d&amp;chksm=c088c2fb9fb85398d149d051de63fb5b2a2d30260b760e1bd42733009e798ff2959c3d71981a&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Abstract本文介绍了 F5-TTS，这是一种基于流匹配与扩散变压器（DiT）的完全非自回归文本转语音系统。它无需诸如时长模型、文本编码器和音素对齐等复杂设计，直接将文本输入用填充标记填充至与输]]></description><author>AI大模型调参指北笔记</author><pubDate>Wed, 06 Aug 2025 22:16:13 +0800</pubDate></item><item><title>E2 TTS：令人尴尬地简单、完全非自回归、零样本的语音合成技术</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495896&amp;idx=1&amp;sn=81e61ad0363214a3431575483b4128a6&amp;chksm=c0be178dfd110e462e5645add58b5762426c69918f75888503cf3ed0b2642ff3aee9284e1501&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[ABSTRACT本文介绍了“毫不费力的文本转语音”（E2 TTS）系统，这是一款完全非自回归的零样本文本转语音系统，其具备接近人类水平的自然度、先进的说话人相似度和清晰度。在 E2 TTS 框架中，]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 04 Aug 2025 22:00:00 +0800</pubDate></item><item><title>为什么都在聊 Kimi K2？Open Agentic Intelligence 藏着哪些新惊喜</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495879&amp;idx=1&amp;sn=866cb0550891e230a5176c87b37cce06&amp;chksm=c095d62f805fd58e12d7999c7e6eea5672559c7f3bf660cbe16f56fd65cc0d8beece4bddee20&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[ABSTRACT我们推出 Kimi K2，这是一款拥有 32B 激活参数和 1T 总参数的专家混合（MoE）大型语言模型。我们提出了 MuonClip 优化器，它在 Muon 的基础上采用了一种新颖]]></description><author>AI大模型调参指北笔记</author><pubDate>Wed, 30 Jul 2025 22:30:17 +0800</pubDate></item><item><title>Step-Audio-AQAA 端到端音频模型</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495875&amp;idx=1&amp;sn=0a6633e2a871168d2127fdd65e2718e0&amp;chksm=c0748715c318f90f05f52c7b655ca9f195869db2799205e6049660888e633675a0a20a93418b&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[1. 研究背景与核心问题• 现状：现有大型音频语言模型（LALMs）依赖文本输出，需额外调用ASR/TTS模块生成语音，导致级联错误累积和系统复杂性增加。• 关键挑战：缺乏端到端模型直接处理音频输入]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 28 Jul 2025 22:03:00 +0800</pubDate></item><item><title>CFM 与 OT-CFM：条件流匹配与最优传输的碰撞</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495795&amp;idx=1&amp;sn=0fdfcac6ee2217931fdff7ece6f6a062&amp;chksm=c09ed9917e8798065c4f30c8dccaf9a3eb943f01d33d63826e392a0a6897b182a5cd3f379101&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在这里插入图片描述1. 核心目标提出条件流匹配（CFM） 及其优化版本OT-CFM，解决连续标准化流（CNF）中模拟ODE的困难，并通过最优传输减少路径交叉问题。2. 关键概念(1) Flow Ma]]></description><author>AI大模型调参指北笔记</author><pubDate>Fri, 11 Jul 2025 21:18:31 +0800</pubDate></item><item><title>DPO损失实现</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495789&amp;idx=1&amp;sn=58b883613d4b0e5f0bdb72b4820b2ff2&amp;chksm=c01fb0f310611219f5c3c3c43a8f316f2f3887c62f5fa0add711b3bad3f1d4371b86b1129753&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[以下是DPO（Direct Preference Optimization）损失函数的PyTorch实现及其详细解析：1. DPO损失函数原理DPO通过隐式奖励对比优化模型偏好，避免传统RLHF的复]]></description><author>AI大模型调参指北笔记</author><pubDate>Wed, 09 Jul 2025 21:34:00 +0800</pubDate></item><item><title>Conditional Flow Matching : 常微分方程ODE、欧拉方法和Neural ODE</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495775&amp;idx=1&amp;sn=6839adba9e164eaae3d5f876641805eb&amp;chksm=c0d67b4a3210f0b7b937092cdcd41a7b71f526b10d0a1ec3105ddd5c580b9abc927bc834e41e&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[核心目标文章是Conditional Flow Matching (CFM) 系列的开篇，旨在为理解CFM（一种新兴生成模型）奠定数学基础。重点介绍三个核心概念：常微分方程（ODE）、数值解法（欧拉]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 08 Jul 2025 21:49:42 +0800</pubDate></item><item><title>当 Normalizing flow 遇上语音生成：AI 说话变 “真人” 的秘密在这里！</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495734&amp;idx=1&amp;sn=d36a272c36a3a3b1749bc9be94b914b2&amp;chksm=c0feb268f6f7cda14e3296bcf43165353eaa11d74aae7cd430b5f882c238e042d36d9ac22c0a&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在这里插入图片描述好的，我们来梳理一下这篇文章的核心内容：Normalizing Flow 的基本原理及其在语音生成（特别是 WaveGlow 和 VITS）中的应用。文章主旨：解释 Normali]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 07 Jul 2025 21:58:04 +0800</pubDate></item><item><title>深度剖析：Kimi - Audio 中 BigVGAN 的神奇作用</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495727&amp;idx=1&amp;sn=5dee8fbb10674dab3ed7c300f5d3de47&amp;chksm=c0ded096456458a6d92e6d2a2a49e9e328c2e7a69b7e0d259b4951b242b4d9792198010fbb9b&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[ABSTRACT尽管基于生成对抗网络（GAN）的语音编码器在近期取得了进展，即模型能够根据声学特征生成原始波形，但要为来自各种录音环境的众多说话者合成高质量的音频却颇具挑战性。在本研究中，我们提出了]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 03 Jul 2025 21:30:27 +0800</pubDate></item><item><title>MiniMax-Speech，零样本语音合成新突破，32 种语言轻松拿捏！</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495629&amp;idx=1&amp;sn=1b8bbd49ca704a9d2fd6434274c34118&amp;chksm=c0d9f888755ae37c7f91ddfccd2c6d0cfa4ed807913e071fa86306adf92ef5c5858d3c5f56b0&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[我们推出了 MiniMax-Speech，这是一款基于自回归 Transformer 的文本转语音（TTS）模型，能够生成高质量的语音。其关键创新在于我们可学习的说话人编码器，它可以从参考音频中提取]]></description><author>AI大模型调参指北笔记</author><pubDate>Fri, 27 Jun 2025 21:00:00 +0800</pubDate></item><item><title>SFT 中指令选择和响应选择哪个更重要？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495569&amp;idx=1&amp;sn=5036007952ff07151f777ef812c6307a&amp;chksm=c059ba56acbe8d8884ed3533a8dae4c58302d629e696c93a13da6fec4a130808aa2a8f5f8521&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Think好的，用户问的是“指令选择更重要还是响应选择更重要”，我需要先回顾之前的对话和论文内容。用户之前让我精读了GRAPE这篇论文，其中主要关注响应选择，通过选择与目标模型预训练分布匹配的响应来]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 19 Jun 2025 21:34:00 +0800</pubDate></item><item><title>角色扮演大模型技术分享2-超拟人模型的困境</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495533&amp;idx=1&amp;sn=d196c1a8c86a69e15301e0a74d1608ac&amp;chksm=c05f3f3040accd3943cb9f442342d7414aa2f53981d3f191fe88771049c5e2f26902302baeb9&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[时隔半年，最近的迷茫反而越来越多了。先碎碎念，有时间写干货。这次干货预计会更多，多到爆炸。本人太懒码字太累，因此可能会少次多量分几篇发出来，目前计划包括但不限于数据合成全流程分享篇、拟人化能力提升篇]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 17 Jun 2025 21:03:18 +0800</pubDate></item><item><title>如何低成本生成高质量指令微调数据？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495462&amp;idx=1&amp;sn=faa1c5fdc7578b76355df344db92e3c3&amp;chksm=c08d95361131164e8b28653d95c973cfca579c0de9e75b9e6d3df495d6e22e1dd79ad0bcd1ec&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[ABSTRACT高质量的指令数据对于对齐大型语言模型（LLM）至关重要。尽管一些模型（如 Llama-3-Instruct）的权重是公开的，但其对齐数据仍处于私有状态，这阻碍了人工智能的民主化。高昂]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 12 Jun 2025 22:05:33 +0800</pubDate></item><item><title>从数量到质量：通过自引导数据选择来提升语言模型性能以实现指令调优</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495460&amp;idx=1&amp;sn=a7203103aa3f18c8c887f90ac9a60beb&amp;chksm=c084c338d44471cbd9548df6cf9c0d1ee687a0f81b2ff623c76d8fd3d35ced9586baec28d9f4&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Abstract在大型语言模型（LLMs）的领域中，指令数据的质量与数量之间的平衡是一个关键问题。鉴于此，我们提出了一种针对 LLM 的 self-guided 方法，使其能够自主地从开源数据集中识别]]></description><author>AI大模型调参指北笔记</author><pubDate>Wed, 11 Jun 2025 21:35:02 +0800</pubDate></item><item><title>Kimi-Audio：开源音频基础模型全面解析</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495459&amp;idx=1&amp;sn=39c21633d5d74bd0df02095a0db53d8c&amp;chksm=c0fbfea15ba9393dffaaa54406c1c931c058c8e7170264a745bd73ef85ce8df436cd7a07220a&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Abstract我们推出了 Kimi-Audio，这是一款开源的音频基础模型，擅长音频理解、生成和对话。我们详细介绍了构建 Kimi-Audio 的方法，包括模型架构、数据整理、训练方案、推理部署和]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 10 Jun 2025 21:24:59 +0800</pubDate></item><item><title>Kimi-Audio 的 TTS 效果如何？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495458&amp;idx=1&amp;sn=8de838556bdff52ed38b208a66866dfa&amp;chksm=c0f2a53d2e81fefe94db3c4a12083deb16476d361b8d2874b5b5031e086f66b314820a804bbd&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Kimi-Audio开放了模型和推理脚本，但不支持TTS推理。魔改了模型可以支持TTS的任务，能同时输出文本和音频。测试发现：1. audio的输出和text的输出有时会不同步，即内容不一致。一般音]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 09 Jun 2025 21:07:45 +0800</pubDate></item><item><title>RLHF及其变体：进展和实际工程见解</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495431&amp;idx=1&amp;sn=c532762f139969093f6d764144f3f7aa&amp;chksm=c014fc019cabb700ad86c0e10602ff182b791c4056332ed8618321994c97c2f112ba4c4d9df5&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Background2022年底，OpenAI关于InstructGPT的论文b[1]引发了人们对人类反馈强化学习（RLHF）的广泛兴趣，现在通常被称为后训练。核心概念包括使用配对偏好数据集结合ra]]></description><author>AI大模型调参指北笔记</author><pubDate>Fri, 06 Jun 2025 21:00:00 +0800</pubDate></item><item><title>晦涩难懂的 Flow matching！图形化理解</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495430&amp;idx=1&amp;sn=3ba64612a5b00ec697c3efdd35f95e4b&amp;chksm=c0b7d7ff0bc7036d0c8b1582fa9b8817b4e55896e6ea0745fe8cc0ec8763f340c3edc3b818c0&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[每个生成模型理想情况下都是一个密度估计器；因此，它会建模一个概率密度，最终是一个联合概率分布（JPD），具有两个预期特性，即采样和压缩。压缩基本上是将数据推送到信息空间，这看起来维度更低，而采样则是]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 05 Jun 2025 21:00:00 +0800</pubDate></item><item><title>校园篇-北京信息科技大学2025</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495409&amp;idx=1&amp;sn=158cd0718ecdb9a47ab6a2b1ea7ce589&amp;chksm=c06dee9c1721b61d1bb042b11ee88acc8b2b0ae8d49024a0b5af9f430ed65358962762adc90d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[北京信息科技大学，北京市重点支持建设的高校，原名北京信息工程学院，隶属于电子工业部，1997年合并成立新的北京信息工程学院，2008年改现名，有沙河、小营、金台路和酒仙桥四个校区，占地81万余平方米，]]></description><author>AI大模型调参指北笔记</author><pubDate>Sat, 31 May 2025 10:00:00 +0800</pubDate></item><item><title>Simhash-文档去重算法简介</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495406&amp;idx=1&amp;sn=f71d4554ddc53ac9bf990e26c857ba3e&amp;chksm=c030ee562d6b60f701a88974af2abd527658b8e4055e5953a79b366438b057ccc771ca954445&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在计算机科学领域，SimHash 是一种用于快速估算两个集合相似度的技术。谷歌利用该算法来查找近乎重复的网页（Detecting Near-Duplicates for Web Crawling）。]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 29 May 2025 21:30:51 +0800</pubDate></item><item><title>Address Sanitizer in C++</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495405&amp;idx=1&amp;sn=32f167aafcc1c058ea27d5113e08f9d9&amp;chksm=c0f78ec2e15ea8aa68f544ecfbe51e34081ed7db65f79db2d13bb6c942dc9fea1a24199240cb&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[AddressSanitizer (ASan)是一种调试工具，用于检测c++程序中的内存错误。它的工作原理是在程序编译的二进制代码中插入特殊的工具，这允许它监视内存访问，并检测程序何时试图访问无效或已]]></description><author>AI大模型调参指北笔记</author><pubDate>Wed, 28 May 2025 21:02:38 +0800</pubDate></item><item><title>Telling gcc directly to link a library statically</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495394&amp;idx=1&amp;sn=8e42fdea76e461a842ac2fec62ea11ee&amp;chksm=c0108db7e4796d737f92d175381204c571fca5cab515b052052cfbef7a9c10b637ae837cc58c&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[It feels strange to me to use -Wl,-Bstatic in order to tell gcc which libraries I want to link with]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 27 May 2025 21:15:00 +0800</pubDate></item><item><title>亲测有效！如何用 Address Sanitizer 精准定位内存漏洞？附保姆级操作指南</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495393&amp;idx=1&amp;sn=00bd794fdca72a4263f5d99fc8eee0d4&amp;chksm=c093d80db860c8de70559a0698c61596258b71bbf8b64ff162a18b15773e390e89c5104ab86b&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Address Sanitizer是谷歌开发的检测 use-after-free、内存泄漏等内存访问错误的工具。它内置在GCC版本>= 4.8中，可以在C和c++代码中使用。Address Sanit]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 26 May 2025 22:04:48 +0800</pubDate></item><item><title>教娃编程系列｜RPG 游戏 – 移动动画</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495388&amp;idx=1&amp;sn=5655297df6ae70e04a7f48bcb94d786d&amp;chksm=c0689391a3f8481642aa13d1b8cf06a503e425615b5c5ebde0e2a88cdae29922943e9c045e7d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[为了完成玩家精灵的移动机制，我们还剩下一个功能叫做动画。如果你有视频和动画的经验，你会知道视频是通过运行许多静止的图像来创建一个移动的效果。这里我们在做同样的事情。我们有近10个Player在移动时的]]></description><author>AI大模型调参指北笔记</author><pubDate>Sat, 24 May 2025 10:00:00 +0800</pubDate></item><item><title>要用 AI 裁员 50% 的千亿独角兽，公开认错，重启招聘！</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495376&amp;idx=1&amp;sn=681500baa4c9761e0be28175c87dc40d&amp;chksm=c06c851951f0cb3214e2b18ed19e5d266cbe2c34369fc65927adbfca360610f67a9e7e87ad9e&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[估值超过1000 亿元，正在筹备美股上市的独角兽公司 Klarna，其 CEO 最近公开承认：公司在过去几年采用的以 AI 为中心的战略，是错误的！图片来源：Klarna从 2023 年开始，Klar]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 22 May 2025 21:00:00 +0800</pubDate></item><item><title>一些文档去重算法</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495346&amp;idx=1&amp;sn=a440b500fe8167b4d5ac0156a6b37ef3&amp;chksm=c0eb8bd230df21bbf20e5921400a2842097ca94de34ba2f9b26a2ce40cc2688784655c948ab2&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在讨论 SimHash 之前，让我们先回顾一下其他一些也能识别重复内容的方法。Longest Common Subsequence(LCS)这就是diff命令所使用的算法。它也是一种编辑距离，仅包含]]></description><author>AI大模型调参指北笔记</author><pubDate>Wed, 21 May 2025 21:00:00 +0800</pubDate></item><item><title>single codebook和dual codebook在LLM中向量量化上有什么区别？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495332&amp;idx=1&amp;sn=b644ea419e336509f8cad65222a2b8df&amp;chksm=c05829104fe1a5e4947c763c2885c604c4e2101be50fa106582253d990be21a424f8d150fbdb&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[think嗯，我现在得弄清楚single codebook和dual codebook在大型语言模型（LLM）的向量量化方面有什么区别。首先，我需要回顾一下向量量化的基本概念，然后再看看这两种不同的]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 19 May 2025 21:00:00 +0800</pubDate></item><item><title>富贵迷人眼</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495331&amp;idx=1&amp;sn=421e3412ff286d26807a9f036cc927c6&amp;chksm=c0cfced5dcd1dc5c49826433a6ced2444f82809ff7a4f8bfca589f9eb46a6a87b84c5f35b9f9&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>AI大模型调参指北笔记</author><pubDate>Sun, 18 May 2025 11:24:31 +0800</pubDate></item><item><title>阳光明媚吗，刘桑？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495324&amp;idx=1&amp;sn=c70d817b42f19ef7b05fb7cee299b118&amp;chksm=c074686acc648a12d265ada9e015feb6f60295f1b670226d73b7e5ff097b9ca5c6d13ae1e711&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>AI大模型调参指北笔记</author><pubDate>Sat, 17 May 2025 11:28:34 +0800</pubDate></item><item><title>什么是置信度？置信度模型怎么做？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495302&amp;idx=1&amp;sn=3ce385f2f14e084403be3bcf4b194493&amp;chksm=c00f542bcefdb9991ea767b086de62da9a7fe994858642c1617ecbb161b3ccb3dd991b90c9e5&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Abstract在本文中，我们描述了用于从医学对话中提取临床相关信息的新组件，这些组件将作为Google API提供。我们描述了一个基于transformer的 Recurrent Neural Ne]]></description><author>AI大模型调参指北笔记</author><pubDate>Fri, 16 May 2025 21:00:00 +0800</pubDate></item><item><title>0:6横扫阵风！中国歼10CE外销封神，福建舰的“六代机”要逆天？​​</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495301&amp;idx=1&amp;sn=670755875616831b88264f604704aaed&amp;chksm=c081d7feed15dd1db5258981a190ddc565e54b0a77998dec7a3b65e1950b71c0413ea39f6c53&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 15 May 2025 10:00:00 +0800</pubDate></item><item><title>红黑树是啥？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495287&amp;idx=1&amp;sn=15842263244cd088b657d4a555e73756&amp;chksm=c0b797696bda1a5597a0098b6c43aa177232e9487ffe8aece50d7748f22590d0be4e403434f9&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[二叉搜索树是一种基本的数据结构，但如果树变得不平衡，它们的性能就会受到影响。红黑树是一种平衡的二叉搜索树，它使用一组规则来保持平衡，确保插入、删除和搜索等操作的对数时间复杂度，而不管树的初始形状如何。]]></description><author>AI大模型调参指北笔记</author><pubDate>Wed, 14 May 2025 20:59:51 +0800</pubDate></item><item><title>FSQ的原理与VQ-VAE的区别和联系</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495286&amp;idx=1&amp;sn=78e36fb259c0e2c3e5cacae572751040&amp;chksm=c09b88c03534b13116110838972febef83689d9865498354a376d6128f1ad8c4c6311e509c9e&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[论文的标题是《Finite Scalar Quantization: VQ-VAE Made Simple》，顾名思义，这是一篇旨在用FSQ（Finite Scalar Quantization）简化]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 13 May 2025 21:00:00 +0800</pubDate></item><item><title>多进程中的 fork 与 spawn：为什么你的 GPU 加速会踩坑？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495285&amp;idx=1&amp;sn=f76795b0d66944cac71b9813d7d4930c&amp;chksm=c09c49cd9dab6bbf75a719eb6e49f0399c934561a06c28d6f50c669f4fe11bac6a6dd8747074&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在 Python 的 multiprocessing 模块中，隐藏着一个影响深度学习框架性能的关键选择——进程创建方式。让我们通过一个真实的 CUDA 初始化报错案例，深入理解 fork 与 spa]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 12 May 2025 21:17:00 +0800</pubDate></item><item><title>教娃编程系列｜RPG 游戏 – 重力与跳跃</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495263&amp;idx=1&amp;sn=07bd6d9997758eed48099dd2adda03f3&amp;chksm=c0d4d74a5c51487cc9c44a1108ada93cf305ba6c2bcb5589a2e10ca7955a04c4eaabe24e846f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[由于我们在上一个教程中的努力，我们的玩家角色现在可以移动了。然而，游戏缺乏重力以及与地面本身的交互性。目前，我们的Player只是漂浮在空中，这当然是不可接受的。你可以制作一个临时的解决方案，使用地面]]></description><author>AI大模型调参指北笔记</author><pubDate>Fri, 09 May 2025 22:02:12 +0800</pubDate></item><item><title>大模型并行训练的一些知识——极简版</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495259&amp;idx=1&amp;sn=8b84b4928ae825917a034cdb264f1542&amp;chksm=c0c25964a2b9eb041566e17aee6d752ff4ae4fa1b40fd9c2736d518e2ce397a1548b93f3cee3&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Tensor ParallelismTensor parallelism is a technique used to fit a large model in multiple GPUs. For]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 08 May 2025 21:13:56 +0800</pubDate></item><item><title>GPTQ：生成式预训练Transformer的精确训练后量化</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495235&amp;idx=1&amp;sn=aeaa963e0081e08a9d4c00a51fe52d11&amp;chksm=c0e11374f08a98d3bb78280950072be2965d3fe7359371e430514089f7d64b86d8c65988b53f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[生成式预训练的Transformer模型，称为GPT或OPT，通过在复杂语言建模任务中的突破性性能，以及极高的计算和存储成本，使自己脱颖而出。具体来说，由于其庞大的尺寸，即使是对大型，高精度GPT模]]></description><author>AI大模型调参指北笔记</author><pubDate>Wed, 07 May 2025 21:17:00 +0800</pubDate></item><item><title>胖东来与京东联手了</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495234&amp;idx=1&amp;sn=437199be1f34c8193fa938042a2028a9&amp;chksm=c062f895e24edf5c0c74b637467d365cebaf771d88042a436a5f048f6c8e8c83034114c02806&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 06 May 2025 22:55:18 +0800</pubDate></item><item><title>教娃编程系列｜RPG 游戏 – Player Movement</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495210&amp;idx=1&amp;sn=e3e73a9d9d0ca26f678fd44e3d522565&amp;chksm=c05141726ec93e461ce708f89ec3650463c06d5b4878532aef6b6cc8c59cd7611ebb54bb850e&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Introduction这个Pygame RPG教程和下一个教程都专注于执行移动和物理，允许我们的玩家可以移动，跳跃并与他所站的地面互动的完整系统。本教程的全部内容都是基于我们需要在Player类中创]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 05 May 2025 21:40:26 +0800</pubDate></item><item><title>这儿没人</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495209&amp;idx=1&amp;sn=ce19c4d463462497b5572790dd6eaf1e&amp;chksm=c059e524f5bd773076ecbc1395c5be242e2b56c46d5caae0c28918e5358e8d885a72618e6ebd&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[]]></description><author>AI大模型调参指北笔记</author><pubDate>Sun, 04 May 2025 09:17:00 +0800</pubDate></item><item><title>教娃编程系列｜PRG - The Player Class</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495202&amp;idx=1&amp;sn=7364d9676403e4fa1a625661e0a06fa1&amp;chksm=c0f41a7e5cbd6457f4fe5ddfd870e9ff5f21665a265909a80a8d1a4ef0355c7f6bb49b4b3c64&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[这个RPG教程中最重要的类是Player类。这个类负责几乎所有与玩家相关的事情，包括移动、攻击、碰撞检测、渲染、状态跟踪等等。由于它的总大小和许多概念，我们将在教程系列的其余部分慢慢构建Player类]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 01 May 2025 21:00:00 +0800</pubDate></item><item><title>LLM 中 tool 和 RAG 怎么融入到对话数据中？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495189&amp;idx=1&amp;sn=a187b4ae55578bf612bc0e3a64f10b53&amp;chksm=c0cfce47c52d8ee51a8c9184a355da5a1e2a0d9201ed31a6355b5b6959d2562f7c3e76cdb10d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在这里插入图片描述整理开源数据的时候，看到一种融入检索 tool 或 RAG 的方式，看着挺简单的，可以供参考：{        "role":"user",    "content":"电脑屏幕被]]></description><author>AI大模型调参指北笔记</author><pubDate>Wed, 30 Apr 2025 21:00:00 +0800</pubDate></item><item><title>Qwen3 在五一节前发布了！</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495188&amp;idx=1&amp;sn=5171c37428afef3f09a3596be13d95d0&amp;chksm=c0c3e57fd12201e981093dbba336e54b5ef5209933084f2467dcf4e57478a68a7ec07febae3f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[今天，阿里宣布推出 Qwen3，这是 Qwen 系列大型语言模型的最新成员。我们的旗舰模型 Qwen3-235B-A22B 在代码、数学、通用能力等基准测试中，与 DeepSeek-R1、o1、o3]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 29 Apr 2025 08:50:58 +0800</pubDate></item><item><title>RLHF 入门，高手勿进！</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495148&amp;idx=1&amp;sn=d52836a0ea408566c0a5814fca818ae6&amp;chksm=c04ab58690db2d7c8befd14bd39514b1f970c7c0ea3a37b34085d7c59d0160158909a3a04348&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[LLM Training: RLHF and Its Alternatives在讨论语言模型（LLM）时，无论是研究新闻还是教程中，我都会频繁提及一种被称为“带有人类反馈的强化学习”（RLHF）的过]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 28 Apr 2025 21:08:55 +0800</pubDate></item><item><title>最佳的指令数据应当是什么样的？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495112&amp;idx=1&amp;sn=59450f85e736ec523d1a38f72fef291b&amp;chksm=c0716a7f895940c6012c750bfe8e8f86c481203037220449a662df1429bcf7a998f21143d719&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Abstract高质量的监督微调（SFT）数据对于激发预训练大型语言模型（LLM）的强大能力至关重要。通常情况下，指令会与从其他 LLM 中采样的多个响应配对，而这些响应往往偏离了要微调的目标模型的]]></description><author>AI大模型调参指北笔记</author><pubDate>Sun, 27 Apr 2025 21:00:00 +0800</pubDate></item><item><title>Pygame RPG Tutorial 2 – Building the World</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495107&amp;idx=1&amp;sn=d45834814b0d9f8a8acc0ca1aa2fb6e7&amp;chksm=c0a15f29cc44d8f11205b9afdf7141b05fd51b695700cba8bc361ab5ab0a3c2da416a1d52a31&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[背景和视觉效果是任何游戏不可或缺的组成部分，无论其大小和类型如何。游戏世界的互动性和动态性越强越好。在本教程中我们不会深入讨论，但将在本系列后面讨论如何更改视觉效果。Creating the Back]]></description><author>AI大模型调参指北笔记</author><pubDate>Fri, 25 Apr 2025 21:00:00 +0800</pubDate></item><item><title>Qwen 的训练数据是怎么做的？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495106&amp;idx=1&amp;sn=6753874c966856721e157f85c2554fa8&amp;chksm=c07eb5bb41fccd74ab2b87f8ab96664e815eb7c2a9ca8e2d30c1d4741eebfddf871eb520848d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[QwenPRE-TRAINING DATA数据量大小已被证明是开发强大大型语言模型的关键因素，这一点在之前的研究中中得到了强调。为了创建一个有效的预训练数据集，确保数据的多样性并涵盖各种类型、领域和]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 24 Apr 2025 21:00:00 +0800</pubDate></item><item><title>用 bitsandbytes、4 比特量化和 QLoRA 打造亲民的 LLM</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495082&amp;idx=1&amp;sn=0e7cf13944163e90b2634cd3a5fc8742&amp;chksm=c02b01c8555a623c60fdb73c222c79f7b443909d3e679abf56c00beba49b7e7e26bf51412664&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[众所周知，LLM 规模庞大，如果在也能消费类硬件中运行或训练它们将是其亲民化的巨大进步。我们之前撰写的 LLM.int8 博文 展示了我们是如何将 LLM.int8 论文 中的技术通过 bitsan]]></description><author>AI大模型调参指北笔记</author><pubDate>Wed, 23 Apr 2025 21:00:00 +0800</pubDate></item><item><title>Prefill-Decode分离</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495078&amp;idx=1&amp;sn=72447115c6a25472396a20c0241e2582&amp;chksm=c0247c9fa37125930c90d2888f3e0a06ad10f2640ecd55c2bf8ce3cd5dd14b9e50220fc714b4&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在这里插入图片描述在这里插入图片描述在这里插入图片描述在这里插入图片描述在这里插入图片描述A request going through an LLM serving engine with dis]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 22 Apr 2025 21:00:00 +0800</pubDate></item><item><title>我们如何为 DeepSeek-R1 对 vLLM 进行优化</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495077&amp;idx=1&amp;sn=10c41611ffe6ca8a48f45fbddd200227&amp;chksm=c055597c3333f66611f2ad09ce3af95238228c5c9bdd65e096e22c4eec93eb8afcea86733dd9&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[DeepSeek 和 vLLM 的优化一直是我们的团队以及整个 vLLM 社区的首要任务，我们很高兴能深入分享我们的工作成果。在本文中，我们将介绍我们所取得的关键推理改进，详细说明 DeepSeek]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 21 Apr 2025 21:00:00 +0800</pubDate></item><item><title>MCP（模型上下文协议）是什么以及它是如何运作的</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495076&amp;idx=1&amp;sn=569df32aa839ee164ce234afd2017dae&amp;chksm=c0497ca9de58ff16127d5e9d275aa4a79f9febc6cc2940c241f3b49500c2ce1bc8e7af4e3468&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[What is MCP?MCP（模型上下文协议）是一种开放、通用的协议，它规范了应用程序如何向大型语言模型（LLM）提供上下文信息。简单来说，正如 HTTP 协议允许不同的网站和浏览器按照相同的规则交]]></description><author>AI大模型调参指北笔记</author><pubDate>Sun, 20 Apr 2025 10:00:00 +0800</pubDate></item><item><title>Model Context Protocol (MCP)</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495060&amp;idx=1&amp;sn=732153e54be140d39f5c8e66707c1bd1&amp;chksm=c04f65d70fc355a1b4db82eb5e96d3352a9e53227c3306d42d1a526bf80bc522108ddb2cfb43&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[虽然模型上下文协议（MCP）目前主要是在工具集成方面进行讨论，但其上下文管理能力却是该协议中同样重要（甚至可能是更为基础）的一个方面。在 MCP 中的上下文管理解决了几个关键问题：•上下文窗口的限制方]]></description><author>AI大模型调参指北笔记</author><pubDate>Sat, 19 Apr 2025 12:20:44 +0800</pubDate></item><item><title>CosyVoice 2：基于大型语言模型的可扩展流式语音合成技术</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495047&amp;idx=1&amp;sn=d1d3ce65334471b66e8488d9c134a2fe&amp;chksm=c09c41e5b8ea2d3e44fc70be227abecdb605a1bb25c3ca67e2de2c9bf9d96066b826741a5825&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Abstract在我们之前的工作中，我们推出了 CosyVoice 这一多语言语音合成模型，其基于有监督的离散语音标记。通过采用带有两种流行生成模型（语言模型（LMs）和流匹配）的渐进式语义解码技术]]></description><author>AI大模型调参指北笔记</author><pubDate>Thu, 17 Apr 2025 22:00:00 +0800</pubDate></item><item><title>CosyVoice：一种基于监督式语义标记的可扩展多语言 Zero-Shot 语音合成器</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495046&amp;idx=1&amp;sn=a6e132b59800fc23de142c9c83174623&amp;chksm=c04709d9d6fc827c3327fd329ef74a9b85d471ca2f3ffb7d7e319829da63157097db752f2206&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Abstract近年来，基于大型语言模型（LLM）的文本转语音（TTS）技术呈现出一种主流化的趋势，这是因为其具有高度自然性和zero-shot能力。在这种模式下，语音信号被离散化为标记序列，这些序]]></description><author>AI大模型调参指北笔记</author><pubDate>Wed, 16 Apr 2025 22:00:00 +0800</pubDate></item><item><title>LLM中的RAG检索内容，是如何应用的呢？需要在SFT阶段加入到answer中训练吗？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495044&amp;idx=1&amp;sn=62687c61c8572db7bd83db049b762f97&amp;chksm=c045164147ce064c516d2af90f912ff31cf1523e773cf0b2d8d4ebdaf5236dad5ad12cb572d1&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[LLM中的RAG检索内容，是如何应用的呢？需要在SFT阶段加入到answer中训练吗？Think嗯，用户问的是RAG在LLM中的应用，特别是是否需要将检索的内容在SFT阶段加入回答中进行训练。我需要]]></description><author>AI大模型调参指北笔记</author><pubDate>Tue, 15 Apr 2025 22:00:00 +0800</pubDate></item><item><title>使用 Transformers， Accelerate和bitsandbytes 进行8-bit矩阵乘法</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495043&amp;idx=1&amp;sn=7e26199bb55208b72600fd261a933e35&amp;chksm=c08b09815f74683e3eff2b854c4bfdff6fbd45ec3af9b4898859c2290fb94628590b173eb365&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Introduction语言模型一直在变得越来越大。在撰写本文时，PaLM有540B个参数，OPT、GPT-3和BLOOM有大约176B个参数，我们正在趋向于更大的模型。下图显示了一些最新语言模型的]]></description><author>AI大模型调参指北笔记</author><pubDate>Mon, 14 Apr 2025 22:00:00 +0800</pubDate></item><item><title>Pygame RPG Tutorial 1 – Building the Base</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495015&amp;idx=1&amp;sn=b58e1f6c7cbbc2593321a35e204be02b&amp;chksm=c069a30648341f17d4541357fdb34b36c82b2659d4fb440ac587d8c877b9cc57429e0ccee894&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Introduction这是我们Pygame RPG系列的第一个教程。在本教程中，我们将专注于为Pygame RPG构建整体“base”或“frame”。我们将首先解释我们将创造何种类型的RPG。解释]]></description><author>指北笔记</author><pubDate>Sun, 13 Apr 2025 10:00:00 +0800</pubDate></item><item><title>Pygame RPG Fighter – Game Tutorial</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495014&amp;idx=1&amp;sn=bfac4be4d406b2d57393710c47aa7a1b&amp;chksm=c032de0e6cb3d0f42a52ce4fe218b4464fae861940900d2b4729c93b076a78aed17617761e37&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[欢迎来到Pygame RPG教程系列。在这里，我们将解释如何使用Python中的Pygame库创建RPG战斗机风格的游戏。本教程系列的目的并不是提供给你一款带有故事，角色和渐进玩法系统的完整RPG游戏]]></description><author>指北笔记</author><pubDate>Sat, 12 Apr 2025 22:50:41 +0800</pubDate></item><item><title>压力测试LLMs——大海捞针实现</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247495013&amp;idx=1&amp;sn=1f7dbf9b2a2d8c4e959509d7539bef34&amp;chksm=c0a33cdda4eaf34a9b468f3827c2da5fa1f122d135ab2d16a1df54367df50302f5470415a22d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Needle In A Haystack - Pressure Testing LLMs一个简单的“大海捞针”分析来测试长上下文llm的上下文检索能力。在这里插入图片描述The Test1. Pla]]></description><author>指北笔记</author><pubDate>Fri, 11 Apr 2025 22:00:00 +0800</pubDate></item><item><title>REINFORCE++: 一种简单而有效的方法来对齐大型语言模型</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494925&amp;idx=1&amp;sn=bb069a396dfaaedc4ed14626f3dc7c37&amp;chksm=c0f734297bf045f53ba2a5338fa0919c46061a6aa17b210d97c65006c6cb1557d0469fb3ba79&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[REINFORCE++: A Simple and Efficient Approach for Aligning Large Language ModelsAbstract基于人类反馈的强化学习（]]></description><author>指北笔记</author><pubDate>Wed, 09 Apr 2025 22:00:00 +0800</pubDate></item><item><title>基于规则的强化学习释放LLM推理</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494821&amp;idx=1&amp;sn=d01e2a439626f787e808e07d8371f46d&amp;chksm=c069524f612107eb6ddbeaaff12452d2ac83ef3cdb63d5bf8444bd5e2cd447c1da9c71f0e113&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Abstract受DeepSeek-R1成功的启发，我们探索了基于规则的强化学习（RL）在大型推理模型中的潜力。为了分析推理动态，我们使用合成逻辑谜题作为训练数据，因为它们具有可控的复杂性和简单的答]]></description><author>指北笔记</author><pubDate>Mon, 07 Apr 2025 22:16:00 +0800</pubDate></item><item><title>Pygame Platformer VI – Bonus Content (Coins and Images)</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494820&amp;idx=1&amp;sn=90e6619d45b284e671077bc368d0811a&amp;chksm=c059bf57fbd0c05230df02d066688ac42da4073a8a1be26d8cc2dfd0f807a3846e9cec15aa06&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在这个Pygame平台游戏的奖励教程中，我们将主要关注在我们的游戏中添加硬币和图像。这将是我们游戏的最终结果，一旦我们完成了本教程。Player and Platform Interaction我们要]]></description><author>指北笔记</author><pubDate>Sat, 05 Apr 2025 22:00:00 +0800</pubDate></item><item><title>Pygame Platformer V – Completing the Game</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494819&amp;idx=1&amp;sn=6717cd13b84b1835a4b90f4d0a9102ac&amp;chksm=c0b3d42abf2c5ccf12c7aea18a295e25afa502db180946755f37fc370266b9412fe64397b470&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[如果你一直在关注我们的平台游戏教程系列，你就会知道我们的游戏已经接近完成了。在Pygame中，要真正完成一款成功且完整的游戏的概念，还需要添加一些小内容。我们的Pygame平台游戏需要添加哪些内容？G]]></description><author>指北笔记</author><pubDate>Fri, 04 Apr 2025 22:00:00 +0800</pubDate></item><item><title>LLM 训练 Loss Spike 优化</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494818&amp;idx=1&amp;sn=122712dbd6dfaddb6fa59c206f6802e2&amp;chksm=c0b6b63905c175f5612d51f027c5d3eadbadc121efe135ab21a337e128acf671035e1ddc0b38&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[AbstractLoss spikes 经常出现在大型语言模型的预训练过程中。The spikes 会降低大型语言模型的性能，有时还会破坏预训练。由于预训练需要大量的计算预算，我们应该避免这样的 sp]]></description><author>指北笔记</author><pubDate>Thu, 03 Apr 2025 22:00:00 +0800</pubDate></item><item><title>RAG评估：大海捞针测试</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494787&amp;idx=1&amp;sn=a1e1cb72e5bd5945b2c8a22638828241&amp;chksm=c06d17a3c813c77b2d96d0e55b34cac0fc9cefe3b774b4f97f03508638fb58afb87192866136&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[检索增强生成（RAG）是当今现实世界中许多LLM应用程序的基础，从生成头条新闻的公司到为小型企业解决问题的独立开发人员。因此，RAG评估已成为开发和部署这些系统的关键部分。一种新的创新方法是“Nee]]></description><author>指北笔记</author><pubDate>Wed, 02 Apr 2025 22:00:00 +0800</pubDate></item><item><title>Partition Algorithm</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494786&amp;idx=1&amp;sn=df0831b97ed7ff02cbfd9a6f576aa87b&amp;chksm=c007d92793d0b1c31062ea00d1311af556b8639ea138dc23aa020b259b84d91e1be332366da5&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Introduction分区算法是我最喜欢的算法之一，因为它在实践中非常有效和有用。它也是排序算法(如Quicksort 和partial sort)和线性时间最坏情况选择算法的基本构建块。在这篇博文]]></description><author>指北笔记</author><pubDate>Tue, 01 Apr 2025 22:00:00 +0800</pubDate></item><item><title>Pygame Platformer IV – Improving the game</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494756&amp;idx=1&amp;sn=011c31617af0b28535b8462a46d84849&amp;chksm=c0833eea922ed0bc1e9debdbec96c4dad66a93ff6706f301884ae56c1ca2fa86fbcd76bc321f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[本节将结合许多小主题或“改进”，所以有时事情可能看起来有点随机。下面是我们将要添加的改进列表。Fixing how the Player lands on a platformImproving th]]></description><author>指北笔记</author><pubDate>Sun, 30 Mar 2025 08:00:00 +0800</pubDate></item><item><title>Pygame Platformer III– Level Generation</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494755&amp;idx=1&amp;sn=cc89e8e1fc2f20fd60b6c7f8615a0b9d&amp;chksm=c0c267ba6720d16349a4263a6eb4f3c7d4f6a14377e5934d5518bd8ee02ae8b1896a7a75bc9e&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[关卡生成是一个很难在Pygame或任何游戏引擎中完美执行的概念。大多数人尝试通过单独定义每个关卡布局来手动创建关卡。在某些拥有一定数量地图或关卡的冒险游戏中，这是可行的，但在平台游戏中，这是非常有限的]]></description><author>指北笔记</author><pubDate>Fri, 28 Mar 2025 23:01:57 +0800</pubDate></item><item><title>vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494735&amp;idx=1&amp;sn=448f4f957fe19de69c443d033b4872d3&amp;chksm=c00955fa61868abd07b1c65d6374780c37fb31c30ff2572df9280a0f86734ace934d3febdac4&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttentionLLM承诺从根本上改变我们在所有行业使用人工智能的方式。然而，实际上为这些模型提]]></description><author>指北笔记</author><pubDate>Thu, 27 Mar 2025 22:00:00 +0800</pubDate></item><item><title>Fully Sharded Data Parallelism (FSDP)</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494734&amp;idx=1&amp;sn=ee1ecd37f4da26dad44e18d54facd4b4&amp;chksm=c0ecd623916022599712aa1112f7c8e52895883232719d6df3fe94c47758852e0a5530a09efe&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Fully Sharded Data Parallelism (FSDP)在这篇博客中，我们将探索完全分片数据并行（FSDP），这是一种允许以分布式方式高效训练大型神经网络模型的技术。我们将从鸟瞰的]]></description><author>指北笔记</author><pubDate>Wed, 26 Mar 2025 22:00:00 +0800</pubDate></item><item><title>什么是拒绝抽样？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494705&amp;idx=1&amp;sn=b5236626aab1620c09842279136d40a0&amp;chksm=c047f2a78be00b68866c5232a6291246be778552f2f69524515ea7113c543d4b5c11fd05d31f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[What is Rejection Sampling?拒绝抽样是一种蒙特卡罗算法，在代理分布的帮助下从复杂（“难以抽样”）分布中抽样数据。蒙特卡洛是什么？如果一种方法/算法使用随机数来解决问题，它被]]></description><author>指北笔记</author><pubDate>Tue, 25 Mar 2025 22:21:00 +0800</pubDate></item><item><title>TRL 关于 GRPO Trainer 的实现</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494704&amp;idx=1&amp;sn=ff3d3f518bbfbc6afcb6282fea148566&amp;chksm=c02b5176c1dc93d113f42d9831bf77c9edcb645c40187c89aa0831d005030178f296a5d449ea&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[TRL 关于 GRPO Trainer的实现OverviewTRL支持GRPO Trainer来训练语言模型，如论文 DeepSeekMath: Pushing the Limits of Math]]></description><author>指北笔记</author><pubDate>Mon, 24 Mar 2025 22:00:00 +0800</pubDate></item><item><title>Pygame Platformer II– adding Gravity and Jumping</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494703&amp;idx=1&amp;sn=aaf4e345eda61d348080615d62b11046&amp;chksm=c044d318f9cb55aa542f25a4c0c04280f031c2512a9cd03c028fac1cb79e9534a300d6b12b4a&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[欢迎来到Pygame游戏编程的第2部分。在本节中，我们将讨论两个主要主题，即赋予玩家跳跃的能力和重力的实现。Part 1 – Code下面是第1部分中的代码，我们将使用它作为本文其余部分的参考。重力和]]></description><author>指北笔记</author><pubDate>Sun, 23 Mar 2025 20:00:00 +0800</pubDate></item><item><title>Pygame Platformer I– Game Development</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494702&amp;idx=1&amp;sn=cb3c225b4e936da80fbe8940bff934b5&amp;chksm=c0288e45d51256c7243e0bb86c1ecdcf2a9a61083e976224d9acf1acf1c25cd1948ad833bc40&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[欢迎来到Pygame平台游戏开发！在本节中，我们将使用Python游戏库Pygame构建一款2D Platformer游戏。要提醒所有读者的是，本文主要针对已经对Pygame有些熟悉的读者。我们将只略]]></description><author>指北笔记</author><pubDate>Fri, 21 Mar 2025 22:00:00 +0800</pubDate></item><item><title>Step-Audio：智能语音的统一理解与生成</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494701&amp;idx=1&amp;sn=44ea0b9f7c7699072d0d93b6b99db008&amp;chksm=c010cd1f741fdd3df8a70b812b19e06e899303448022281822e050c3b010e8b10ea648f4f04d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[实时语音交互作为人机协作的基本接口，具有巨大的潜力。然而，目前的开源模型面临着语音数据采集成本高、动态控制能力弱、智能有限等局限性。为了应对这些挑战，本文介绍了Step-Audio，这是第一个生产就]]></description><author>指北笔记</author><pubDate>Thu, 20 Mar 2025 22:00:00 +0800</pubDate></item><item><title>FLOW-MATCHING TTS的时变情绪状态控制</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494683&amp;idx=1&amp;sn=ed23949ccb6d153752d4357f20035f42&amp;chksm=c03733d36a98d595069557a99864369af58a51bb763ba3ca742c9ee86d5ccd1dc3d8373bd8c1&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[ABSTRACT人们改变声调，通常伴随着非语言发声（NVs, nonverbal vocalizations），如笑和哭，以传达丰富的情感。然而，大多数文本到语音（TTS）系统缺乏生成具有丰富情感的语]]></description><author>指北笔记</author><pubDate>Wed, 19 Mar 2025 22:00:00 +0800</pubDate></item><item><title>AutoModelForCausalLMWithValueHead是什么？</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494682&amp;idx=1&amp;sn=7c816a92a5862215cb8c5060fd5d62a3&amp;chksm=c083b2a9c71074ca0151ec36af1660cd8f1faa976d44409c5dffdf443cbcffef00c0cd121617&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Mainly, PPO optimization (a RLHF technique) relies on computing “advantages” associated with taking]]></description><author>指北笔记</author><pubDate>Tue, 18 Mar 2025 22:00:00 +0800</pubDate></item><item><title>Emo-DPO: 基于直接偏好优化的可控情绪语音合成</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494675&amp;idx=1&amp;sn=bccf8ba41853d25cb877d5eedf357c55&amp;chksm=c0f528257562a0f3a0c7734984fcedcfab96b951f7e907fc6816928a002dae32f53b15a3b368&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Abstract目前的情感文本到语音（TTS）模型主要通过监督训练来学习从文本和期望的情感到其情感语音的转换，关注每个文本到语音对的单个情感。这些模型只学习正确的情绪输出，而没有完全理解其他情绪特征，]]></description><author>指北笔记</author><pubDate>Mon, 17 Mar 2025 22:00:00 +0800</pubDate></item><item><title>Efficient Infinite Context Transformers with Infini-attention</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494674&amp;idx=1&amp;sn=a8fa5d5329ab8e1bccddd01c064253af&amp;chksm=c055f53727c5e645e599fff7d4feb49149aec88acc0461120311959f0567942ecba7388bc577&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Abstract这项工作介绍了一种有效的方法，将基于transformer的大语言模型（llm）扩展到具有有限内存和计算的无限长输入。我们提出的方法的一个关键组成部分是一种新的注意力技术，称为Infi]]></description><author>指北笔记</author><pubDate>Sun, 16 Mar 2025 22:00:00 +0800</pubDate></item><item><title>SuperGPQA 评估</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494673&amp;idx=1&amp;sn=a8bc5850b3a0abbfe45940e3692e76a6&amp;chksm=c0011c4c5e0942e649bf73cbf300b22fe72784113872d482cf90c76199f1346007204c386391&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[SuperGPQA，这是一个综合基准，旨在评估285个研究生水平学科的大型语言模型（llm）的知识和推理能力。SuperGPQA每个学科至少有50个问题，涵盖了广泛的研究生水平主题，旨在成为LLM评]]></description><author>指北笔记</author><pubDate>Sat, 15 Mar 2025 22:00:00 +0800</pubDate></item><item><title>LLM评估集SuperGPQA</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494657&amp;idx=1&amp;sn=92c9276b6b05afd7f574408f15aba50f&amp;chksm=c072a45611b8a156bb58917fd27a0ef0740dfd98aaf97875f3f3cbd83900fb5ff7a263b58d4c&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Abstract大型语言模型（llm）在数学、物理和计算机科学等主流学术学科中表现出了显著的熟练程度。然而，人类的知识涵盖了200多个专业学科，远远超出了现有基准的范围。LLM在许多这些专业领域的能]]></description><author>指北笔记</author><pubDate>Fri, 14 Mar 2025 22:00:00 +0800</pubDate></item><item><title>Refine Retrieval Quality with Rerank</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494656&amp;idx=1&amp;sn=a929b0a12db8fbfc817234f5deb639fa&amp;chksm=c0051fb24e3195353236259ded958cd4191e7d0c6f89e5ce6057621211f75a866a4bb8f8b88d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在大规模构建向量搜索或检索增强生成（RAG）时，很难提高检索质量。质量的每一次提升都关系到用户体验的好坏。使用reranker可以在搜索过程中进一步细化检索到的文档，从而增加与用户查询的相关性。在大多]]></description><author>指北笔记</author><pubDate>Thu, 13 Mar 2025 22:00:00 +0800</pubDate></item><item><title>Metrics-Driven Agent Development</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494628&amp;idx=1&amp;sn=4213d1ffb2c0700a9ad7984f64365018&amp;chksm=c0b1d273d4cb4445034e6f075ef9977df6f769b0fcbdb3be816cf408deb1f0d649989697b638&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Retrieval Augmented Generation Assessment（RAGAS）是一个用于量化agent和RAG管道性能的评估框架。通过将评估添加到我们的工作流中，我们可以更可靠地迭代]]></description><author>指北笔记</author><pubDate>Wed, 12 Mar 2025 22:46:00 +0800</pubDate></item><item><title>Rerankers and Two-Stage Retrieval</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494608&amp;idx=1&amp;sn=a4f2e81aaf3388225a35deb58683a8b0&amp;chksm=c0f0491305ccd439ebe9f22d48e2a42b866238061a88379402775cf89c146f0ba72a1c698a4f&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Retrieval Augmented Generation（RAG）是一个重载术语。它向世界承诺，但在开发了RAG管道之后，我们中的许多人都想知道为什么它没有像我们预期的那样工作。与大多数工具一样，]]></description><author>指北笔记</author><pubDate>Tue, 11 Mar 2025 22:00:00 +0800</pubDate></item><item><title>Choosing an Embedding Model</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494607&amp;idx=1&amp;sn=437b235987a2820c608d4cdd2814ee84&amp;chksm=c02c6a8b0f1c7deeb57d7b6bbd2bd5a68aeccd56b360da8db0c715eaffaf48493ef58542c59e&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[我们大多数人都在使用OpenAI的Ada 002进行文本嵌入。原因是OpenAl建立了一个很好的嵌入模型，它比其他任何人都更容易使用。然而，这是很久以前的事了。看看MTEB排行榜，我们就会发现Ada并]]></description><author>指北笔记</author><pubDate>Mon, 10 Mar 2025 22:00:00 +0800</pubDate></item><item><title>RAG 中的 web retrieval 与 DeepSeek-R1 RAG Prompt</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494606&amp;idx=1&amp;sn=3924023cceb8c244b6f05ce5b1afaa5f&amp;chksm=c08740acd1067f815edd86f882ff9e1b96a2f42e03b6628052a8fc147f149349a1387b068a05&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[RAG 中的 web retrieval 与 DeepSeek-R1 RAG Promptenvspip install validators==0.34.0pip install pydantic]]></description><author>指北笔记</author><pubDate>Sun, 09 Mar 2025 11:50:07 +0800</pubDate></item><item><title>DeepSeek-R1关于RL中Environment Functions 的理解</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494605&amp;idx=1&amp;sn=7c9385a8fa3b682ac3edab60646f60ef&amp;chksm=c0b1f7addf65f53396915cd9e4da24b1a39a939ce08fda5b0e7befa2cc172698aa255fe0c24e&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[1. RL中的环境函数怎么理解？Think嗯，我现在要理解强化学习中的环境函数是怎么回事。刚开始学强化学习，可能有点懵，不过慢慢来。首先，我记得强化学习里有智能体（agent）和环境（environm]]></description><author>指北笔记</author><pubDate>Sat, 08 Mar 2025 09:00:00 +0800</pubDate></item><item><title>DeepSeek-R1 对 LLM Post-Training 的思考</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494539&amp;idx=1&amp;sn=c3f33b9bef53d298943ffdd8d9ec7ec8&amp;chksm=c0ac3ebaa61699ffce7b8f8a14235552c96aaece70d4c58d43186b49d02616cee6351644b808&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[DeepSeek-R1 对 LLM Post-Training 的思考1. 一般LLM的聊天，role-play，RAG的是功能是在SFT阶段实现的，如果放到pre-training阶段是否合适，或]]></description><author>指北笔记</author><pubDate>Fri, 07 Mar 2025 22:00:00 +0800</pubDate></item><item><title>Vanilla Policy Gradient</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494538&amp;idx=1&amp;sn=43e0a681af1b95f91eb1119804832f2f&amp;chksm=c08f57f8475adfba21f2ac09e161517a6560f12a65704aa64a82408288ac1e8e852ededa1a12&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Background策略梯度的关键思想是提高导致高回报的action的概率，降低导致低回报的action的概率，直到你达到最优策略。Quick FactsVPG is an on-policy alg]]></description><author>指北笔记</author><pubDate>Thu, 06 Mar 2025 22:00:00 +0800</pubDate></item><item><title>RL导论 - Policy Optimization</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494537&amp;idx=1&amp;sn=35c0c4b34ff0b7078ce17c174afd44d4&amp;chksm=c0acb859d649aa6c7479045d5ca0722c3822ff2184e0017c4a84fa3ca0f3549a6fbeacf474c8&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[在本节中，我们将讨论策略优化算法的数学基础，并将材料与示例代码连接起来。我们将讨论policy gradients 理论中的三个关键结果：the simplest equation describin]]></description><author>指北笔记</author><pubDate>Wed, 05 Mar 2025 22:00:00 +0800</pubDate></item><item><title>动手复现 DeepSeek-R1-Zero 顿悟时刻</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494491&amp;idx=1&amp;sn=245adbf6e3cfe83876643e30190ce339&amp;chksm=c04abbc82adec75678db3bfc4771ca0af5338267b4a700a7d1bc0a0ae727288a2acc81743696&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[动手复现 DeepSeek-R1-Zero 顿悟时刻开源复现 DeepSeek-R1-Zero 的工程在这里插入图片描述• GRPO 开源实现• trl grpo trainer：TRL 的 GRP]]></description><author>指北笔记</author><pubDate>Tue, 04 Mar 2025 22:00:00 +0800</pubDate></item><item><title>RL导论- RL算法的分类</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494490&amp;idx=1&amp;sn=8dca7bf43fc916c3c9dcd10ae8f39585&amp;chksm=c0cbdbe2e411c27698e4eff4f2586f5b5ea717f1d71cdec7f37e8fd3d04cde87979aeb73bb19&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[现在我们已经学习了强化学习术语和符号的基础知识，我们可以介绍一些更丰富的内容：现代强化学习算法的概况，以及算法设计中各种权衡的描述。A Taxonomy of RL AlgorithmsA non-e]]></description><author>指北笔记</author><pubDate>Mon, 03 Mar 2025 22:00:00 +0800</pubDate></item><item><title>transformers 的采样方式</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494429&amp;idx=1&amp;sn=38b5556fc635947b2ce8401f0d88afc2&amp;chksm=c0d863371d36fc301f01a526bfb98c8115dfa3ed377324162331efcae10bca3af8a7270a82de&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Introduction近年来，随着以 OpenAI GPT2 模型 为代表的基于数百万网页数据训练的大型 Transformer 语言模型的兴起，开放域语言生成领域吸引了越来越多的关注。开放域中的条]]></description><author>指北笔记</author><pubDate>Fri, 28 Feb 2025 22:18:11 +0800</pubDate></item><item><title>RL导论- RL中的关键概念</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494421&amp;idx=1&amp;sn=0cd9c2060996282f402d8e844a809cb5&amp;chksm=c0a3250f1569cb78482e83f53725bf650249cb765c5a681451fff1934264556e81f18ef46634&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Introduction to RL - Key Concepts in RL欢迎来到我们的强化学习简介！在这里，我们想让你了解• the language and notation used to]]></description><author>指北笔记</author><pubDate>Thu, 27 Feb 2025 22:00:00 +0800</pubDate></item><item><title>LLM 强化学习对齐综述 下篇</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494409&amp;idx=1&amp;sn=d0214faaf52f6238f28176812827119d&amp;chksm=c03349ea4225f462559a4320924a1e94436149e824e54968d5792ff1b0b3d7f598fc665141c0&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Direct Human Preference Optimization传统的RLHF方法通常涉及优化基于人类偏好的Reward function。虽然这种方法是有效的，但它可能会带来一些挑战，比如]]></description><author>指北笔记</author><pubDate>Wed, 26 Feb 2025 22:00:00 +0800</pubDate></item><item><title>LLM 强化学习对齐综述 上篇</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494408&amp;idx=1&amp;sn=3b4ad84ff2d628180b28b0839dbb2ea7&amp;chksm=c031ae53692a043a061c0e0202fc58cdd218c4d3b99c8e97896ad92b4d953b55cc1da7ec8717&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[ABSTRACT随着自我监督学习的进步、预训练语料库中数万亿个令牌的可用性、指令微调以及具有数十亿个参数的large trasnformers 的开发，大型语言模型（llm）现在能够对人类查询生成事实]]></description><author>指北笔记</author><pubDate>Tue, 25 Feb 2025 22:00:00 +0800</pubDate></item><item><title>DeepSeek-R1-Zero 起源与 GRPO 方法</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494406&amp;idx=1&amp;sn=5dc79f963c40efac9b6cbbd5d9dbcfb1&amp;chksm=c0d5732c7835cbbda5e4983d636a8a1ab2003eb05cbf4ba644a85130706d666a1389e38d9575&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language ModelsAbstract数学推理由于其复杂]]></description><author>指北笔记</author><pubDate>Mon, 24 Feb 2025 22:00:00 +0800</pubDate></item><item><title>Duplex Conversation: Towards Human-like Interaction</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494405&amp;idx=1&amp;sn=738b9e9cb0228ca61a6da6e68f8c0991&amp;chksm=c049765270bc31ca10b25da76878a5d94e37239faed9c72179313079d35637d843e7e0d1a33d&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[ABSTRACTDuplex Conversation，是一个多轮、多模态的口语对话系统，它使基于电话的代理能够像人类一样与客户进行交互。我们用电信中全双工的概念来演示类似人类的交互体验应该是什么，以]]></description><author>指北笔记</author><pubDate>Fri, 21 Feb 2025 22:03:40 +0800</pubDate></item><item><title>DeepSeek中多Token预测的起源</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494386&amp;idx=1&amp;sn=76bfa008e25e614af53642e9d2e4c081&amp;chksm=c005f03480ea3f4f4fd018c01eb97ef9280e610b95f42ab5b3187bcd3c1794c0b0a18f996418&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[Abstract像GPT和Llama这样的大型语言模型是用next-token预测损失来训练的。在这项工作中，我们建议训练语言模型一次预测多个未来标记可以提高样本效率。更具体地说，在训练语料库中的每个]]></description><author>指北笔记</author><pubDate>Thu, 20 Feb 2025 22:00:00 +0800</pubDate></item><item><title>DeepSeek V3 中 AUXILIARY-LOSS-FREE LOAD BALANCING STRATEGY 的由来</title><link>http://mp.weixin.qq.com/s?__biz=MzkyMTQyMjY0MA==&amp;mid=2247494262&amp;idx=1&amp;sn=25228e5d35d5f84767878c7ef25b15d0&amp;chksm=c0b353245aa9127af3f2d604d3104fd850026c88507466266d0c12cc236d9010e076fcbc624a&amp;scene=0&amp;xtrack=1#rd</link><description><![CDATA[ABSTRACT对于混合专家（MoE）模型，不平衡的专家负载将导致路由崩溃或增加计算开销。现有方法通常采用辅助损失来促进负载平衡，但较大的辅助损耗会在训练中引入不可忽略的干扰梯度，从而影响模型的性能。]]></description><author>指北笔记</author><pubDate>Wed, 19 Feb 2025 22:00:00 +0800</pubDate></item></channel></rss>